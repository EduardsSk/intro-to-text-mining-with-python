{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Topic Modelling with a Latent Dirichlet Allocation (LDA) Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Introduction to Latent Dirichlet Allocation (LDA)\n",
    "If you've heard of topic modelling before, you may have heard of Latent Dirichlet Allocation. LDA is a popular statistical model for topics and one that is almost synonymous with topic modelling in general.\n",
    "\n",
    "It's important to understand that LDA is only _one_ type of topic model; there are many others with equally dull acronyms (e.g. LSA, HDP, LSI, NNMF). Also, Gensim provides an _implementation_ of LDA called `LdaModel` (based on the LDA mathematics), but there are many other implementations in different libraries and software. Different implementations of LDA should give you more or less the same results, but different topic models may well give you different results.\n",
    "\n",
    "---\n",
    "### Going Further: More About LDA and Topic Modelling\n",
    "\n",
    "The mathematics behind LDA is out of the scope of this workshop. Likewise, the other types of topic model are too much for us to cover in this beginners' class. However, if you wish to go further there are links to extension material in the last section of this notebook 'What's Next?'.\n",
    "\n",
    "---\n",
    "\n",
    "So, topic modelling with LDA. **Let's dive right in! 🌊**\n",
    "\n",
    "We have a corpus of 56 presidential speeches that we've prepared into nicely cleaned tokens.\n",
    "\n",
    "> Our question: **What are the underlying themes of these texts as a group?**\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "## Loading the Corpus into Gensim from Files\n",
    "\n",
    "First, we need to get a list of all the files in the `data/inaugural` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "inaugural = Path('data', 'inaugural')\n",
    "files = list(inaugural.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open all the files in turn and add their contents to a big list of strings call `text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 56 documents loaded.\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as reader:       \n",
    "        document = []\n",
    "        for token in reader.read().split():\n",
    "            document.append(token)\n",
    "        text.append(document)\n",
    "\n",
    "print(f'There are {len(text)} documents loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(👆👆👆 If you don't understand this code above yet, don't worry. You can skip over it and still follow along with the topic modelling.)\n",
    "\n",
    "### Loading the Tokens into a Dictionary\n",
    "\n",
    "Now we have to load the corpus from text files into a _dictionary_. Gensim provides a special class of dictionary for us to work with called `gensim.corpora.Dictionary`. It has some extra stuff in it over and above the ordinary Python `dict`, but we don't need to worry about the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dictionary(6164 unique tokens: ['5', 'accomplish', 'accordingly', 'acknowledge', 'acquit']...)\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(text)\n",
    "str(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can understand that Gensim has found 6164 unique tokens in the corpus. But exactly what information does this `Dictionary` contain?\n",
    "\n",
    "In short, it is a _mapping_ between each _token_ and a _unique id number_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5': 0,\n",
       " 'accomplish': 1,\n",
       " 'accordingly': 2,\n",
       " 'acknowledge': 3,\n",
       " 'acquit': 4,\n",
       " 'act': 5,\n",
       " 'actual': 6,\n",
       " 'actuate': 7,\n",
       " 'add': 8,\n",
       " 'addition': 9,\n",
       " 'address': 10,\n",
       " 'administration': 11,\n",
       " 'adopt': 12,\n",
       " 'adore': 13,\n",
       " 'adorn': 14,\n",
       " 'advance': 15,\n",
       " 'advancement': 16,\n",
       " 'advantage': 17,\n",
       " 'advantageously': 18,\n",
       " 'affair': 19,\n",
       " 'affect': 20,\n",
       " 'affection': 21,\n",
       " 'affectionate': 22,\n",
       " 'agency': 23,\n",
       " 'aid': 24,\n",
       " 'all': 25,\n",
       " 'allot': 26,\n",
       " 'almighty': 27,\n",
       " 'alteration': 28,\n",
       " 'american': 29,\n",
       " 'among': 30,\n",
       " 'animosity': 31,\n",
       " 'anticipation': 32,\n",
       " 'anxiety': 33,\n",
       " 'appreciation': 34,\n",
       " 'ardent': 35,\n",
       " 'arduous': 36,\n",
       " 'arise': 37,\n",
       " 'article': 38,\n",
       " 'assemblage': 39,\n",
       " 'assemble': 40,\n",
       " 'assure': 41,\n",
       " 'asylum': 42,\n",
       " 'attachment': 43,\n",
       " 'attention': 44,\n",
       " 'attribute': 45,\n",
       " 'auspiciously': 46,\n",
       " 'author': 47,\n",
       " 'aver': 48,\n",
       " 'avoid': 49,\n",
       " 'await': 50,\n",
       " 'awaken': 51,\n",
       " 'be': 52,\n",
       " 'behold': 53,\n",
       " 'benediction': 54,\n",
       " 'benefit': 55,\n",
       " 'benign': 56,\n",
       " 'besides': 57,\n",
       " 'bind': 58,\n",
       " 'birth': 59,\n",
       " 'bless': 60,\n",
       " 'blessing': 61,\n",
       " 'brief': 62,\n",
       " 'bring': 63,\n",
       " 'call': 64,\n",
       " 'care': 65,\n",
       " 'carefully': 66,\n",
       " 'character': 67,\n",
       " 'characteristic': 68,\n",
       " 'charge': 69,\n",
       " 'charter': 70,\n",
       " 'choose': 71,\n",
       " 'circumstance': 72,\n",
       " 'citizen': 73,\n",
       " 'civil': 74,\n",
       " 'collect': 75,\n",
       " 'command': 76,\n",
       " 'commence': 77,\n",
       " 'commit': 78,\n",
       " 'community': 79,\n",
       " 'compare': 80,\n",
       " 'compensation': 81,\n",
       " 'comprehensive': 82,\n",
       " 'concern': 83,\n",
       " 'conduct': 84,\n",
       " 'confidence': 85,\n",
       " 'conflict': 86,\n",
       " 'congenial': 87,\n",
       " 'conscious': 88,\n",
       " 'consecrate': 89,\n",
       " 'consent': 90,\n",
       " 'consequence': 91,\n",
       " 'consider': 92,\n",
       " 'consideration': 93,\n",
       " 'consistent': 94,\n",
       " 'conspicuous': 95,\n",
       " 'constitution': 96,\n",
       " 'constitutional': 97,\n",
       " 'consult': 98,\n",
       " 'consultation': 99,\n",
       " 'contemplate': 100,\n",
       " 'continuance': 101,\n",
       " 'council': 102,\n",
       " 'country': 103,\n",
       " 'course': 104,\n",
       " 'crisis': 105,\n",
       " 'dare': 106,\n",
       " 'day': 107,\n",
       " 'dear': 108,\n",
       " 'decide': 109,\n",
       " 'decision': 110,\n",
       " 'decline': 111,\n",
       " 'deeply': 112,\n",
       " 'defect': 113,\n",
       " 'deficiency': 114,\n",
       " 'define': 115,\n",
       " 'degree': 116,\n",
       " 'delegate': 117,\n",
       " 'deliberate': 118,\n",
       " 'deliberation': 119,\n",
       " 'depart': 120,\n",
       " 'department': 121,\n",
       " 'depend': 122,\n",
       " 'derive': 123,\n",
       " 'designate': 124,\n",
       " 'despondence': 125,\n",
       " 'destiny': 126,\n",
       " 'devise': 127,\n",
       " 'difficulty': 128,\n",
       " 'discernment': 129,\n",
       " 'disinclination': 130,\n",
       " 'disposition': 131,\n",
       " 'disregard': 132,\n",
       " 'distinct': 133,\n",
       " 'distinguish': 134,\n",
       " 'distrustful': 135,\n",
       " 'divine': 136,\n",
       " 'duty': 137,\n",
       " 'dwell': 138,\n",
       " 'economy': 139,\n",
       " 'effective': 140,\n",
       " 'emolument': 141,\n",
       " 'emotion': 142,\n",
       " 'employ': 143,\n",
       " 'enable': 144,\n",
       " 'endanger': 145,\n",
       " 'endowment': 146,\n",
       " 'enlarge': 147,\n",
       " 'enter': 148,\n",
       " 'entire': 149,\n",
       " 'entrust': 150,\n",
       " 'equal': 151,\n",
       " 'equally': 152,\n",
       " 'error': 153,\n",
       " 'essential': 154,\n",
       " 'establish': 155,\n",
       " 'estimate': 156,\n",
       " 'eternal': 157,\n",
       " 'eve': 158,\n",
       " 'event': 159,\n",
       " 'every': 160,\n",
       " 'execute': 161,\n",
       " 'executive': 162,\n",
       " 'exemplify': 163,\n",
       " 'exercise': 164,\n",
       " 'exist': 165,\n",
       " 'expect': 166,\n",
       " 'expedient': 167,\n",
       " 'expenditure': 168,\n",
       " 'experience': 169,\n",
       " 'experiment': 170,\n",
       " 'express': 171,\n",
       " 'eye': 172,\n",
       " 'faithful': 173,\n",
       " 'far': 174,\n",
       " 'favor': 175,\n",
       " 'feeling': 176,\n",
       " 'felicity': 177,\n",
       " 'fellow': 178,\n",
       " 'fervent': 179,\n",
       " 'fill': 180,\n",
       " 'finally': 181,\n",
       " 'flatter': 182,\n",
       " 'fond': 183,\n",
       " 'force': 184,\n",
       " 'forego': 185,\n",
       " 'form': 186,\n",
       " 'fortify': 187,\n",
       " 'foundation': 188,\n",
       " 'free': 189,\n",
       " 'freeman': 190,\n",
       " 'frequent': 191,\n",
       " 'from': 192,\n",
       " 'function': 193,\n",
       " 'future': 194,\n",
       " 'genuine': 195,\n",
       " 'give': 196,\n",
       " 'good': 197,\n",
       " 'government': 198,\n",
       " 'gradual': 199,\n",
       " 'grateful': 200,\n",
       " 'gratitude': 201,\n",
       " 'great': 202,\n",
       " 'guide': 203,\n",
       " 'habit': 204,\n",
       " 'hand': 205,\n",
       " 'happiness': 206,\n",
       " 'harmony': 207,\n",
       " 'have': 208,\n",
       " 'health': 209,\n",
       " 'hear': 210,\n",
       " 'heaven': 211,\n",
       " 'his': 212,\n",
       " 'homage': 213,\n",
       " 'honest': 214,\n",
       " 'honor': 215,\n",
       " 'honorable': 216,\n",
       " 'hope': 217,\n",
       " 'house': 218,\n",
       " 'human': 219,\n",
       " 'humble': 220,\n",
       " 'immutable': 221,\n",
       " 'impart': 222,\n",
       " 'important': 223,\n",
       " 'impregnably': 224,\n",
       " 'impression': 225,\n",
       " 'improper': 226,\n",
       " 'inapplicable': 227,\n",
       " 'incapacity': 228,\n",
       " 'incident': 229,\n",
       " 'inclination': 230,\n",
       " 'include': 231,\n",
       " 'independent': 232,\n",
       " 'indispensably': 233,\n",
       " 'indissoluble': 234,\n",
       " 'inferior': 235,\n",
       " 'influence': 236,\n",
       " 'inherit': 237,\n",
       " 'inquietude': 238,\n",
       " 'inspire': 239,\n",
       " 'instance': 240,\n",
       " 'instead': 241,\n",
       " 'institute': 242,\n",
       " 'instrument': 243,\n",
       " 'interest': 244,\n",
       " 'interruption': 245,\n",
       " 'invisible': 246,\n",
       " 'join': 247,\n",
       " 'judge': 248,\n",
       " 'judgment': 249,\n",
       " 'juncture': 250,\n",
       " 'justly': 251,\n",
       " 'large': 252,\n",
       " 'lay': 253,\n",
       " 'leave': 254,\n",
       " 'lesson': 255,\n",
       " 'liberty': 256,\n",
       " 'life': 257,\n",
       " 'light': 258,\n",
       " 'limit': 259,\n",
       " 'little': 260,\n",
       " 'local': 261,\n",
       " 'love': 262,\n",
       " 'magnanimous': 263,\n",
       " 'magnitude': 264,\n",
       " 'man': 265,\n",
       " 'maxim': 266,\n",
       " 'mean': 267,\n",
       " 'measure': 268,\n",
       " 'meet': 269,\n",
       " 'mind': 270,\n",
       " 'misdirect': 271,\n",
       " 'mislead': 272,\n",
       " 'model': 273,\n",
       " 'month': 274,\n",
       " 'morality': 275,\n",
       " 'motive': 276,\n",
       " 'nation': 277,\n",
       " 'national': 278,\n",
       " 'nature': 279,\n",
       " 'necessary': 280,\n",
       " 'new': 281,\n",
       " 'notification': 282,\n",
       " 'obedience': 283,\n",
       " 'object': 284,\n",
       " 'objection': 285,\n",
       " 'observation': 286,\n",
       " 'occasion': 287,\n",
       " 'occasional': 288,\n",
       " 'official': 289,\n",
       " 'omit': 290,\n",
       " 'opportunity': 291,\n",
       " 'ordain': 292,\n",
       " 'order': 293,\n",
       " 'ordinary': 294,\n",
       " 'originate': 295,\n",
       " 'ought': 296,\n",
       " 'overwhelm': 297,\n",
       " 'palliate': 298,\n",
       " 'parent': 299,\n",
       " 'partiality': 300,\n",
       " 'particular': 301,\n",
       " 'party': 302,\n",
       " 'past': 303,\n",
       " 'patriotism': 304,\n",
       " 'peculiarly': 305,\n",
       " 'pecuniary': 306,\n",
       " 'people': 307,\n",
       " 'perfect': 308,\n",
       " 'permanent': 309,\n",
       " 'personal': 310,\n",
       " 'persuade': 311,\n",
       " 'pious': 312,\n",
       " 'place': 313,\n",
       " 'please': 314,\n",
       " 'pledge': 315,\n",
       " 'policy': 316,\n",
       " 'possible': 317,\n",
       " 'power': 318,\n",
       " 'pray': 319,\n",
       " 'predilection': 320,\n",
       " 'preeminence': 321,\n",
       " 'prejudice': 322,\n",
       " 'presage': 323,\n",
       " 'present': 324,\n",
       " 'preservation': 325,\n",
       " 'preside': 326,\n",
       " 'president': 327,\n",
       " 'principle': 328,\n",
       " 'private': 329,\n",
       " 'proceeding': 330,\n",
       " 'produce': 331,\n",
       " 'promote': 332,\n",
       " 'proof': 333,\n",
       " 'properly': 334,\n",
       " 'propitious': 335,\n",
       " 'prospect': 336,\n",
       " 'prosperity': 337,\n",
       " 'providential': 338,\n",
       " 'provision': 339,\n",
       " 'public': 340,\n",
       " 'pure': 341,\n",
       " 'purpose': 342,\n",
       " 'pursuit': 343,\n",
       " 'qualification': 344,\n",
       " 'question': 345,\n",
       " 'race': 346,\n",
       " 'receive': 347,\n",
       " 'recommend': 348,\n",
       " 'recommendation': 349,\n",
       " 'rectitude': 350,\n",
       " 'refer': 351,\n",
       " 'reflection': 352,\n",
       " 'regard': 353,\n",
       " 'remain': 354,\n",
       " 'remembrance': 355,\n",
       " 'render': 356,\n",
       " 'renounce': 357,\n",
       " 'repair': 358,\n",
       " 'representative': 359,\n",
       " 'republican': 360,\n",
       " 'require': 361,\n",
       " 'resolution': 362,\n",
       " 'resort': 363,\n",
       " 'respect': 364,\n",
       " 'result': 365,\n",
       " 'retreat': 366,\n",
       " 'return': 367,\n",
       " 'reverence': 368,\n",
       " 'revolution': 369,\n",
       " 'reward': 370,\n",
       " 'right': 371,\n",
       " 'rule': 372,\n",
       " 'sacred': 373,\n",
       " 'safely': 374,\n",
       " 'satisfaction': 375,\n",
       " 'scrutiny': 376,\n",
       " 'security': 377,\n",
       " 'select': 378,\n",
       " 'senate': 379,\n",
       " 'sensibility': 380,\n",
       " 'sentiment': 381,\n",
       " 'separate': 382,\n",
       " 'service': 383,\n",
       " 'shall': 384,\n",
       " 'share': 385,\n",
       " 'smile': 386,\n",
       " 'solid': 387,\n",
       " 'stake': 388,\n",
       " 'state': 389,\n",
       " 'station': 390,\n",
       " 'step': 391,\n",
       " 'strongly': 392,\n",
       " 'struggle': 393,\n",
       " 'study': 394,\n",
       " 'subject': 395,\n",
       " 'submit': 396,\n",
       " 'substitute': 397,\n",
       " 'success': 398,\n",
       " 'such': 399,\n",
       " 'sufficient': 400,\n",
       " 'sufficiently': 401,\n",
       " 'summon': 402,\n",
       " 'supplication': 403,\n",
       " 'supply': 404,\n",
       " 'suppress': 405,\n",
       " 'sure': 406,\n",
       " 'sway': 407,\n",
       " 'talent': 408,\n",
       " 'task': 409,\n",
       " 'temperate': 410,\n",
       " 'tender': 411,\n",
       " 'the': 412,\n",
       " 'think': 413,\n",
       " 'this': 414,\n",
       " 'thoroughly': 415,\n",
       " 'time': 416,\n",
       " 'token': 417,\n",
       " 'tranquil': 418,\n",
       " 'tranquillity': 419,\n",
       " 'transcendent': 420,\n",
       " 'transmit': 421,\n",
       " 'tribute': 422,\n",
       " 'trust': 423,\n",
       " 'truth': 424,\n",
       " 'unanimity': 425,\n",
       " 'undertake': 426,\n",
       " 'union': 427,\n",
       " 'unite': 428,\n",
       " 'universe': 429,\n",
       " 'unparalleled': 430,\n",
       " 'unpracticed': 431,\n",
       " 'untried': 432,\n",
       " 'urge': 433,\n",
       " 'veneration': 434,\n",
       " 'vicissitude': 435,\n",
       " 'view': 436,\n",
       " 'virtue': 437,\n",
       " 'voice': 438,\n",
       " 'voluntary': 439,\n",
       " 'waste': 440,\n",
       " 'watch': 441,\n",
       " 'way': 442,\n",
       " 'weighty': 443,\n",
       " 'when': 444,\n",
       " 'whilst': 445,\n",
       " 'win': 446,\n",
       " 'wise': 447,\n",
       " 'world': 448,\n",
       " 'year': 449,\n",
       " 'you': 450,\n",
       " 'america': 451,\n",
       " 'arrive': 452,\n",
       " 'ceremony': 453,\n",
       " 'chief': 454,\n",
       " 'endeavor': 455,\n",
       " 'entertain': 456,\n",
       " 'execution': 457,\n",
       " 'high': 458,\n",
       " 'incur': 459,\n",
       " 'injunction': 460,\n",
       " 'knowingly': 461,\n",
       " 'magistrate': 462,\n",
       " 'oath': 463,\n",
       " 'office': 464,\n",
       " 'presence': 465,\n",
       " 'previous': 466,\n",
       " 'proper': 467,\n",
       " 'punishment': 468,\n",
       " 'repose': 469,\n",
       " 'sense': 470,\n",
       " 'solemn': 471,\n",
       " 'that': 472,\n",
       " 'thereof': 473,\n",
       " 'upbraidings': 474,\n",
       " 'violate': 475,\n",
       " 'willingly': 476,\n",
       " 'witness': 477,\n",
       " 'abandon': 478,\n",
       " 'aboriginal': 479,\n",
       " 'abroad': 480,\n",
       " 'abuse': 481,\n",
       " 'academy': 482,\n",
       " 'accident': 483,\n",
       " 'accord': 484,\n",
       " 'acquire': 485,\n",
       " 'action': 486,\n",
       " 'adapt': 487,\n",
       " 'admiration': 488,\n",
       " 'admit': 489,\n",
       " 'adoption': 490,\n",
       " 'age': 491,\n",
       " 'agriculture': 492,\n",
       " 'alter': 493,\n",
       " 'altercation': 494,\n",
       " 'amiable': 495,\n",
       " 'amicable': 496,\n",
       " 'ancient': 497,\n",
       " 'and': 498,\n",
       " 'angel': 499,\n",
       " 'animate': 500,\n",
       " 'antiquity': 501,\n",
       " 'apology': 502,\n",
       " 'appear': 503,\n",
       " 'applaud': 504,\n",
       " 'apprehensive': 505,\n",
       " 'approbation': 506,\n",
       " 'ardor': 507,\n",
       " 'army': 508,\n",
       " 'artifice': 509,\n",
       " 'assembly': 510,\n",
       " 'assist': 511,\n",
       " 'asunder': 512,\n",
       " 'august': 513,\n",
       " 'authority': 514,\n",
       " 'batavian': 515,\n",
       " 'belligerent': 516,\n",
       " 'benevolence': 517,\n",
       " 'benevolent': 518,\n",
       " 'boast': 519,\n",
       " 'body': 520,\n",
       " 'bosom': 521,\n",
       " 'branch': 522,\n",
       " 'break': 523,\n",
       " 'bulwark': 524,\n",
       " 'but': 525,\n",
       " 'calamity': 526,\n",
       " 'can': 527,\n",
       " 'candid': 528,\n",
       " 'case': 529,\n",
       " 'cause': 530,\n",
       " 'caution': 531,\n",
       " 'certain': 532,\n",
       " 'certainly': 533,\n",
       " 'chain': 534,\n",
       " 'chamber': 535,\n",
       " 'chance': 536,\n",
       " 'chiefly': 537,\n",
       " 'choice': 538,\n",
       " 'christianity': 539,\n",
       " 'christians': 540,\n",
       " 'city': 541,\n",
       " 'claim': 542,\n",
       " 'class': 543,\n",
       " 'college': 544,\n",
       " 'colorable': 545,\n",
       " 'combination': 546,\n",
       " 'commerce': 547,\n",
       " 'common': 548,\n",
       " 'complaint': 549,\n",
       " 'comply': 550,\n",
       " 'concert': 551,\n",
       " 'condition': 552,\n",
       " 'confederacy': 553,\n",
       " 'confederation': 554,\n",
       " 'conformable': 555,\n",
       " 'congregation': 556,\n",
       " 'congress': 557,\n",
       " 'conscientious': 558,\n",
       " 'consist': 559,\n",
       " 'constant': 560,\n",
       " 'constituent': 561,\n",
       " 'contempt': 562,\n",
       " 'contest': 563,\n",
       " 'continue': 564,\n",
       " 'contribute': 565,\n",
       " 'convenience': 566,\n",
       " 'convention': 567,\n",
       " 'conviction': 568,\n",
       " 'corruption': 569,\n",
       " 'courier': 570,\n",
       " 'credit': 571,\n",
       " 'cut': 572,\n",
       " 'daily': 573,\n",
       " 'danger': 574,\n",
       " 'dangerous': 575,\n",
       " 'debate': 576,\n",
       " 'deceive': 577,\n",
       " 'decent': 578,\n",
       " 'decoration': 579,\n",
       " 'defense': 580,\n",
       " 'delicacy': 581,\n",
       " 'delicious': 582,\n",
       " 'delight': 583,\n",
       " 'demand': 584,\n",
       " 'denomination': 585,\n",
       " 'descend': 586,\n",
       " 'deserve': 587,\n",
       " 'desire': 588,\n",
       " 'destruction': 589,\n",
       " 'determination': 590,\n",
       " 'determine': 591,\n",
       " 'diamond': 592,\n",
       " 'difference': 593,\n",
       " 'diffidence': 594,\n",
       " 'diligent': 595,\n",
       " 'discontent': 596,\n",
       " 'discouragement': 597,\n",
       " 'discussion': 598,\n",
       " 'disobedience': 599,\n",
       " 'disquisition': 600,\n",
       " 'dissemination': 601,\n",
       " 'dissension': 602,\n",
       " 'domestic': 603,\n",
       " 'doubt': 604,\n",
       " 'durable': 605,\n",
       " 'duration': 606,\n",
       " 'early': 607,\n",
       " 'earnest': 608,\n",
       " 'eastern': 609,\n",
       " 'effect': 610,\n",
       " 'effort': 611,\n",
       " 'elect': 612,\n",
       " 'election': 613,\n",
       " 'elective': 614,\n",
       " 'elevate': 615,\n",
       " 'encourage': 616,\n",
       " 'end': 617,\n",
       " 'enemy': 618,\n",
       " 'energy': 619,\n",
       " 'engraven': 620,\n",
       " 'enjoy': 621,\n",
       " 'enlighten': 622,\n",
       " 'equity': 623,\n",
       " 'esteem': 624,\n",
       " 'europe': 625,\n",
       " 'exalt': 626,\n",
       " 'example': 627,\n",
       " 'excusable': 628,\n",
       " 'exhibit': 629,\n",
       " 'existence': 630,\n",
       " 'expectation': 631,\n",
       " 'expose': 632,\n",
       " 'extensive': 633,\n",
       " 'extraneous': 634,\n",
       " 'fact': 635,\n",
       " 'fair': 636,\n",
       " 'faith': 637,\n",
       " 'fall': 638,\n",
       " 'feel': 639,\n",
       " 'fix': 640,\n",
       " 'flattery': 641,\n",
       " 'fleet': 642,\n",
       " 'for': 643,\n",
       " 'foreign': 644,\n",
       " 'foresee': 645,\n",
       " 'forge': 646,\n",
       " 'formation': 647,\n",
       " 'formidable': 648,\n",
       " 'fortitude': 649,\n",
       " 'fortune': 650,\n",
       " 'found': 651,\n",
       " 'fountain': 652,\n",
       " 'frankly': 653,\n",
       " 'fraud': 654,\n",
       " 'french': 655,\n",
       " 'fresh': 656,\n",
       " 'friend': 657,\n",
       " 'friendly': 658,\n",
       " 'friendship': 659,\n",
       " 'frontier': 660,\n",
       " 'fruit': 661,\n",
       " 'general': 662,\n",
       " 'genius': 663,\n",
       " 'glory': 664,\n",
       " 'govern': 665,\n",
       " 'grandeur': 666,\n",
       " 'habitual': 667,\n",
       " 'half': 668,\n",
       " 'happy': 669,\n",
       " 'hazard': 670,\n",
       " 'head': 671,\n",
       " 'heart': 672,\n",
       " 'heat': 673,\n",
       " 'helvetic': 674,\n",
       " 'hesitate': 675,\n",
       " 'hesitation': 676,\n",
       " 'history': 677,\n",
       " 'humanity': 678,\n",
       " 'idea': 679,\n",
       " 'imitation': 680,\n",
       " 'immortal': 681,\n",
       " 'impartial': 682,\n",
       " 'impartiality': 683,\n",
       " 'improve': 684,\n",
       " 'improvement': 685,\n",
       " 'inattention': 686,\n",
       " 'incline': 687,\n",
       " 'increase': 688,\n",
       " 'independence': 689,\n",
       " 'individual': 690,\n",
       " 'infect': 691,\n",
       " 'inflexible': 692,\n",
       " 'information': 693,\n",
       " 'injury': 694,\n",
       " 'innocence': 695,\n",
       " 'inquiry': 696,\n",
       " 'institution': 697,\n",
       " 'insure': 698,\n",
       " 'insurrection': 699,\n",
       " 'integrity': 700,\n",
       " 'intellectual': 701,\n",
       " 'intelligence': 702,\n",
       " 'intelligences': 703,\n",
       " 'intention': 704,\n",
       " 'interior': 705,\n",
       " 'internal': 706,\n",
       " 'intrigue': 707,\n",
       " 'investigate': 708,\n",
       " 'inviolable': 709,\n",
       " 'iron': 710,\n",
       " 'irritate': 711,\n",
       " 'issue': 712,\n",
       " 'jealousy': 713,\n",
       " 'justice': 714,\n",
       " 'justifiable': 715,\n",
       " 'knowledge': 716,\n",
       " 'land': 717,\n",
       " 'languor': 718,\n",
       " 'launch': 719,\n",
       " 'law': 720,\n",
       " 'legislature': 721,\n",
       " 'legitimate': 722,\n",
       " 'length': 723,\n",
       " 'letter': 724,\n",
       " 'lie': 725,\n",
       " 'lift': 726,\n",
       " 'like': 727,\n",
       " 'literary': 728,\n",
       " 'live': 729,\n",
       " 'long': 730,\n",
       " 'lose': 731,\n",
       " 'loss': 732,\n",
       " 'lot': 733,\n",
       " 'maintain': 734,\n",
       " 'majestic': 735,\n",
       " 'majesty': 736,\n",
       " 'majority': 737,\n",
       " 'mankind': 738,\n",
       " 'manufacture': 739,\n",
       " 'manufacturer': 740,\n",
       " 'melancholy': 741,\n",
       " 'meliorate': 742,\n",
       " 'menace': 743,\n",
       " 'mere': 744,\n",
       " 'merit': 745,\n",
       " 'middle': 746,\n",
       " 'midst': 747,\n",
       " 'mode': 748,\n",
       " 'moral': 749,\n",
       " 'native': 750,\n",
       " 'natural': 751,\n",
       " 'navigation': 752,\n",
       " 'necessity': 753,\n",
       " 'negligence': 754,\n",
       " 'negotiation': 755,\n",
       " 'neighbor': 756,\n",
       " 'neutrality': 757,\n",
       " 'noble': 758,\n",
       " 'nor': 759,\n",
       " 'northern': 760,\n",
       " 'numb': 761,\n",
       " 'obligation': 762,\n",
       " 'obscure': 763,\n",
       " 'obtain': 764,\n",
       " 'ocean': 765,\n",
       " 'one': 766,\n",
       " 'open': 767,\n",
       " 'operation': 768,\n",
       " 'opinion': 769,\n",
       " 'ornament': 770,\n",
       " 'outline': 771,\n",
       " 'overrule': 772,\n",
       " 'painful': 773,\n",
       " 'part': 774,\n",
       " 'partial': 775,\n",
       " 'patron': 776,\n",
       " 'patronize': 777,\n",
       " 'peace': 778,\n",
       " 'perceive': 779,\n",
       " 'period': 780,\n",
       " 'pestilence': 781,\n",
       " 'piece': 782,\n",
       " 'plan': 783,\n",
       " 'point': 784,\n",
       " 'political': 785,\n",
       " 'position': 786,\n",
       " 'posterity': 787,\n",
       " 'praise': 788,\n",
       " 'precision': 789,\n",
       " 'preference': 790,\n",
       " 'prepare': 791,\n",
       " 'prescribe': 792,\n",
       " 'preserve': 793,\n",
       " 'pretense': 794,\n",
       " 'pride': 795,\n",
       " 'procure': 796,\n",
       " 'profess': 797,\n",
       " 'profligacy': 798,\n",
       " 'prompt': 799,\n",
       " 'propagate': 800,\n",
       " 'propose': 801,\n",
       " 'protect': 802,\n",
       " 'protector': 803,\n",
       " 'provide': 804,\n",
       " 'providence': 805,\n",
       " 'prudence': 806,\n",
       " 'purity': 807,\n",
       " 'pursue': 808,\n",
       " 'rampart': 809,\n",
       " 'rational': 810,\n",
       " 'read': 811,\n",
       " 'recollection': 812,\n",
       " 'reflect': 813,\n",
       " 'regular': 814,\n",
       " 'regulate': 815,\n",
       " 'regulation': 816,\n",
       " 'rejection': 817,\n",
       " 'relation': 818,\n",
       " 'religion': 819,\n",
       " 'rely': 820,\n",
       " 'remote': 821,\n",
       " 'remove': 822,\n",
       " 'reparation': 823,\n",
       " 'repeatedly': 824,\n",
       " 'represent': 825,\n",
       " 'residence': 826,\n",
       " 'resist': 827,\n",
       " 'resource': 828,\n",
       " 'respectable': 829,\n",
       " 'respectful': 830,\n",
       " 'retirement': 831,\n",
       " 'revolutionary': 832,\n",
       " 'rich': 833,\n",
       " 'rivalry': 834,\n",
       " 'robe': 835,\n",
       " 'rod': 836,\n",
       " 'sagacious': 837,\n",
       " 'sanction': 838,\n",
       " 'sanguine': 839,\n",
       " 'school': 840,\n",
       " 'science': 841,\n",
       " 'seat': 842,\n",
       " 'secret': 843,\n",
       " 'secure': 844,\n",
       " 'see': 845,\n",
       " 'separation': 846,\n",
       " 'seven': 847,\n",
       " 'sight': 848,\n",
       " 'signally': 849,\n",
       " 'silent': 850,\n",
       " 'single': 851,\n",
       " 'situation': 852,\n",
       " 'society': 853,\n",
       " 'solemnly': 854,\n",
       " 'solidity': 855,\n",
       " 'solitary': 856,\n",
       " 'soon': 857,\n",
       " 'sophistry': 858,\n",
       " 'southern': 859,\n",
       " 'speak': 860,\n",
       " 'spectacle': 861,\n",
       " 'spirit': 862,\n",
       " 'splendid': 863,\n",
       " 'spring': 864,\n",
       " 'stage': 865,\n",
       " 'strenuous': 866,\n",
       " 'strike': 867,\n",
       " 'submission': 868,\n",
       " 'successor': 869,\n",
       " 'suffrage': 870,\n",
       " 'suggest': 871,\n",
       " 'superior': 872,\n",
       " 'support': 873,\n",
       " 'supreme': 874,\n",
       " 'temperance': 875,\n",
       " 'temporary': 876,\n",
       " 'terror': 877,\n",
       " 'theirs': 878,\n",
       " 'there': 879,\n",
       " 'thing': 880,\n",
       " 'threaten': 881,\n",
       " 'tie': 882,\n",
       " 'total': 883,\n",
       " 'transaction': 884,\n",
       " 'uncertainty': 885,\n",
       " 'unessential': 886,\n",
       " 'unexampled': 887,\n",
       " 'unfaithful': 888,\n",
       " 'universal': 889,\n",
       " 'university': 890,\n",
       " 'unlimited': 891,\n",
       " 'unshaken': 892,\n",
       " 'usual': 893,\n",
       " 'utmost': 894,\n",
       " 'value': 895,\n",
       " 'venality': 896,\n",
       " 'venture': 897,\n",
       " 'violence': 898,\n",
       " 'virtuous': 899,\n",
       " 'vote': 900,\n",
       " 'war': 901,\n",
       " 'wealth': 902,\n",
       " 'welfare': 903,\n",
       " 'well': 904,\n",
       " 'western': 905,\n",
       " 'what': 906,\n",
       " 'wish': 907,\n",
       " 'with': 908,\n",
       " 'zeal': 909,\n",
       " '1000': 910,\n",
       " 'about': 911,\n",
       " 'absolute': 912,\n",
       " 'acquiescence': 913,\n",
       " 'acquisition': 914,\n",
       " 'agitation': 915,\n",
       " 'agonize': 916,\n",
       " 'alarm': 917,\n",
       " 'alliance': 918,\n",
       " 'amidst': 919,\n",
       " 'anchor': 920,\n",
       " 'animation': 921,\n",
       " 'announce': 922,\n",
       " 'answer': 923,\n",
       " 'antirepublican': 924,\n",
       " 'anxious': 925,\n",
       " 'appeal': 926,\n",
       " 'approach': 927,\n",
       " 'arraignment': 928,\n",
       " 'arrange': 929,\n",
       " 'ask': 930,\n",
       " 'aspect': 931,\n",
       " 'assign': 932,\n",
       " 'associate': 933,\n",
       " 'attainment': 934,\n",
       " 'auspice': 935,\n",
       " 'avail': 936,\n",
       " 'awful': 937,\n",
       " 'banish': 938,\n",
       " 'bar': 939,\n",
       " 'bear': 940,\n",
       " 'believe': 941,\n",
       " 'beloved': 942,\n",
       " 'bestow': 943,\n",
       " 'billow': 944,\n",
       " 'bitter': 945,\n",
       " 'bleed': 946,\n",
       " 'blood': 947,\n",
       " 'bloody': 948,\n",
       " 'bread': 949,\n",
       " 'bright': 950,\n",
       " 'brother': 951,\n",
       " 'burthened': 952,\n",
       " 'capable': 953,\n",
       " 'change': 954,\n",
       " 'circle': 955,\n",
       " 'civic': 956,\n",
       " 'close': 957,\n",
       " 'combat': 958,\n",
       " 'compass': 959,\n",
       " 'competent': 960,\n",
       " 'comprehend': 961,\n",
       " 'compress': 962,\n",
       " 'conciliate': 963,\n",
       " 'condemn': 964,\n",
       " 'consciousness': 965,\n",
       " 'consequently': 966,\n",
       " 'consolation': 967,\n",
       " 'constellation': 968,\n",
       " 'contemplation': 969,\n",
       " 'contrary': 970,\n",
       " 'convulsion': 971,\n",
       " 'corpus': 972,\n",
       " 'corrective': 973,\n",
       " 'countenance': 974,\n",
       " 'courage': 975,\n",
       " 'creed': 976,\n",
       " 'debt': 977,\n",
       " 'declare': 978,\n",
       " 'deem': 979,\n",
       " 'degradation': 980,\n",
       " 'descendant': 981,\n",
       " 'despair': 982,\n",
       " 'despotic': 983,\n",
       " 'despotism': 984,\n",
       " 'destine': 985,\n",
       " 'devote': 986,\n",
       " 'different': 987,\n",
       " 'diffusion': 988,\n",
       " 'discipline': 989,\n",
       " 'dispensation': 990,\n",
       " 'dissolve': 991,\n",
       " 'distant': 992,\n",
       " 'divide': 993,\n",
       " 'dreary': 994,\n",
       " 'during': 995,\n",
       " 'earn': 996,\n",
       " 'earth': 997,\n",
       " 'element': 998,\n",
       " 'embark': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Size and Filtering Extremes\n",
    "\n",
    "The tokens are collectively known as a _vocabulary_ and the size and nature of the vocabulary you choose is important. A large vocabulary will take more computational power and memory to analyse. A vocabulary with many rare words has less useful information in it (so you are wasting time and memory processing it).\n",
    "\n",
    "To reduce the size of the vocabulary and increase the density of information content, we can filter out the extremes with `filter_extremes()`. You can experiment with different values, but here we filter out tokens that appear less than 5 times or appear in more than 50% of the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dictionary(1679 unique tokens: ['accomplish', 'acknowledge', 'actual', 'add', 'addition']...)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "str(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 1679 unique tokens, compared with 6164 for the original `Dictionary`.\n",
    "\n",
    "### Saving the Dictionary To File\n",
    "\n",
    "Gensim provides an easy way to save the `Dictionary` to file so you can reload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_file = str(Path('data', 'saved', '1-dictionary.gensim')) # Transform Path to string as `save()` only accepts strings\n",
    "dictionary.save(dict_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that we now have a file named `1-dictionary.gensim` in the `data/saved` folder. NB: This file is not human-readable.\n",
    "\n",
    "### Loading the Dictionary From File\n",
    "\n",
    "Here is how you can load the dictionary, or any other object you create in Gensim, back into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dictionary(1679 unique tokens: ['accomplish', 'acknowledge', 'actual', 'add', 'addition']...)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = Dictionary.load(dict_file)\n",
    "str(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the corpus loaded we can start to analyse its contents. The first step is to count the words to create a **bag-of-words** corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Bag of Words Corpus\n",
    "\n",
    ">**The key to understanding Natural Language Processing (NLP) is that the computer can only do computations on _numbers_. We have to present our corpus for analysis in a numerical form — typically _vectors_ — and make human sense of everything at the end.**\n",
    "\n",
    "A bag-of-words (BoW) corpus is the _vocabulary_ of known tokens (words) in the corpus together with some _measure_ of how often they occur. The measurement may be:\n",
    "* binary (presence or absence)\n",
    "* count (how many times the token occurs)\n",
    "* frequency (count divided by the total number of tokens).\n",
    "\n",
    "In our example, we will use Gensim's `doc2bow()`, which simply counts the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 2),\n",
       " (21, 1),\n",
       " (22, 2),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 2),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 3),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 2),\n",
       " (48, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1),\n",
       " (53, 1),\n",
       " (54, 1),\n",
       " (55, 1),\n",
       " (56, 1),\n",
       " (57, 1),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (60, 1),\n",
       " (61, 1),\n",
       " (62, 1),\n",
       " (63, 1),\n",
       " (64, 2),\n",
       " (65, 1),\n",
       " (66, 2),\n",
       " (67, 1),\n",
       " (68, 2),\n",
       " (69, 1),\n",
       " (70, 1),\n",
       " (71, 1),\n",
       " (72, 1),\n",
       " (73, 1),\n",
       " (74, 1),\n",
       " (75, 2),\n",
       " (76, 1),\n",
       " (77, 2),\n",
       " (78, 1),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (82, 1),\n",
       " (83, 1),\n",
       " (84, 1),\n",
       " (85, 1),\n",
       " (86, 1),\n",
       " (87, 1),\n",
       " (88, 1),\n",
       " (89, 1),\n",
       " (90, 1),\n",
       " (91, 1),\n",
       " (92, 1),\n",
       " (93, 1),\n",
       " (94, 1),\n",
       " (95, 1),\n",
       " (96, 1),\n",
       " (97, 1),\n",
       " (98, 3),\n",
       " (99, 1),\n",
       " (100, 1),\n",
       " (101, 2),\n",
       " (102, 1),\n",
       " (103, 2),\n",
       " (104, 2),\n",
       " (105, 1),\n",
       " (106, 1),\n",
       " (107, 1),\n",
       " (108, 2),\n",
       " (109, 1),\n",
       " (110, 2),\n",
       " (111, 1),\n",
       " (112, 1),\n",
       " (113, 1),\n",
       " (114, 1),\n",
       " (115, 1),\n",
       " (116, 1),\n",
       " (117, 1),\n",
       " (118, 1),\n",
       " (119, 1),\n",
       " (120, 1),\n",
       " (121, 1),\n",
       " (122, 1),\n",
       " (123, 1),\n",
       " (124, 1),\n",
       " (125, 1),\n",
       " (126, 1),\n",
       " (127, 1),\n",
       " (128, 1),\n",
       " (129, 3),\n",
       " (130, 1),\n",
       " (131, 1),\n",
       " (132, 1),\n",
       " (133, 1),\n",
       " (134, 2),\n",
       " (135, 2),\n",
       " (136, 1),\n",
       " (137, 1),\n",
       " (138, 2),\n",
       " (139, 2),\n",
       " (140, 1),\n",
       " (141, 1),\n",
       " (142, 1),\n",
       " (143, 2),\n",
       " (144, 1),\n",
       " (145, 1),\n",
       " (146, 2),\n",
       " (147, 1),\n",
       " (148, 1),\n",
       " (149, 1),\n",
       " (150, 1),\n",
       " (151, 2),\n",
       " (152, 1),\n",
       " (153, 1),\n",
       " (154, 1),\n",
       " (155, 1),\n",
       " (156, 2),\n",
       " (157, 1),\n",
       " (158, 1),\n",
       " (159, 1),\n",
       " (160, 1),\n",
       " (161, 1),\n",
       " (162, 1),\n",
       " (163, 1),\n",
       " (164, 3),\n",
       " (165, 1),\n",
       " (166, 2),\n",
       " (167, 1),\n",
       " (168, 1),\n",
       " (169, 1),\n",
       " (170, 2),\n",
       " (171, 2),\n",
       " (172, 1),\n",
       " (173, 4),\n",
       " (174, 1),\n",
       " (175, 1),\n",
       " (176, 2),\n",
       " (177, 1),\n",
       " (178, 2),\n",
       " (179, 1),\n",
       " (180, 1),\n",
       " (181, 1),\n",
       " (182, 1),\n",
       " (183, 1),\n",
       " (184, 1),\n",
       " (185, 1),\n",
       " (186, 1),\n",
       " (187, 1),\n",
       " (188, 2),\n",
       " (189, 1),\n",
       " (190, 1),\n",
       " (191, 1),\n",
       " (192, 1),\n",
       " (193, 1),\n",
       " (194, 1),\n",
       " (195, 1),\n",
       " (196, 1),\n",
       " (197, 2),\n",
       " (198, 1),\n",
       " (199, 1),\n",
       " (200, 1),\n",
       " (201, 2),\n",
       " (202, 1),\n",
       " (203, 1),\n",
       " (204, 1),\n",
       " (205, 2),\n",
       " (206, 1),\n",
       " (207, 2),\n",
       " (208, 1),\n",
       " (209, 1),\n",
       " (210, 1),\n",
       " (211, 1),\n",
       " (212, 2),\n",
       " (213, 1),\n",
       " (214, 1),\n",
       " (215, 1),\n",
       " (216, 1),\n",
       " (217, 1),\n",
       " (218, 1),\n",
       " (219, 1),\n",
       " (220, 1),\n",
       " (221, 1),\n",
       " (222, 2),\n",
       " (223, 1),\n",
       " (224, 2),\n",
       " (225, 1),\n",
       " (226, 2),\n",
       " (227, 1),\n",
       " (228, 1),\n",
       " (229, 1),\n",
       " (230, 1),\n",
       " (231, 1),\n",
       " (232, 1),\n",
       " (233, 1),\n",
       " (234, 1),\n",
       " (235, 1),\n",
       " (236, 2),\n",
       " (237, 2),\n",
       " (238, 1),\n",
       " (239, 1),\n",
       " (240, 1),\n",
       " (241, 1),\n",
       " (242, 1),\n",
       " (243, 1),\n",
       " (244, 1),\n",
       " (245, 1),\n",
       " (246, 1),\n",
       " (247, 1),\n",
       " (248, 1),\n",
       " (249, 1),\n",
       " (250, 1),\n",
       " (251, 2),\n",
       " (252, 1),\n",
       " (253, 1),\n",
       " (254, 1),\n",
       " (255, 1),\n",
       " (256, 1),\n",
       " (257, 1),\n",
       " (258, 2),\n",
       " (259, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in text]\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What `corpus[0]` shows us is a list of _token ids_ and their _count_ for the first document in the corpus. For example, `(7, 1)` is the token id `7` and its count `1` i.e. it was found once in this document. \n",
    "\n",
    "You can look at the counts for any of the documents from 0-55 by changing the index number (remember indexing starts at 0).\n",
    "\n",
    "### The 'Bag' in Bag of Words\n",
    "\n",
    "In this basic BoW model the order and location of words is discarded. For example, it does not matter if the words 'red' and 'nose' are adjacent ('red nose'), or at the beginning or end of a sentence; BoW just treats the words individually. It is like a 'bag' of Scrabble™ tiles, where each tile is a word, all rattling around together in no particular order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Going Further: Term Frequency–Inverse Document Frequency (TF-IDF)\n",
    "Highly frequent words can come to dominate your results and yet they may not be as meaningful or interesting as rarer words. For example, if you are looking at articles about the history of the Moon landings, even if you have removed all the stopwords, you may well find that the words 'lunar', 'moon', 'landing', 'orbit', and 'earth' predominate. Subtle differences in topic between documents may be lost.\n",
    "\n",
    "We have already done some filtering of extremes (above) by filtering tokens that appeared less than 5 times or appeared in more than 50% of the documents.\n",
    "\n",
    "Another way to deal with this is to use a _weighting factor_ called **TF-IDF**. A value is calculated for each word that reflects:\n",
    "* Term frequency (TF) - the number of times the word appears in the document\n",
    "* Document frequency (DF) - the number of documents in the corpus that contain the word\n",
    "\n",
    "For example, if a very uncommon word is present in two documents, this word is weighted more highly than a word that is present in all documents in a corpus.\n",
    "\n",
    "Gensim provides `TfidfModel`, which accepts a BoW corpus and creates the weightings for each token in each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(corpus)\n",
    "tfidf.num_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peak at the weightings for any document like this, where the first number in each pair (tuple) is the _token id_ and the second is the _weighting_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.03371549584954543)\n",
      "(1, 0.04539502752050589)\n",
      "(2, 0.06371997697331631)\n",
      "(3, 0.029138908511114364)\n",
      "(4, 0.07911052337005132)\n",
      "(5, 0.05044278256396589)\n",
      "(6, 0.03716558815461547)\n",
      "(7, 0.05641300960979839)\n",
      "(8, 0.03211783311115547)\n",
      "(9, 0.026408528486027517)\n",
      "(10, 0.04102246321306336)\n",
      "(11, 0.05329202148740097)\n",
      "(12, 0.05641300960979839)\n",
      "(13, 0.03211783311115547)\n",
      "(14, 0.027745268803712947)\n",
      "(15, 0.07314029632421884)\n",
      "(16, 0.04539502752050589)\n",
      "(17, 0.059863101914868426)\n",
      "(18, 0.059863101914868426)\n",
      "(19, 0.03903727417027296)\n",
      "(20, 0.11282601921959678)\n",
      "(21, 0.05641300960979839)\n",
      "(22, 0.07079025013026456)\n",
      "(23, 0.06809254128075884)\n",
      "(24, 0.03716558815461547)\n",
      "(25, 0.05641300960979839)\n",
      "(26, 0.04313581520044797)\n",
      "(27, 0.05044278256396589)\n",
      "(28, 0.05329202148740097)\n",
      "(29, 0.07911052337005132)\n",
      "(30, 0.030594507727148022)\n",
      "(31, 0.06371997697331631)\n",
      "(32, 0.023888393745265055)\n",
      "(33, 0.047821736832581174)\n",
      "(34, 0.023888393745265055)\n",
      "(35, 0.03371549584954543)\n",
      "(36, 0.06371997697331631)\n",
      "(37, 0.050248446144656456)\n",
      "(38, 0.07314029632421884)\n",
      "(39, 0.03903727417027296)\n",
      "(40, 0.07911052337005132)\n",
      "(41, 0.026408528486027517)\n",
      "(42, 0.10114648754863628)\n",
      "(43, 0.06371997697331631)\n",
      "(44, 0.04102246321306336)\n",
      "(45, 0.07314029632421884)\n",
      "(46, 0.03539512506513228)\n",
      "(47, 0.050248446144656456)\n",
      "(48, 0.07314029632421884)\n",
      "(49, 0.07911052337005132)\n",
      "(50, 0.025124223072328228)\n",
      "(51, 0.029138908511114364)\n",
      "(52, 0.059863101914868426)\n",
      "(53, 0.07911052337005132)\n",
      "(54, 0.06809254128075884)\n",
      "(55, 0.04102246321306336)\n",
      "(56, 0.03211783311115547)\n",
      "(57, 0.03539512506513228)\n",
      "(58, 0.05641300960979839)\n",
      "(59, 0.027745268803712947)\n",
      "(60, 0.047821736832581174)\n",
      "(61, 0.05641300960979839)\n",
      "(62, 0.059863101914868426)\n",
      "(63, 0.04539502752050589)\n",
      "(64, 0.11972620382973685)\n",
      "(65, 0.059863101914868426)\n",
      "(66, 0.10088556512793179)\n",
      "(67, 0.03211783311115547)\n",
      "(68, 0.12743995394663263)\n",
      "(69, 0.03211783311115547)\n",
      "(70, 0.07314029632421884)\n",
      "(71, 0.07911052337005132)\n",
      "(72, 0.05641300960979839)\n",
      "(73, 0.03371549584954543)\n",
      "(74, 0.07314029632421884)\n",
      "(75, 0.12743995394663263)\n",
      "(76, 0.07911052337005132)\n",
      "(77, 0.07433117630923095)\n",
      "(78, 0.025124223072328228)\n",
      "(79, 0.05044278256396589)\n",
      "(80, 0.025124223072328228)\n",
      "(81, 0.059863101914868426)\n",
      "(82, 0.03539512506513228)\n",
      "(83, 0.04539502752050589)\n",
      "(84, 0.05641300960979839)\n",
      "(85, 0.06809254128075884)\n",
      "(86, 0.04313581520044797)\n",
      "(87, 0.04313581520044797)\n",
      "(88, 0.047821736832581174)\n",
      "(89, 0.04102246321306336)\n",
      "(90, 0.04102246321306336)\n",
      "(91, 0.06809254128075884)\n",
      "(92, 0.04313581520044797)\n",
      "(93, 0.03211783311115547)\n",
      "(94, 0.05641300960979839)\n",
      "(95, 0.04539502752050589)\n",
      "(96, 0.05329202148740097)\n",
      "(97, 0.022697513760252946)\n",
      "(98, 0.07537266921698468)\n",
      "(99, 0.06809254128075884)\n",
      "(100, 0.07314029632421884)\n",
      "(101, 0.07433117630923095)\n",
      "(102, 0.059863101914868426)\n",
      "(103, 0.07433117630923095)\n",
      "(104, 0.04777678749053011)\n",
      "(105, 0.027745268803712947)\n",
      "(106, 0.03539512506513228)\n",
      "(107, 0.025124223072328228)\n",
      "(108, 0.12743995394663263)\n",
      "(109, 0.03371549584954543)\n",
      "(110, 0.04539502752050589)\n",
      "(111, 0.03903727417027296)\n",
      "(112, 0.022697513760252946)\n",
      "(113, 0.047821736832581174)\n",
      "(114, 0.026408528486027517)\n",
      "(115, 0.023888393745265055)\n",
      "(116, 0.059863101914868426)\n",
      "(117, 0.06371997697331631)\n",
      "(118, 0.06809254128075884)\n",
      "(119, 0.05044278256396589)\n",
      "(120, 0.07911052337005132)\n",
      "(121, 0.03716558815461547)\n",
      "(122, 0.06371997697331631)\n",
      "(123, 0.03716558815461547)\n",
      "(124, 0.03716558815461547)\n",
      "(125, 0.04539502752050589)\n",
      "(126, 0.04539502752050589)\n",
      "(127, 0.03371549584954543)\n",
      "(128, 0.05044278256396589)\n",
      "(129, 0.07166518123579517)\n",
      "(130, 0.04102246321306336)\n",
      "(131, 0.029138908511114364)\n",
      "(132, 0.05044278256396589)\n",
      "(133, 0.05044278256396589)\n",
      "(134, 0.11282601921959678)\n",
      "(135, 0.055490537607425894)\n",
      "(136, 0.03903727417027296)\n",
      "(137, 0.03539512506513228)\n",
      "(138, 0.08627163040089594)\n",
      "(139, 0.08627163040089594)\n",
      "(140, 0.06809254128075884)\n",
      "(141, 0.05641300960979839)\n",
      "(142, 0.03903727417027296)\n",
      "(143, 0.04539502752050589)\n",
      "(144, 0.07911052337005132)\n",
      "(145, 0.03211783311115547)\n",
      "(146, 0.10658404297480194)\n",
      "(147, 0.03903727417027296)\n",
      "(148, 0.07911052337005132)\n",
      "(149, 0.03371549584954543)\n",
      "(150, 0.03903727417027296)\n",
      "(151, 0.08627163040089594)\n",
      "(152, 0.026408528486027517)\n",
      "(153, 0.04539502752050589)\n",
      "(154, 0.059863101914868426)\n",
      "(155, 0.047821736832581174)\n",
      "(156, 0.05827781702222873)\n",
      "(157, 0.027745268803712947)\n",
      "(158, 0.029138908511114364)\n",
      "(159, 0.06809254128075884)\n",
      "(160, 0.07911052337005132)\n",
      "(161, 0.06809254128075884)\n",
      "(162, 0.07911052337005132)\n",
      "(163, 0.047821736832581174)\n",
      "(164, 0.09178352318144406)\n",
      "(165, 0.05641300960979839)\n",
      "(166, 0.052817056972055035)\n",
      "(167, 0.06809254128075884)\n",
      "(168, 0.07314029632421884)\n",
      "(169, 0.025124223072328228)\n",
      "(170, 0.09079005504101179)\n",
      "(171, 0.04777678749053011)\n",
      "(172, 0.059863101914868426)\n",
      "(173, 0.1284713324446219)\n",
      "(174, 0.06371997697331631)\n",
      "(175, 0.06809254128075884)\n",
      "(176, 0.11282601921959678)\n",
      "(177, 0.03211783311115547)\n",
      "(178, 0.15822104674010265)\n",
      "(179, 0.03716558815461547)\n",
      "(180, 0.03211783311115547)\n",
      "(181, 0.03371549584954543)\n",
      "(182, 0.07314029632421884)\n",
      "(183, 0.03539512506513228)\n",
      "(184, 0.06371997697331631)\n",
      "(185, 0.03716558815461547)\n",
      "(186, 0.03903727417027296)\n",
      "(187, 0.07314029632421884)\n",
      "(188, 0.06743099169909086)\n",
      "(189, 0.030594507727148022)\n",
      "(190, 0.027745268803712947)\n",
      "(191, 0.05329202148740097)\n",
      "(192, 0.06809254128075884)\n",
      "(193, 0.059863101914868426)\n",
      "(194, 0.04539502752050589)\n",
      "(195, 0.07911052337005132)\n",
      "(196, 0.04313581520044797)\n",
      "(197, 0.15822104674010265)\n",
      "(198, 0.030594507727148022)\n",
      "(199, 0.03371549584954543)\n",
      "(200, 0.04313581520044797)\n",
      "(201, 0.11282601921959678)\n",
      "(202, 0.06371997697331631)\n",
      "(203, 0.06809254128075884)\n",
      "(204, 0.025124223072328228)\n",
      "(205, 0.09564347366516235)\n",
      "(206, 0.07911052337005132)\n",
      "(207, 0.07433117630923095)\n",
      "(208, 0.04313581520044797)\n",
      "(209, 0.06809254128075884)\n",
      "(210, 0.05044278256396589)\n",
      "(211, 0.022697513760252946)\n",
      "(212, 0.15822104674010265)\n",
      "(213, 0.026408528486027517)\n",
      "(214, 0.06371997697331631)\n",
      "(215, 0.03211783311115547)\n",
      "(216, 0.03539512506513228)\n",
      "(217, 0.03716558815461547)\n",
      "(218, 0.06371997697331631)\n",
      "(219, 0.04313581520044797)\n",
      "(220, 0.059863101914868426)\n",
      "(221, 0.059863101914868426)\n",
      "(222, 0.07079025013026456)\n",
      "(223, 0.04539502752050589)\n",
      "(224, 0.052817056972055035)\n",
      "(225, 0.07314029632421884)\n",
      "(226, 0.08204492642612672)\n",
      "(227, 0.04313581520044797)\n",
      "(228, 0.07314029632421884)\n",
      "(229, 0.03211783311115547)\n",
      "(230, 0.06809254128075884)\n",
      "(231, 0.047821736832581174)\n",
      "(232, 0.07314029632421884)\n",
      "(233, 0.03716558815461547)\n",
      "(234, 0.030594507727148022)\n",
      "(235, 0.07314029632421884)\n",
      "(236, 0.11972620382973685)\n",
      "(237, 0.15822104674010265)\n",
      "(238, 0.05329202148740097)\n",
      "(239, 0.07314029632421884)\n",
      "(240, 0.03539512506513228)\n",
      "(241, 0.04539502752050589)\n",
      "(242, 0.023888393745265055)\n",
      "(243, 0.07911052337005132)\n",
      "(244, 0.06371997697331631)\n",
      "(245, 0.06809254128075884)\n",
      "(246, 0.030594507727148022)\n",
      "(247, 0.04102246321306336)\n",
      "(248, 0.04539502752050589)\n",
      "(249, 0.07314029632421884)\n",
      "(250, 0.03716558815461547)\n",
      "(251, 0.055490537607425894)\n",
      "(252, 0.07911052337005132)\n",
      "(253, 0.04539502752050589)\n",
      "(254, 0.047821736832581174)\n",
      "(255, 0.023888393745265055)\n",
      "(256, 0.06809254128075884)\n",
      "(257, 0.059863101914868426)\n",
      "(258, 0.055490537607425894)\n",
      "(259, 0.047821736832581174)\n"
     ]
    }
   ],
   "source": [
    "for doc in tfidf[corpus[0]]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model could be used instead of the BoW model as input to topic modelling algorithms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "\n",
    "## Training the Latent Dirichlet Allocation (LDA) Model\n",
    "\n",
    "### What Does 'Training a Model' Mean?\n",
    "\n",
    "The first thing we need to do is 'train a model'. These words and concepts come from the (fashionable!) sphere of **machine learning**. A 'model' is a simplified representation of something in the real world that a computer can handle. In topic modelling, the model is a representation of the topics of the corpus.\n",
    "\n",
    "We can say the computer acquires 'experience', or a simplified 'understanding' of what the corpus is about by creating a model of it. We have to train the computer in how to make its model by feeding it training data -- in the case of topic modelling, this data is the text we are interested in.\n",
    "\n",
    "Typically, in a machine learning project you would split your data into a _training set_ and a _holdout set_. The training set is used to train the model, and the holdout set is used to test the model to see if it is valid or useful.\n",
    "\n",
    "As we are doing a simple exploratory analysis here we are going to use all the data at once. We won't be doing any validation in this workshop.\n",
    "\n",
    "**Let's get started with our topic modelling!**\n",
    "\n",
    "We `import` the `LdaModel`, pass it our BoW `corpus` and limit the number of topics we are interested in to `5`. Feel free to experiment with the number of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "ldamodel = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we save the LDA model to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_file = str(Path('data', 'saved', '2-lda.gensim'))\n",
    "ldamodel.save(lda_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Topics for the Whole Corpus\n",
    "\n",
    "> **❗Important Note: You may see the topics, words and probabilities created differently than the examples below due to the way they are generated. This means my descriptions may not match up exactly with what you see when you run the notebook.**\n",
    "\n",
    "To view the topics we can use `show_topics` — and we can optionally limit it to the number of topics and words we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"congress\" + 0.006*\"executive\" + 0.004*\"general\" + 0.004*\"ought\" + 0.004*\"business\"'),\n",
       " (1,\n",
       "  '0.007*\"institution\" + 0.006*\"opinion\" + 0.005*\"revenue\" + 0.005*\"object\" + 0.004*\"authority\"'),\n",
       " (2,\n",
       "  '0.016*\"there\" + 0.012*\"friend\" + 0.009*\"word\" + 0.009*\"today\" + 0.007*\"child\"'),\n",
       " (3,\n",
       "  '0.010*\"case\" + 0.006*\"democracy\" + 0.006*\"program\" + 0.006*\"minority\" + 0.005*\"provision\"'),\n",
       " (4,\n",
       "  '0.008*\"today\" + 0.007*\"help\" + 0.007*\"century\" + 0.007*\"americans\" + 0.005*\"opportunity\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topics(num_topics=5, num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we see here? These 5 topics represent the topic distribution of the **corpus as a whole**.\n",
    "\n",
    "Let's take an example topic:\n",
    "\n",
    "```\n",
    "(3, '0.008*\"congress\" + 0.007*\"business\" + 0.005*\"increase\" + 0.004*\"trade\" + 0.004*\"ought\"')\n",
    "```\n",
    "\n",
    "The first number `3` in the tuple is the topic number. In front of each word is the probability of that word making up the topic. For example, `0.007*\"business\"` means that the topic is 0.7% business-y.\n",
    "\n",
    "Overall, the topic _appears_ to be about the role of congress in increasing business and trade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics for an Individual Document\n",
    "We can ask the model to give us the topic distribution for any individual document.\n",
    "\n",
    "For example, if we pass in document `10` from the BoW corpus, it gives us two topics for that document: it is 56% topic `0` and 44% topic `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.013316183), (1, 0.9844907)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.get_document_topics(corpus[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Topics with pyLDAvis\n",
    "Understanding the data that underlies a topic model is vital, but fortunately we also have a slightly more human-friendly option to help us interpret the topics!\n",
    "\n",
    "[pyLDAvis](https://github.com/bmabey/pyLDAvis) is a library for creating interactive topic model visualisations. It even has a helper function specifically for Gensim that we can use.\n",
    "\n",
    "> **It will take a while to load this visualisation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mary/digitalhumanities/intro-to-text-mining-with-python/venv/lib/python3.7/site-packages/past/types/oldstr.py:33: DeprecationWarning: invalid escape sequence \\d\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el6590847236420647909592289\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el6590847236420647909592289_data = {\"mdsDat\": {\"x\": [0.08791283079902963, -0.113353416447644, 0.11904788156424777, 0.0004953487834030957, -0.09410264469903647], \"y\": [-0.021614277741628232, 0.005161610141940216, -0.03325230196038329, 0.11756320903120766, -0.0678582394711363], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [47.81563186645508, 31.704442977905273, 15.354429244995117, 3.5857949256896973, 1.5397067070007324]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [74.0, 83.0, 69.0, 53.0, 43.0, 55.0, 39.0, 54.0, 60.0, 41.0, 62.0, 126.0, 36.0, 34.0, 68.0, 95.0, 45.0, 28.0, 52.0, 33.0, 46.0, 32.0, 64.0, 38.0, 36.0, 43.0, 43.0, 66.0, 50.0, 26.0, 14.066899299621582, 14.0635347366333, 24.414154052734375, 17.639713287353516, 11.08863639831543, 16.676637649536133, 11.99372673034668, 10.113275527954102, 32.35131072998047, 9.165133476257324, 9.160539627075195, 9.156189918518066, 13.75788688659668, 17.073326110839844, 16.140695571899414, 10.90867805480957, 9.100363731384277, 10.018001556396484, 9.095900535583496, 8.158427238464355, 10.841882705688477, 21.84269142150879, 8.085376739501953, 7.1777496337890625, 7.175723552703857, 7.175772666931152, 39.00322341918945, 7.170217990875244, 10.782824516296387, 8.915715217590332, 53.4769172668457, 34.49785232543945, 39.68506622314453, 49.192138671875, 13.344167709350586, 28.64387321472168, 22.44987678527832, 22.676677703857422, 78.94161987304688, 103.03433990478516, 15.061914443969727, 32.840213775634766, 42.32734298706055, 26.963830947875977, 15.014805793762207, 51.25935745239258, 50.11690139770508, 44.924068450927734, 27.879358291625977, 28.88946533203125, 54.08714294433594, 27.805965423583984, 32.00110626220703, 47.01995849609375, 43.618202209472656, 31.308515548706055, 48.84956741333008, 38.43128967285156, 37.070213317871094, 41.98316192626953, 42.423946380615234, 37.09382629394531, 46.05637741088867, 44.96804428100586, 37.68266677856445, 36.46070861816406, 35.188411712646484, 38.863677978515625, 40.46257781982422, 43.32356643676758, 36.57637405395508, 36.8702278137207, 35.98420715332031, 36.403255462646484, 37.500999450683594, 19.01590919494629, 17.14284896850586, 17.135326385498047, 15.25029182434082, 59.50729751586914, 14.280272483825684, 11.497773170471191, 11.486366271972656, 10.548447608947754, 10.534144401550293, 18.081562042236328, 9.605891227722168, 9.603790283203125, 9.563644409179688, 8.624432563781738, 7.725804805755615, 7.724480628967285, 7.72473669052124, 8.58580493927002, 7.722568511962891, 7.721014022827148, 16.209163665771484, 7.714580535888672, 7.714256763458252, 7.712033271789551, 14.299925804138184, 21.634443283081055, 6.782942771911621, 9.372501373291016, 29.368227005004883, 74.93492889404297, 43.22523880004883, 60.44999694824219, 25.636632919311523, 59.68830871582031, 28.22005844116211, 22.347618103027344, 28.295854568481445, 36.13936996459961, 22.511783599853516, 22.398637771606445, 40.86003494262695, 45.0671272277832, 26.908023834228516, 43.279388427734375, 36.84941864013672, 42.273223876953125, 23.673311233520508, 44.129337310791016, 32.80446243286133, 38.85916519165039, 38.71924591064453, 26.725645065307617, 28.463069915771484, 31.02353858947754, 39.900089263916016, 30.0234317779541, 32.775360107421875, 25.549196243286133, 28.226137161254883, 27.224365234375, 25.84177017211914, 25.657533645629883, 6.101724147796631, 5.531607627868652, 4.803971290588379, 9.994086265563965, 4.724564075469971, 3.8277087211608887, 3.8588790893554688, 10.057591438293457, 5.801259994506836, 4.68366003036499, 7.6873674392700195, 4.643975257873535, 5.890113830566406, 3.4886724948883057, 6.361156463623047, 7.004619121551514, 5.668247699737549, 3.3979198932647705, 8.360724449157715, 4.50684928894043, 4.937897205352783, 3.6974761486053467, 13.712742805480957, 3.150634527206421, 5.841906547546387, 3.0757641792297363, 5.111120223999023, 3.627652168273926, 8.003352165222168, 5.600730895996094, 17.143949508666992, 11.233403205871582, 7.266579627990723, 32.9470100402832, 27.727895736694336, 14.438007354736328, 8.239053726196289, 8.754002571105957, 21.506004333496094, 18.825119018554688, 22.37795066833496, 11.109708786010742, 8.698556900024414, 9.55057144165039, 15.286798477172852, 17.439010620117188, 18.97212028503418, 16.664491653442383, 14.858448028564453, 17.886167526245117, 14.293292045593262, 16.228687286376953, 13.190605163574219, 12.559774398803711, 11.932515144348145, 17.062685012817383, 17.389650344848633, 12.640374183654785, 14.739130020141602, 12.736140251159668, 16.070775985717773, 13.46258544921875, 13.106322288513184, 14.471120834350586, 13.454999923706055, 13.879231452941895, 12.443649291992188, 4.275540351867676, 3.8010165691375732, 3.76389217376709, 2.895195960998535, 4.4932861328125, 2.2581958770751953, 5.969707489013672, 2.256173610687256, 5.802413463592529, 3.7688307762145996, 5.617830753326416, 1.6289215087890625, 3.232229232788086, 1.557279109954834, 2.295692205429077, 2.2723653316497803, 10.019373893737793, 1.5918277502059937, 2.132795810699463, 2.062000274658203, 1.595849633216858, 2.763627767562866, 1.5962554216384888, 1.5954632759094238, 3.1108956336975098, 1.5037250518798828, 1.4841336011886597, 1.4779667854309082, 1.5974500179290771, 1.4216434955596924, 2.714024543762207, 3.0406670570373535, 5.6806640625, 3.808283805847168, 3.7911245822906494, 3.0742857456207275, 6.681037902832031, 3.2253692150115967, 5.100489139556885, 3.951195001602173, 3.7666478157043457, 4.784633159637451, 4.833425521850586, 5.081671237945557, 4.205533027648926, 4.494004726409912, 5.074409484863281, 4.06714391708374, 5.240567207336426, 4.776521682739258, 3.7872872352600098, 4.1217875480651855, 3.6675477027893066, 3.75618314743042, 3.643162965774536, 2.3702101707458496, 1.7975983619689941, 1.7978229522705078, 1.7991535663604736, 1.7984464168548584, 1.8005527257919312, 1.3167821168899536, 2.9216537475585938, 1.8748317956924438, 1.3653010129928589, 1.2410290241241455, 1.2465832233428955, 1.2382889986038208, 0.677629828453064, 0.674745500087738, 0.6742486953735352, 1.2377440929412842, 0.674354612827301, 0.6735897660255432, 0.6748651266098022, 0.6751749515533447, 1.8052644729614258, 5.172852993011475, 1.244322657585144, 1.2385129928588867, 0.8297145366668701, 0.6756462454795837, 2.3619611263275146, 0.6762580275535583, 0.6756025552749634, 4.089443206787109, 6.978973388671875, 2.990534782409668, 1.7995339632034302, 2.3621826171875, 1.8601014614105225, 2.9743237495422363, 2.372295379638672, 4.088375091552734, 1.8420569896697998, 3.0283360481262207, 2.9903974533081055, 2.9436135292053223, 2.9166605472564697, 1.812380313873291, 1.8044559955596924, 2.379591464996338, 1.7975081205368042, 1.8133293390274048, 1.8410059213638306, 1.839807391166687, 1.817923665046692, 1.8144532442092896, 1.8055822849273682, 1.8001102209091187], \"Term\": [\"there\", \"today\", \"help\", \"democracy\", \"friend\", \"child\", \"word\", \"like\", \"generation\", \"turn\", \"americans\", \"congress\", \"case\", \"fact\", \"century\", \"executive\", \"difference\", \"woman\", \"make\", \"remember\", \"face\", \"challenge\", \"object\", \"bless\", \"moment\", \"problem\", \"economic\", \"authority\", \"constitutional\", \"unity\", \"recommendation\", \"combination\", \"remedy\", \"treasury\", \"obedience\", \"naval\", \"intelligent\", \"feature\", \"attention\", \"please\", \"deliberation\", \"defect\", \"session\", \"earnest\", \"connect\", \"commence\", \"extravagance\", \"preparation\", \"amity\", \"estimate\", \"commission\", \"currency\", \"ignorant\", \"commencement\", \"owe\", \"admission\", \"legislation\", \"observation\", \"arbitration\", \"resolution\", \"ought\", \"consideration\", \"importance\", \"effect\", \"southern\", \"south\", \"court\", \"navy\", \"executive\", \"congress\", \"appointment\", \"expenditure\", \"department\", \"appear\", \"construction\", \"business\", \"proper\", \"promote\", \"tariff\", \"claim\", \"general\", \"method\", \"election\", \"influence\", \"relation\", \"grant\", \"revenue\", \"territory\", \"trade\", \"result\", \"commerce\", \"establish\", \"increase\", \"opinion\", \"regard\", \"protection\", \"favor\", \"object\", \"feel\", \"institution\", \"exist\", \"control\", \"exercise\", \"republic\", \"ideal\", \"vision\", \"goal\", \"answer\", \"journey\", \"americans\", \"dark\", \"role\", \"group\", \"hatred\", \"hero\", \"era\", \"heal\", \"nuclear\", \"heritage\", \"realization\", \"historic\", \"decency\", \"spiritual\", \"reality\", \"renewal\", \"adversary\", \"weapon\", \"compassion\", \"storm\", \"idealism\", \"commitment\", \"strive\", \"quest\", \"ceremony\", \"challenge\", \"today\", \"build\", \"help\", \"woman\", \"century\", \"dream\", \"dignity\", \"courage\", \"problem\", \"unity\", \"endure\", \"task\", \"opportunity\", \"forward\", \"earth\", \"face\", \"child\", \"set\", \"generation\", \"economic\", \"democracy\", \"promise\", \"moment\", \"turn\", \"reach\", \"there\", \"understand\", \"self\", \"million\", \"use\", \"fear\", \"friend\", \"share\", \"extinguish\", \"coordinate\", \"desirable\", \"compromise\", \"infancy\", \"cement\", \"salutary\", \"apprehension\", \"illustrious\", \"occupy\", \"beloved\", \"fervently\", \"accountability\", \"inestimable\", \"contract\", \"council\", \"adherence\", \"auxiliary\", \"confer\", \"confine\", \"bulwark\", \"regret\", \"intercourse\", \"benediction\", \"sacredly\", \"combat\", \"discretion\", \"supplication\", \"art\", \"avail\", \"debt\", \"error\", \"patriot\", \"institution\", \"opinion\", \"population\", \"disturb\", \"strict\", \"object\", \"extend\", \"revenue\", \"source\", \"press\", \"reserve\", \"happiness\", \"exist\", \"authority\", \"protection\", \"reason\", \"federal\", \"desire\", \"experience\", \"pay\", \"safety\", \"discharge\", \"feel\", \"increase\", \"blessing\", \"exercise\", \"period\", \"general\", \"domestic\", \"fear\", \"republic\", \"regard\", \"executive\", \"constitutional\", \"expressly\", \"agreement\", \"plainly\", \"precisely\", \"communism\", \"speech\", \"program\", \"fabric\", \"minority\", \"area\", \"slave\", \"momentous\", \"contract\", \"hostility\", \"rightful\", \"deliver\", \"case\", \"abundance\", \"perpetual\", \"ruler\", \"hunger\", \"frame\", \"addition\", \"atlantic\", \"attack\", \"lawful\", \"alien\", \"association\", \"misery\", \"unimpaired\", \"grave\", \"base\", \"provision\", \"oppose\", \"development\", \"aim\", \"democracy\", \"surrender\", \"benefit\", \"majority\", \"achieve\", \"strengthen\", \"difference\", \"constitutional\", \"section\", \"economic\", \"labor\", \"all\", \"help\", \"authority\", \"international\", \"desire\", \"knowledge\", \"object\", \"trade\", \"door\", \"loyal\", \"your\", \"speaker\", \"engagement\", \"big\", \"generosity\", \"thank\", \"soul\", \"memory\", \"mother\", \"tomorrow\", \"putt\", \"prudent\", \"night\", \"timeless\", \"diversity\", \"town\", \"beautiful\", \"statement\", \"speech\", \"watch\", \"friend\", \"yes\", \"senator\", \"attitude\", \"send\", \"young\", \"intellectual\", \"throw\", \"word\", \"there\", \"fact\", \"hard\", \"woman\", \"washington\", \"turn\", \"remember\", \"today\", \"offer\", \"child\", \"like\", \"democracy\", \"help\", \"expression\", \"idea\", \"generation\", \"unity\", \"challenge\", \"bless\", \"father\", \"congress\", \"make\", \"difference\", \"moment\"], \"Total\": [74.0, 83.0, 69.0, 53.0, 43.0, 55.0, 39.0, 54.0, 60.0, 41.0, 62.0, 126.0, 36.0, 34.0, 68.0, 95.0, 45.0, 28.0, 52.0, 33.0, 46.0, 32.0, 64.0, 38.0, 36.0, 43.0, 43.0, 66.0, 50.0, 26.0, 14.79780387878418, 14.804360389709473, 25.759906768798828, 18.76681137084961, 11.810314178466797, 17.773048400878906, 12.80293083190918, 10.814335823059082, 34.65228271484375, 9.818881034851074, 9.81926441192627, 9.818305015563965, 14.784605979919434, 18.37100601196289, 17.3769474029541, 11.75069808959961, 9.814717292785645, 10.808049201965332, 9.815324783325195, 8.81833267211914, 11.772908210754395, 23.72893524169922, 8.800431251525879, 7.822010040283203, 7.821922302246094, 7.822025299072266, 42.544864654541016, 7.821307182312012, 11.79369831085205, 9.761356353759766, 60.14528274536133, 38.47780990600586, 44.462921142578125, 56.61009979248047, 14.754389762878418, 32.59255599975586, 25.310449600219727, 25.61066436767578, 95.60015869140625, 126.58796691894531, 16.72583770751953, 38.3787956237793, 51.07311248779297, 31.511001586914062, 16.723590850830078, 64.73204803466797, 63.430145263671875, 56.96162796020508, 33.40225601196289, 35.287357330322266, 74.16405487060547, 34.40878677368164, 40.80926513671875, 65.25498962402344, 60.34540557861328, 40.19870376586914, 71.84199523925781, 53.063926696777344, 51.40126419067383, 61.147552490234375, 62.13436508178711, 52.895870208740234, 76.61402130126953, 75.1968002319336, 57.186744689941406, 55.21653366088867, 52.327335357666016, 64.58484649658203, 71.09187316894531, 84.07450103759766, 58.014583587646484, 61.2138557434082, 56.9407958984375, 76.00347137451172, 38.553890228271484, 19.691051483154297, 17.80645179748535, 17.808012008666992, 15.91784381866455, 62.370323181152344, 14.973165512084961, 12.149553298950195, 12.147531509399414, 11.203990936279297, 11.202719688415527, 19.312999725341797, 10.260723114013672, 10.259241104125977, 10.244187355041504, 9.305334091186523, 8.375385284423828, 8.375327110290527, 8.376169204711914, 9.310158729553223, 8.374645233154297, 8.37450885772705, 17.590469360351562, 8.37264633178711, 8.372358322143555, 8.372880935668945, 15.536375999450684, 23.52754783630371, 7.431941032409668, 10.271711349487305, 32.48708724975586, 83.72239685058594, 48.714542388916016, 69.12506866455078, 28.55775260925293, 68.8871078491211, 32.131919860839844, 25.21278190612793, 33.38784408569336, 43.43866729736328, 26.176183700561523, 26.125099182128906, 50.43440628051758, 56.22634506225586, 32.12334060668945, 54.75192642211914, 46.52368927001953, 55.75387954711914, 28.226512908935547, 60.972843170166016, 43.217769622802734, 53.85106658935547, 61.96134567260742, 36.66505432128906, 41.16737747192383, 47.654296875, 74.3917236328125, 49.29557800292969, 59.70962142944336, 37.92164611816406, 52.17051315307617, 49.753780364990234, 43.10007095336914, 45.89591598510742, 7.314029216766357, 7.304811000823975, 6.392317295074463, 13.426641464233398, 6.433376312255859, 5.45111608505249, 5.508457183837891, 14.451539039611816, 8.33968448638916, 7.179993629455566, 12.048554420471191, 7.325350284576416, 9.323955535888672, 5.540406703948975, 10.13327693939209, 11.233650207519531, 9.200867652893066, 5.547078609466553, 13.724483489990234, 7.442152500152588, 8.351985931396484, 6.401989936828613, 23.969730377197266, 5.5307207107543945, 10.301703453063965, 5.4724602699279785, 9.189939498901367, 6.528038024902344, 14.702241897583008, 10.340441703796387, 33.15332794189453, 21.782455444335938, 13.989375114440918, 84.07450103759766, 75.1968002319336, 33.29377746582031, 17.071231842041016, 18.87934684753418, 64.58484649658203, 55.01713943481445, 71.84199523925781, 27.648582458496094, 18.97669792175293, 21.944581985473633, 46.6585807800293, 58.014583587646484, 66.97126770019531, 55.21653366088867, 45.670875549316406, 68.67314147949219, 45.90452575683594, 58.017372131347656, 40.64369583129883, 37.847808837890625, 34.706661224365234, 71.09187316894531, 76.61402130126953, 39.432579040527344, 56.9407958984375, 41.628170013427734, 74.16405487060547, 49.19560241699219, 49.753780364990234, 76.00347137451172, 57.186744689941406, 95.60015869140625, 50.66280746459961, 8.167610168457031, 7.918766021728516, 8.194581031799316, 6.729058265686035, 10.853879928588867, 5.596494674682617, 15.693120002746582, 5.986928462982178, 16.186674118041992, 10.691301345825195, 16.600250244140625, 5.0949015617370605, 10.13327693939209, 5.224374294281006, 7.723519802093506, 7.8072309494018555, 36.34352111816406, 6.058721542358398, 8.89626693725586, 8.729328155517578, 6.99931526184082, 12.587418556213379, 7.277885913848877, 7.2768425941467285, 14.40696907043457, 7.230195045471191, 7.1496477127075195, 7.136292457580566, 7.897291660308838, 7.149621963500977, 13.789987564086914, 15.801054954528809, 31.426254272460938, 20.903690338134766, 21.27124786376953, 17.02640724182129, 53.85106658935547, 19.42001724243164, 40.24477005004883, 26.820852279663086, 26.297060012817383, 42.34709930419922, 45.64519119262695, 50.66280746459961, 35.55176544189453, 43.217769622802734, 58.70652770996094, 33.85362243652344, 69.12506866455078, 66.97126770019531, 33.7203254699707, 45.90452575683594, 37.19181823730469, 64.58484649658203, 51.40126419067383, 7.832761287689209, 6.442061424255371, 7.100473880767822, 7.239563941955566, 8.510710716247559, 9.12547779083252, 6.674975395202637, 16.828020095825195, 11.013760566711426, 8.260019302368164, 7.709674835205078, 8.55557918548584, 8.617509841918945, 5.157869338989258, 5.167454719543457, 5.167852401733398, 9.490313529968262, 5.257493495941162, 5.253429889678955, 5.385674476623535, 5.596494674682617, 14.970759391784668, 43.10007095336914, 10.443680763244629, 10.500894546508789, 7.220186233520508, 5.968588352203369, 20.931825637817383, 6.059322834014893, 6.079239845275879, 39.019927978515625, 74.3917236328125, 34.44559097290039, 19.59207534790039, 28.55775260925293, 20.885019302368164, 41.16737747192383, 33.237762451171875, 83.72239685058594, 25.322341918945312, 55.75387954711914, 54.731597900390625, 53.85106658935547, 69.12506866455078, 25.720447540283203, 25.596797943115234, 60.972843170166016, 26.176183700561523, 32.48708724975586, 38.031341552734375, 39.89012908935547, 126.58796691894531, 52.82659149169922, 45.64519119262695, 36.66505432128906], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6872000098228455, 0.6865000128746033, 0.6841999888420105, 0.6758999824523926, 0.6747999787330627, 0.6740999817848206, 0.6725000143051147, 0.670799970626831, 0.6690999865531921, 0.6689000129699707, 0.66839998960495, 0.6679999828338623, 0.6657999753952026, 0.6646000146865845, 0.6639999747276306, 0.6635000109672546, 0.6621999740600586, 0.661899983882904, 0.6617000102996826, 0.6600000262260437, 0.6553999781608582, 0.6549999713897705, 0.6531000137329102, 0.6518999934196472, 0.6516000032424927, 0.6516000032424927, 0.6509000062942505, 0.6509000062942505, 0.6481999754905701, 0.6471999883651733, 0.6202999949455261, 0.628600001335144, 0.6241000294685364, 0.5974000096321106, 0.6373999714851379, 0.6086999773979187, 0.617900013923645, 0.616100013256073, 0.5464000105857849, 0.5318999886512756, 0.6330000162124634, 0.5820000171661377, 0.550000011920929, 0.5820000171661377, 0.6299999952316284, 0.5044999718666077, 0.5022000074386597, 0.5004000067710876, 0.5570999979972839, 0.5378000140190125, 0.4221000075340271, 0.5248000025749207, 0.49470001459121704, 0.4101000130176544, 0.4131999909877777, 0.4878999888896942, 0.3521000146865845, 0.41519999504089355, 0.41100001335144043, 0.3617999851703644, 0.3562000095844269, 0.3828999996185303, 0.2289000004529953, 0.22370000183582306, 0.3206999897956848, 0.32280001044273376, 0.3409999907016754, 0.22990000247955322, 0.17419999837875366, 0.07479999959468842, 0.27649998664855957, 0.23080000281333923, 0.27889999747276306, 0.0017000000225380063, 1.121000051498413, 1.113800048828125, 1.110700011253357, 1.110200047492981, 1.1059000492095947, 1.101699948310852, 1.1013000011444092, 1.0936000347137451, 1.0927000045776367, 1.0884000062942505, 1.0872000455856323, 1.082800030708313, 1.082800030708313, 1.0827000141143799, 1.0800000429153442, 1.072700023651123, 1.0679999589920044, 1.0678000450134277, 1.0678000450134277, 1.0677000284194946, 1.0677000284194946, 1.0674999952316284, 1.0669000148773193, 1.0669000148773193, 1.0667999982833862, 1.066499948501587, 1.0657999515533447, 1.0648000240325928, 1.0572999715805054, 1.0571000576019287, 1.0477999448776245, 1.0377999544143677, 1.0291999578475952, 1.0146000385284424, 1.0407999753952026, 1.0053999423980713, 1.0189000368118286, 1.0281000137329102, 0.9832000136375427, 0.9646999835968018, 0.9979000091552734, 0.9947999715805054, 0.9381999969482422, 0.9275000095367432, 0.9715999960899353, 0.9136000275611877, 0.9156000018119812, 0.8719000220298767, 0.9728000164031982, 0.8253999948501587, 0.8730000257492065, 0.8223999738693237, 0.6784999966621399, 0.8324999809265137, 0.779699981212616, 0.7195000052452087, 0.5256999731063843, 0.652899980545044, 0.5489000082015991, 0.7537999749183655, 0.5343999862670898, 0.5457000136375427, 0.6371999979019165, 0.5672000050544739, 1.6924999952316284, 1.5957000255584717, 1.5880999565124512, 1.5785000324249268, 1.565000057220459, 1.5202000141143799, 1.517899990081787, 1.511299967765808, 1.5108000040054321, 1.4464999437332153, 1.424399971961975, 1.4179999828338623, 1.4144999980926514, 1.4112000465393066, 1.4082000255584717, 1.4013999700546265, 1.389299988746643, 1.3837000131607056, 1.378100037574768, 1.3722000122070312, 1.3481999635696411, 1.3248000144958496, 1.3152999877929688, 1.3111000061035156, 1.30649995803833, 1.2976000308990479, 1.2870999574661255, 1.2862000465393066, 1.2655999660491943, 1.260599970817566, 1.2143000364303589, 1.2115999460220337, 1.2187999486923218, 0.9369999766349792, 0.8761000037193298, 1.0383000373840332, 1.145300030708313, 1.1052000522613525, 0.7741000056266785, 0.8012999892234802, 0.7074000239372253, 0.9620000123977661, 1.0937000513076782, 1.0418000221252441, 0.7578999996185303, 0.6718000173568726, 0.612500011920929, 0.6758000254631042, 0.7508999705314636, 0.5284000039100647, 0.7070000171661377, 0.5997999906539917, 0.7483999729156494, 0.7706999778747559, 0.8061000108718872, 0.44670000672340393, 0.39089998602867126, 0.7361000180244446, 0.5223000049591064, 0.6894000172615051, 0.34450000524520874, 0.5778999924659729, 0.5397999882698059, 0.2151000052690506, 0.426800012588501, -0.0560000017285347, 0.4697999954223633, 2.6809000968933105, 2.5941998958587646, 2.5501999855041504, 2.484800100326538, 2.4463000297546387, 2.420599937438965, 2.3617000579833984, 2.352299928665161, 2.302299976348877, 2.2855000495910645, 2.2446999549865723, 2.1879000663757324, 2.185499906539917, 2.117799997329712, 2.115000009536743, 2.0940001010894775, 2.0397000312805176, 1.9916000366210938, 1.899999976158142, 1.885200023651123, 1.8497999906539917, 1.812000036239624, 1.8109999895095825, 1.8107000589370728, 1.7954000234603882, 1.7578999996185303, 1.75600004196167, 1.7537000179290771, 1.7301000356674194, 1.7129000425338745, 1.7027000188827515, 1.6801999807357788, 1.6175999641418457, 1.6253999471664429, 1.6035000085830688, 1.6165000200271606, 1.2411999702453613, 1.5328999757766724, 1.2625000476837158, 1.4129999876022339, 1.3848999738693237, 1.1476999521255493, 1.082800030708313, 1.0285999774932861, 1.193600058555603, 1.0647000074386597, 0.879800021648407, 1.2091000080108643, 0.7487000226974487, 0.6876000165939331, 1.141700029373169, 0.917900025844574, 1.0116000175476074, 0.483599990606308, 0.6814000010490417, 2.9781999588012695, 2.897200107574463, 2.799999952316284, 2.7813000679016113, 2.6191999912261963, 2.550600051879883, 2.5504000186920166, 2.4226999282836914, 2.4030001163482666, 2.373500108718872, 2.3469998836517334, 2.2474000453948975, 2.2335000038146973, 2.143899917602539, 2.1377999782562256, 2.13700008392334, 2.1366000175476074, 2.1198999881744385, 2.1196000576019287, 2.09660005569458, 2.0587000846862793, 2.058199882507324, 2.053499937057495, 2.0462000370025635, 2.0360000133514404, 2.009999990463257, 1.9950000047683716, 1.9917999505996704, 1.9808000326156616, 1.9765000343322754, 1.9178999662399292, 1.8071000576019287, 1.729599952697754, 1.7860000133514404, 1.6812000274658203, 1.7552000284194946, 1.5458999872207642, 1.5336999893188477, 1.1541999578475952, 1.5528000593185425, 1.260599970817566, 1.2664999961853027, 1.2669999599456787, 1.0081000328063965, 1.520900011062622, 1.521399974822998, 0.9301000237464905, 1.4951000213623047, 1.2878999710083008, 1.1454999446868896, 1.097100019454956, -0.06970000267028809, 0.802299976348877, 0.9435999989509583, 1.159600019454956], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.888400077819824, -6.888700008392334, -6.337100028991699, -6.662099838256836, -7.126299858093262, -6.718200206756592, -7.047900199890137, -7.218400001525879, -6.055600166320801, -7.316800117492676, -7.317399978637695, -7.317800045013428, -6.910600185394287, -6.694699764251709, -6.750899791717529, -7.1427001953125, -7.32390022277832, -7.22790002822876, -7.324399948120117, -7.433199882507324, -7.148799896240234, -6.448400020599365, -7.442200183868408, -7.561299800872803, -7.561600208282471, -7.561500072479248, -5.868599891662598, -7.562300205230713, -7.154300212860107, -7.344399929046631, -5.552999973297119, -5.991399765014648, -5.85129976272583, -5.636499881744385, -6.941199779510498, -6.177299976348877, -6.421000003814697, -6.410900115966797, -5.16349983215332, -4.897200107574463, -6.820099830627441, -6.040599822998047, -5.786799907684326, -6.237800121307373, -6.823200225830078, -5.595399856567383, -5.6178998947143555, -5.72730016708374, -6.204400062561035, -6.168799877166748, -5.5416998863220215, -6.206999778747559, -6.066500186920166, -5.681700229644775, -5.756800174713135, -6.088399887084961, -5.643499851226807, -5.883399963378906, -5.919400215148926, -5.795000076293945, -5.7845001220703125, -5.918799877166748, -5.702400207519531, -5.72629976272583, -5.90310001373291, -5.935999870300293, -5.971499919891357, -5.872200012207031, -5.831900119781494, -5.763599872589111, -5.9328999519348145, -5.924900054931641, -5.94920015335083, -5.937600135803223, -5.497000217437744, -6.17609977722168, -6.279799938201904, -6.280200004577637, -6.3968000411987305, -5.035299777984619, -6.462500095367432, -6.679200172424316, -6.680200099945068, -6.765399932861328, -6.76669979095459, -6.226500034332275, -6.859000205993652, -6.8592000007629395, -6.863399982452393, -6.966800212860107, -7.0767998695373535, -7.077000141143799, -7.076900005340576, -6.971199989318848, -7.077199935913086, -7.077400207519531, -6.3358001708984375, -7.078199863433838, -7.0782999992370605, -7.07859992980957, -6.461100101470947, -6.047100067138672, -7.206900119781494, -6.883600234985352, -5.741399765014648, -4.804699897766113, -5.354899883270264, -5.019499778747559, -5.877299785614014, -5.032199859619141, -5.781300067901611, -6.014599800109863, -5.778600215911865, -5.533999919891357, -6.007299900054932, -6.012400150299072, -5.411200046539307, -5.313199996948242, -5.82889986038208, -5.353700160980225, -5.514500141143799, -5.377200126647949, -5.956999778747559, -5.334199905395508, -5.630799770355225, -5.461400032043457, -5.465000152587891, -5.835700035095215, -5.772799968719482, -5.686600208282471, -5.434999942779541, -5.719399929046631, -5.631700038909912, -5.880799770355225, -5.781099796295166, -5.817200183868408, -5.8694000244140625, -5.876500129699707, -6.587699890136719, -6.685800075531006, -6.826900005340576, -6.094299793243408, -6.843500137329102, -7.053999900817871, -7.045899868011475, -6.0879998207092285, -6.638199806213379, -6.852200031280518, -6.3566999435424805, -6.8607001304626465, -6.623000144958496, -7.1468000411987305, -6.54610013961792, -6.449699878692627, -6.661399841308594, -7.173099994659424, -6.272799968719482, -6.890699863433838, -6.7993998527526855, -7.088699817657471, -5.7779998779296875, -7.248700141906738, -6.631199836730957, -7.272799968719482, -6.764900207519531, -7.107699871063232, -6.316400051116943, -6.673399925231934, -5.554699897766113, -5.977399826049805, -6.413000106811523, -4.901400089263916, -5.07390022277832, -5.726399898529053, -6.287399768829346, -6.226799964904785, -5.328000068664551, -5.461100101470947, -5.2881999015808105, -5.988500118255615, -6.233099937438965, -6.139699935913086, -5.669300079345703, -5.537600040435791, -5.4532999992370605, -5.583000183105469, -5.697700023651123, -5.51230001449585, -5.736499786376953, -5.609499931335449, -5.816800117492676, -5.865799903869629, -5.916999816894531, -5.5594000816345215, -5.54040002822876, -5.859399795532227, -5.7058000564575195, -5.851900100708008, -5.61929988861084, -5.79640007019043, -5.823200225830078, -5.7241997718811035, -5.796999931335449, -5.765900135040283, -5.875100135803223, -5.488999843597412, -5.606599807739258, -5.616399765014648, -5.878799915313721, -5.439300060272217, -6.127299785614014, -5.155200004577637, -6.128200054168701, -5.183599948883057, -5.615099906921387, -5.21589994430542, -6.453999996185303, -5.768700122833252, -6.498899936676025, -6.110799789428711, -6.121099948883057, -4.637400150299072, -6.4770002365112305, -6.1844000816345215, -6.218200206756592, -6.4745001792907715, -5.925300121307373, -6.4741997718811035, -6.474699974060059, -5.807000160217285, -6.533899784088135, -6.547100067138672, -6.551199913024902, -6.473499774932861, -6.590099811553955, -5.94350004196167, -5.829800128936768, -5.204800128936768, -5.604700088500977, -5.6092000007629395, -5.81879997253418, -5.042600154876709, -5.7708001136779785, -5.3125, -5.56790018081665, -5.615699768066406, -5.376500129699707, -5.366300106048584, -5.316199779510498, -5.505499839782715, -5.4390997886657715, -5.317699909210205, -5.538899898529053, -5.2855000495910645, -5.378200054168701, -5.610199928283691, -5.525599956512451, -5.642399787902832, -5.618500232696533, -5.64900016784668, -5.233500003814697, -5.510000228881836, -5.509900093078613, -5.509200096130371, -5.5096001625061035, -5.508399963378906, -5.821300029754639, -5.0243000984191895, -5.4679999351501465, -5.785099983215332, -5.8805999755859375, -5.876100063323975, -5.882800102233887, -6.485599994659424, -6.4899001121521, -6.490699768066406, -5.883200168609619, -6.490499973297119, -6.491600036621094, -6.489699840545654, -6.489299774169922, -5.505799770355225, -4.453100204467773, -5.877900123596191, -5.882599830627441, -6.283199787139893, -6.48859977722168, -5.236999988555908, -6.48769998550415, -6.48859977722168, -4.6880998611450195, -4.153600215911865, -5.000999927520752, -5.508999824523926, -5.2368998527526855, -5.475900173187256, -5.006499767303467, -5.232600212097168, -4.688300132751465, -5.485599994659424, -4.988500118255615, -5.001100063323975, -5.016900062561035, -5.026100158691406, -5.5019001960754395, -5.506199836730957, -5.229599952697754, -5.5100998878479, -5.501299858093262, -5.486199855804443, -5.486800193786621, -5.498799800872803, -5.500699996948242, -5.5055999755859375, -5.508600234985352]}, \"token.table\": {\"Topic\": [2, 4, 1, 3, 1, 2, 3, 4, 1, 4, 1, 2, 3, 1, 2, 1, 2, 4, 5, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 5, 1, 2, 1, 2, 3, 1, 3, 1, 3, 4, 1, 2, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 1, 2, 4, 1, 3, 1, 2, 5, 1, 2, 3, 4, 1, 3, 1, 3, 1, 2, 4, 5, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 2, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 4, 1, 2, 3, 1, 2, 4, 1, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 2, 2, 4, 5, 1, 2, 3, 5, 1, 2, 3, 2, 3, 1, 1, 1, 1, 2, 3, 4, 1, 2, 5, 2, 4, 2, 2, 3, 5, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 5, 1, 5, 1, 3, 1, 2, 3, 4, 1, 3, 3, 4, 1, 2, 3, 4, 2, 3, 1, 3, 1, 2, 4, 5, 1, 2, 4, 1, 2, 2, 1, 2, 3, 2, 1, 1, 1, 2, 4, 1, 2, 4, 5, 1, 3, 1, 3, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 1, 3, 4, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 1, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 5, 2, 5, 1, 2, 3, 1, 2, 3, 4, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 1, 3, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 5, 2, 1, 2, 3, 1, 2, 4, 2, 1, 2, 3, 4, 1, 2, 5, 2, 2, 2, 4, 5, 2, 2, 2, 1, 2, 4, 2, 4, 1, 2, 5, 2, 2, 1, 1, 3, 1, 2, 3, 1, 2, 3, 4, 1, 3, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 5, 1, 1, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 1, 3, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 5, 2, 4, 1, 2, 5, 1, 3, 1, 3, 2, 5, 2, 1, 1, 3, 4, 1, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 2, 3, 4, 1, 1, 2, 3, 1, 2, 4, 1, 1, 2, 3, 1, 2, 4, 5, 2, 4, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 3, 4, 1, 2, 4, 5, 1, 2, 5, 2, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 1, 1, 2, 3, 2, 3, 1, 2, 3, 4, 1, 2, 1, 2, 3, 5, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 5, 1, 3, 1, 3, 4, 1, 2, 3, 4, 1, 2, 5, 1, 2, 4, 5, 1, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 5, 1, 2, 3, 1, 2, 1, 2, 2, 5, 1, 4, 5, 2, 1, 5, 2, 1, 2, 3, 4, 1, 3, 4, 1, 2, 1, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 5, 1, 2, 4, 5, 2, 3, 5, 2, 5, 1, 2, 4, 5, 2, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 5, 1, 2, 3, 4, 1, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 5, 1, 2, 3, 5, 2, 4, 2, 5, 1, 2, 3, 5, 2, 5, 2, 3, 5, 1, 2, 4, 5], \"Freq\": [0.6602053046226501, 0.3301026523113251, 0.3217518627643585, 0.643503725528717, 0.11408119648694992, 0.6844871640205383, 0.03802706301212311, 0.15210825204849243, 0.6870126724243164, 0.27480506896972656, 0.10868540406227112, 0.32605621218681335, 0.6521124243736267, 0.8949089050292969, 0.9552798867225647, 0.12628230452537537, 0.25256460905075073, 0.5051292181015015, 0.12628230452537537, 0.17619688808918, 0.4698583781719208, 0.17619688808918, 0.17619688808918, 0.2797340750694275, 0.41960108280181885, 0.13986703753471375, 0.23631149530410767, 0.3544672429561615, 0.2658504247665405, 0.11815574765205383, 0.016033265739679337, 0.9619959592819214, 0.016033265739679337, 0.9169334769248962, 0.9546265006065369, 0.8568435907363892, 0.06346989423036575, 0.06346989423036575, 0.896816074848175, 0.05978773906826973, 0.1383935660123825, 0.6919678449630737, 0.06919678300619125, 0.9327014684677124, 0.08479104191064835, 0.5612038969993591, 0.37413594126701355, 0.09353398531675339, 0.20405051112174988, 0.20405051112174988, 0.5441346764564514, 0.06801683455705643, 0.42038634419441223, 0.14012879133224487, 0.28025758266448975, 0.14012879133224487, 0.6871111989021301, 0.2748444676399231, 0.4164651036262512, 0.34705427289009094, 0.2082325518131256, 0.923460066318512, 0.057716254144907, 0.6925029158592224, 0.13850058615207672, 0.13850058615207672, 0.5226121544837952, 0.11945421248674393, 0.2837037444114685, 0.07465888559818268, 0.3605501353740692, 0.5408252477645874, 0.3868306577205658, 0.5802460312843323, 0.1898607462644577, 0.5695822238922119, 0.1898607462644577, 0.0632869154214859, 0.3807036578655243, 0.3807036578655243, 0.19035182893276215, 0.1659950166940689, 0.1659950166940689, 0.6639800667762756, 0.18080826103687286, 0.18080826103687286, 0.5424247980117798, 0.6460466980934143, 0.07454384863376617, 0.14908769726753235, 0.12423974275588989, 0.7670831084251404, 0.2191666066646576, 0.3418233394622803, 0.5521761775016785, 0.05258820578455925, 0.05258820578455925, 0.532554566860199, 0.12679870426654816, 0.32967662811279297, 0.08211100101470947, 0.8826932907104492, 0.041055500507354736, 0.23946399986743927, 0.11973199993371964, 0.5986599922180176, 0.7878631949424744, 0.18537957966327667, 0.015448298305273056, 0.6053348779678345, 0.11006088554859161, 0.27515220642089844, 0.027515221387147903, 0.1834486722946167, 0.7337946891784668, 0.07258252054452896, 0.8709902763366699, 0.029033008962869644, 0.014516504481434822, 0.014516504481434822, 0.8761928677558899, 0.8926623463630676, 0.0307814609259367, 0.0615629218518734, 0.12555180490016937, 0.7533107995986938, 0.05380791425704956, 0.05380791425704956, 0.8218240737915039, 0.08501628786325455, 0.08501628786325455, 0.36546632647514343, 0.548199474811554, 0.9456673264503479, 0.9361146092414856, 0.8949106335639954, 0.6759544610977173, 0.14484737813472748, 0.16094152629375458, 0.016094153746962547, 0.9343485832214355, 0.9011110663414001, 0.06436507403850555, 0.5527977347373962, 0.36853182315826416, 0.9554924368858337, 0.14895758032798767, 0.744787871837616, 0.07447879016399384, 0.14572496712207794, 0.14572496712207794, 0.5828998684883118, 0.07286248356103897, 0.2687394618988037, 0.6718486547470093, 0.8136634230613708, 0.08689609169960022, 0.07109680771827698, 0.007899644784629345, 0.01579928956925869, 0.9207600951194763, 0.05754750594496727, 0.8836261630058289, 0.07796701788902283, 0.5724120140075684, 0.07895338535308838, 0.23686014115810394, 0.09869172424077988, 0.8969365358352661, 0.059795770794153214, 0.5921085476875305, 0.29605427384376526, 0.604438304901123, 0.22870638966560364, 0.11435319483280182, 0.04900851100683212, 0.1368960738182068, 0.8213765025138855, 0.3560730516910553, 0.623127818107605, 0.08985306322574615, 0.8386285901069641, 0.029951021075248718, 0.029951021075248718, 0.8692061901092529, 0.039509374648332596, 0.039509374648332596, 0.927138090133667, 0.04214264079928398, 0.9350060224533081, 0.3921175003051758, 0.09048864990472794, 0.5127690434455872, 0.9551865458488464, 0.9166551828384399, 0.9165655970573425, 0.1280863881111145, 0.512345552444458, 0.256172776222229, 0.09284867346286774, 0.7242196202278137, 0.12998813390731812, 0.05570920184254646, 0.8223505020141602, 0.15663819015026093, 0.15643778443336487, 0.7821889519691467, 0.5228242874145508, 0.06535303592681885, 0.3049808144569397, 0.0871373787522316, 0.7051772475242615, 0.09402363002300262, 0.18804726004600525, 0.5038865804672241, 0.21908113360404968, 0.1314486712217331, 0.10954056680202484, 0.043816227465867996, 0.07932484149932861, 0.8725733160972595, 0.03966242074966431, 0.6050711870193481, 0.028812913224101067, 0.3457549512386322, 0.32644394040107727, 0.544073224067688, 0.10881464183330536, 0.46862465143203735, 0.05857808142900467, 0.46862465143203735, 0.10537059605121613, 0.4214823842048645, 0.31611180305480957, 0.10537059605121613, 0.5894835591316223, 0.12196212261915207, 0.2642512619495392, 0.12766890227794647, 0.3830066919326782, 0.12766890227794647, 0.25533780455589294, 0.09336510300636292, 0.8714076280593872, 0.9253712296485901, 0.05443359911441803, 0.07305678725242615, 0.7853605151176453, 0.09132098406553268, 0.036528393626213074, 0.018264196813106537, 0.13883177936077118, 0.7635747790336609, 0.09255452454090118, 0.8655699491500854, 0.017664693295955658, 0.07065877318382263, 0.017664693295955658, 0.017664693295955658, 0.784135639667511, 0.09801695495843887, 0.09801695495843887, 0.02450423873960972, 0.038277365267276764, 0.84210205078125, 0.038277365267276764, 0.038277365267276764, 0.7049940228462219, 0.23499800264835358, 0.9320147037506104, 0.05177859589457512, 0.413176566362381, 0.09181701391935349, 0.5049935579299927, 0.6994875073432922, 0.13233546912670135, 0.11343040317296982, 0.05671520158648491, 0.9072009921073914, 0.826358437538147, 0.010460233315825462, 0.14644327759742737, 0.010460233315825462, 0.6322356462478638, 0.05268630385398865, 0.26343151926994324, 0.05268630385398865, 0.017562100663781166, 0.6377706527709961, 0.2930297553539276, 0.0689481794834137, 0.8598498106002808, 0.02605605497956276, 0.1302802711725235, 0.6032676100730896, 0.06894486397504807, 0.27577945590019226, 0.03447243198752403, 0.017236215993762016, 0.5831936001777649, 0.2721570134162903, 0.038879573345184326, 0.038879573345184326, 0.07775914669036865, 0.244869664311409, 0.1224348321557045, 0.489739328622818, 0.4544038474559784, 0.18176153302192688, 0.34534692764282227, 0.036352306604385376, 0.13672354817390442, 0.8203412890434265, 0.9169902205467224, 0.5010916590690613, 0.16703055799007416, 0.3340611159801483, 0.085977703332901, 0.7952937483787537, 0.02149442583322525, 0.06448327749967575, 0.02149442583322525, 0.4935319721698761, 0.3193442225456238, 0.08709387481212616, 0.029031291604042053, 0.08709387481212616, 0.3509640097618103, 0.4011017382144928, 0.2005508691072464, 0.0501377172768116, 0.6688664555549622, 0.09555235505104065, 0.21021518111228943, 0.01911047101020813, 0.1205938532948494, 0.542672336101532, 0.2612866759300232, 0.0401979498565197, 0.02009897492825985, 0.9246984720230103, 0.5096606612205505, 0.20386427640914917, 0.26211121678352356, 0.014561734162271023, 0.014561734162271023, 0.5626522302627563, 0.18286196887493134, 0.23912718892097473, 0.014066305011510849, 0.2730244994163513, 0.6825612187385559, 0.12452004849910736, 0.840510368347168, 0.03113001212477684, 0.4766664505004883, 0.07944440841674805, 0.1588888168334961, 0.23833322525024414, 0.09280727058649063, 0.6032472848892212, 0.13921090960502625, 0.046403635293245316, 0.11600908637046814, 0.7281154990196228, 0.0539344847202301, 0.2157379388809204, 0.14760670065879822, 0.721632719039917, 0.08200372010469437, 0.03280148655176163, 0.14981327950954437, 0.5992531180381775, 0.14981327950954437, 0.9547101259231567, 0.771169126033783, 0.1243821233510971, 0.09950569272041321, 0.7251638174057007, 0.07251638174057007, 0.2175491452217102, 0.9055337905883789, 0.45007798075675964, 0.19289056956768036, 0.3214842677116394, 0.021432284265756607, 0.10208208858966827, 0.8166567087173462, 0.10208208858966827, 0.9817929863929749, 0.9745901823043823, 0.8679919242858887, 0.07233265787363052, 0.043399594724178314, 0.9761633276939392, 0.9819044470787048, 0.9551799297332764, 0.3828209638595581, 0.19141048192977905, 0.3828209638595581, 0.7143555879592896, 0.28574222326278687, 0.35160648822784424, 0.5469434261322021, 0.07813477516174316, 0.985633373260498, 0.9554656147956848, 0.9090463519096375, 0.23981723189353943, 0.7194516658782959, 0.8996260166168213, 0.022490650415420532, 0.0674719512462616, 0.6004123091697693, 0.1305244117975235, 0.22189149260520935, 0.03915732353925705, 0.36098432540893555, 0.5414764881134033, 0.1554393768310547, 0.7771968841552734, 0.7202514410018921, 0.13792048394680023, 0.13792048394680023, 0.015324498526751995, 0.5114511251449585, 0.07136527448892593, 0.39250901341438293, 0.02378842607140541, 0.4951048195362091, 0.1650349497795105, 0.1650349497795105, 0.1650349497795105, 0.9372853636741638, 0.3337542712688446, 0.5840699672698975, 0.08343856781721115, 0.5338026881217957, 0.32621273398399353, 0.029655704274773598, 0.11862281709909439, 0.9423387050628662, 0.34953925013542175, 0.48397740721702576, 0.08066289871931076, 0.10755053907632828, 0.5791519284248352, 0.2555082142353058, 0.06813552230596542, 0.08516940474510193, 0.5532354116439819, 0.13830885291099548, 0.27661770582199097, 0.9166793823242188, 0.07051379978656769, 0.47504550218582153, 0.38369059562683105, 0.07308392226696014, 0.018270980566740036, 0.054812945425510406, 0.46568945050239563, 0.1552298218011856, 0.3104596436023712, 0.48469749093055725, 0.07456884533166885, 0.2609909474849701, 0.1491376906633377, 0.03728442266583443, 0.5111062526702881, 0.416456937789917, 0.01892985962331295, 0.01892985962331295, 0.0378597192466259, 0.3631952702999115, 0.24213019013404846, 0.12106509506702423, 0.12106509506702423, 0.8137456178665161, 0.14531171321868896, 0.029062343761324883, 0.02637016400694847, 0.6856242418289185, 0.2637016475200653, 0.05274032801389694, 0.18533764779567719, 0.18533764779567719, 0.2471168488264084, 0.37067529559135437, 0.5065027475357056, 0.2532513737678528, 0.2532513737678528, 0.13636963069438934, 0.7363960146903992, 0.08182177692651749, 0.05454785376787186, 0.5888239145278931, 0.3925493061542511, 0.25941431522369385, 0.5188286304473877, 0.12970715761184692, 0.9565044641494751, 0.0562649667263031, 0.8980633616447449, 0.07809247076511383, 0.7740755081176758, 0.19351887702941895, 0.9747309684753418, 0.9313892722129822, 0.6038568019866943, 0.3406371772289276, 0.061934031546115875, 0.8949910402297974, 0.13927589356899261, 0.6963794231414795, 0.13927589356899261, 0.31592655181884766, 0.4738898277282715, 0.07898163795471191, 0.03949081897735596, 0.07898163795471191, 0.5984297394752502, 0.026596875861287117, 0.37235626578330994, 0.12449680268764496, 0.8003365397453308, 0.01778525672852993, 0.03557051345705986, 0.43054598569869995, 0.2870306670665741, 0.14351533353328705, 0.19135376811027527, 0.8811995983123779, 0.049879223108291626, 0.033252816647291183, 0.016626408323645592, 0.8949206471443176, 0.3574140965938568, 0.0714828222990036, 0.500379741191864, 0.0714828222990036, 0.34445685148239136, 0.29524874687194824, 0.3198527991771698, 0.024604061618447304, 0.5044660568237305, 0.14413316547870636, 0.3122885227203369, 0.048044390976428986, 0.4496268033981323, 0.22481340169906616, 0.22481340169906616, 0.24406373500823975, 0.24406373500823975, 0.4881274700164795, 0.9166013598442078, 0.4204989969730377, 0.1501782089471817, 0.4204989969730377, 0.2972184121608734, 0.1486092060804367, 0.4458276033401489, 0.9252363443374634, 0.4742658734321594, 0.05269620567560196, 0.4742658734321594, 0.11510481685400009, 0.828754723072052, 0.023020964115858078, 0.023020964115858078, 0.5734997391700745, 0.3823331594467163, 0.06372219324111938, 0.3389209806919098, 0.6294246912002563, 0.016139093786478043, 0.016139093786478043, 0.7900055050849915, 0.12288974970579147, 0.08777838945388794, 0.7882687449455261, 0.04729612544178963, 0.14188836514949799, 0.015765374526381493, 0.651978611946106, 0.036221034824848175, 0.3078787922859192, 0.7000516057014465, 0.12728211283683777, 0.19092316925525665, 0.38775700330734253, 0.19387850165367126, 0.19387850165367126, 0.19387850165367126, 0.11604280024766922, 0.6962568163871765, 0.11604280024766922, 0.941880464553833, 0.2098446637392044, 0.6505184769630432, 0.1049223318696022, 0.0209844671189785, 0.0209844671189785, 0.9666860103607178, 0.967187225818634, 0.4817074239253998, 0.15327054262161255, 0.32843688130378723, 0.021895792335271835, 0.9460863471031189, 0.6644896268844604, 0.0874328464269638, 0.2273254096508026, 0.3124028742313385, 0.624805748462677, 0.7291358709335327, 0.11599888652563095, 0.13257016241550446, 0.016571270301938057, 0.9316803812980652, 0.038820017129182816, 0.09025878459215164, 0.6618977189064026, 0.18051756918430328, 0.06017252057790756, 0.9552643299102783, 0.4736625850200653, 0.32893234491348267, 0.18420211970806122, 0.5012626647949219, 0.04556933417916298, 0.4556933343410492, 0.9220030307769775, 0.686863124370575, 0.11447718739509583, 0.19624660909175873, 0.01635388471186161, 0.6820523142814636, 0.30622756481170654, 0.12947463989257812, 0.12947463989257812, 0.38842394948005676, 0.25894927978515625, 0.9053831100463867, 0.11455634981393814, 0.45822539925575256, 0.22911269962787628, 0.22911269962787628, 0.3882853090763092, 0.0970713272690773, 0.5824279189109802, 0.4491673409938812, 0.21137286722660065, 0.3434809148311615, 0.02642160840332508, 0.18153902888298035, 0.7261561155319214, 0.6188159584999084, 0.22502398490905762, 0.11251199245452881, 0.35170212388038635, 0.5526747703552246, 0.050243157893419266, 0.03349544107913971, 0.09522998332977295, 0.7618398666381836, 0.09522998332977295, 0.3350875973701477, 0.502631425857544, 0.16754379868507385, 0.16754379868507385, 0.9469308853149414, 0.07085537165403366, 0.8502644300460815, 0.07085537165403366, 0.348614901304245, 0.5664992332458496, 0.043576862663030624, 0.021788431331515312, 0.021788431331515312, 0.481920450925827, 0.18072016537189484, 0.3614403307437897, 0.09079550951719284, 0.7263640761375427, 0.18159101903438568, 0.43401864171028137, 0.14467288553714752, 0.3978504240512848, 0.8897737264633179, 0.09204556047916412, 0.8810936808586121, 0.06777644157409668, 0.6906493306159973, 0.27625972032546997, 0.35736656188964844, 0.35736656188964844, 0.17868328094482422, 0.9550905227661133, 0.742711067199707, 0.18567776679992676, 0.955525279045105, 0.2833724319934845, 0.4014442563056946, 0.1889149397611618, 0.11807183921337128, 0.4767113924026489, 0.4767113924026489, 0.05296793580055237, 0.042503368109464645, 0.9350740909576416, 0.3063707649707794, 0.6127415299415588, 0.6179191470146179, 0.15447978675365448, 0.05149326100945473, 0.15447978675365448, 0.8382667303085327, 0.029938098043203354, 0.11975239217281342, 0.059483204036951065, 0.8129370808601379, 0.09913866966962814, 0.03965546935796738, 0.7161173820495605, 0.018845194950699806, 0.20729713141918182, 0.03769038990139961, 0.7130963802337646, 0.05942469835281372, 0.17827409505844116, 0.3360588848590851, 0.5376942157745361, 0.026884710416197777, 0.09409648925065994, 0.4934827387332916, 0.16449424624443054, 0.16449424624443054, 0.7740159034729004, 0.1935039758682251, 0.03583270683884621, 0.8958176374435425, 0.023888470605015755, 0.04777694121003151, 0.8181795477867126, 0.1168827936053276, 0.3804094195365906, 0.3804094195365906, 0.1902047097682953, 0.7198266386985779, 0.13618342578411102, 0.058364324271678925, 0.0778190940618515, 0.019454773515462875, 0.9591400027275085, 0.05328555777668953, 0.17003755271434784, 0.6801502108573914, 0.048582155257463455, 0.07287323474884033, 0.2434295415878296, 0.608573853969574, 0.14200057089328766, 0.020285794511437416, 0.4196026027202606, 0.2797350585460663, 0.13986752927303314, 0.038202665746212006, 0.8786613345146179, 0.07640533149242401, 0.3258545696735382, 0.5367016196250916, 0.057503748685121536, 0.038335829973220825, 0.019167914986610413, 0.964905321598053, 0.43093088269233704, 0.43093088269233704, 0.04788121208548546, 0.09576242417097092, 0.3339844048023224, 0.4007812738418579, 0.13359375298023224, 0.13359375298023224, 0.9095834493637085, 0.05684896558523178, 0.9104357957839966, 0.07003352046012878, 0.20502343773841858, 0.640698254108429, 0.051255859434604645, 0.10251171886920929, 0.8617651462554932, 0.09575168043375015, 0.7643862366676331, 0.09554827958345413, 0.09554827958345413, 0.14083567261695862, 0.42250701785087585, 0.14083567261695862, 0.28167134523391724], \"Term\": [\"abundance\", \"abundance\", \"accountability\", \"accountability\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"addition\", \"addition\", \"adherence\", \"adherence\", \"adherence\", \"admission\", \"adversary\", \"agreement\", \"agreement\", \"agreement\", \"agreement\", \"aim\", \"aim\", \"aim\", \"aim\", \"alien\", \"alien\", \"alien\", \"all\", \"all\", \"all\", \"all\", \"americans\", \"americans\", \"americans\", \"amity\", \"answer\", \"appear\", \"appear\", \"appear\", \"appointment\", \"appointment\", \"apprehension\", \"apprehension\", \"apprehension\", \"arbitration\", \"arbitration\", \"area\", \"area\", \"area\", \"art\", \"art\", \"art\", \"art\", \"association\", \"association\", \"association\", \"association\", \"atlantic\", \"atlantic\", \"attack\", \"attack\", \"attack\", \"attention\", \"attention\", \"attitude\", \"attitude\", \"attitude\", \"authority\", \"authority\", \"authority\", \"authority\", \"auxiliary\", \"auxiliary\", \"avail\", \"avail\", \"base\", \"base\", \"base\", \"base\", \"beautiful\", \"beautiful\", \"beautiful\", \"beloved\", \"beloved\", \"beloved\", \"benediction\", \"benediction\", \"benediction\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"big\", \"big\", \"bless\", \"bless\", \"bless\", \"bless\", \"blessing\", \"blessing\", \"blessing\", \"build\", \"build\", \"build\", \"bulwark\", \"bulwark\", \"bulwark\", \"business\", \"business\", \"business\", \"case\", \"case\", \"case\", \"case\", \"cement\", \"cement\", \"century\", \"century\", \"century\", \"century\", \"century\", \"ceremony\", \"challenge\", \"challenge\", \"challenge\", \"child\", \"child\", \"child\", \"child\", \"claim\", \"claim\", \"claim\", \"combat\", \"combat\", \"combination\", \"commence\", \"commencement\", \"commerce\", \"commerce\", \"commerce\", \"commerce\", \"commission\", \"commitment\", \"commitment\", \"communism\", \"communism\", \"compassion\", \"compromise\", \"compromise\", \"compromise\", \"confer\", \"confer\", \"confer\", \"confer\", \"confine\", \"confine\", \"congress\", \"congress\", \"congress\", \"congress\", \"congress\", \"connect\", \"connect\", \"consideration\", \"consideration\", \"constitutional\", \"constitutional\", \"constitutional\", \"constitutional\", \"construction\", \"construction\", \"contract\", \"contract\", \"control\", \"control\", \"control\", \"control\", \"coordinate\", \"coordinate\", \"council\", \"council\", \"courage\", \"courage\", \"courage\", \"courage\", \"court\", \"court\", \"court\", \"currency\", \"currency\", \"dark\", \"debt\", \"debt\", \"debt\", \"decency\", \"defect\", \"deliberation\", \"deliver\", \"deliver\", \"deliver\", \"democracy\", \"democracy\", \"democracy\", \"democracy\", \"department\", \"department\", \"desirable\", \"desirable\", \"desire\", \"desire\", \"desire\", \"desire\", \"development\", \"development\", \"development\", \"difference\", \"difference\", \"difference\", \"difference\", \"difference\", \"dignity\", \"dignity\", \"dignity\", \"discharge\", \"discharge\", \"discharge\", \"discretion\", \"discretion\", \"discretion\", \"disturb\", \"disturb\", \"disturb\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"domestic\", \"domestic\", \"domestic\", \"door\", \"door\", \"door\", \"door\", \"dream\", \"dream\", \"earnest\", \"earnest\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"economic\", \"economic\", \"economic\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"election\", \"election\", \"election\", \"election\", \"endure\", \"endure\", \"endure\", \"endure\", \"engagement\", \"engagement\", \"era\", \"era\", \"error\", \"error\", \"error\", \"establish\", \"establish\", \"establish\", \"establish\", \"estimate\", \"executive\", \"executive\", \"executive\", \"executive\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"exist\", \"exist\", \"exist\", \"expenditure\", \"expenditure\", \"expenditure\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"expression\", \"expression\", \"expression\", \"expression\", \"expression\", \"expressly\", \"expressly\", \"expressly\", \"extend\", \"extend\", \"extend\", \"extend\", \"extinguish\", \"extinguish\", \"extravagance\", \"fabric\", \"fabric\", \"fabric\", \"face\", \"face\", \"face\", \"face\", \"face\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"father\", \"father\", \"father\", \"father\", \"favor\", \"favor\", \"favor\", \"favor\", \"fear\", \"fear\", \"fear\", \"fear\", \"fear\", \"feature\", \"federal\", \"federal\", \"federal\", \"federal\", \"federal\", \"feel\", \"feel\", \"feel\", \"feel\", \"fervently\", \"fervently\", \"forward\", \"forward\", \"forward\", \"frame\", \"frame\", \"frame\", \"frame\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"general\", \"general\", \"general\", \"generation\", \"generation\", \"generation\", \"generation\", \"generosity\", \"generosity\", \"generosity\", \"goal\", \"grant\", \"grant\", \"grant\", \"grave\", \"grave\", \"grave\", \"group\", \"happiness\", \"happiness\", \"happiness\", \"happiness\", \"hard\", \"hard\", \"hard\", \"hatred\", \"heal\", \"help\", \"help\", \"help\", \"heritage\", \"hero\", \"historic\", \"hostility\", \"hostility\", \"hostility\", \"hunger\", \"hunger\", \"idea\", \"idea\", \"idea\", \"ideal\", \"idealism\", \"ignorant\", \"illustrious\", \"illustrious\", \"importance\", \"importance\", \"importance\", \"increase\", \"increase\", \"increase\", \"increase\", \"inestimable\", \"inestimable\", \"infancy\", \"infancy\", \"influence\", \"influence\", \"influence\", \"influence\", \"institution\", \"institution\", \"institution\", \"institution\", \"intellectual\", \"intellectual\", \"intellectual\", \"intellectual\", \"intelligent\", \"intercourse\", \"intercourse\", \"intercourse\", \"international\", \"international\", \"international\", \"international\", \"journey\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"labor\", \"labor\", \"labor\", \"labor\", \"lawful\", \"lawful\", \"lawful\", \"legislation\", \"legislation\", \"like\", \"like\", \"like\", \"like\", \"like\", \"loyal\", \"loyal\", \"loyal\", \"majority\", \"majority\", \"majority\", \"majority\", \"majority\", \"make\", \"make\", \"make\", \"make\", \"make\", \"memory\", \"memory\", \"memory\", \"memory\", \"method\", \"method\", \"method\", \"million\", \"million\", \"million\", \"million\", \"minority\", \"minority\", \"minority\", \"minority\", \"misery\", \"misery\", \"misery\", \"moment\", \"moment\", \"moment\", \"moment\", \"momentous\", \"momentous\", \"mother\", \"mother\", \"mother\", \"naval\", \"naval\", \"navy\", \"navy\", \"night\", \"night\", \"nuclear\", \"obedience\", \"object\", \"object\", \"object\", \"observation\", \"occupy\", \"occupy\", \"occupy\", \"offer\", \"offer\", \"offer\", \"offer\", \"offer\", \"opinion\", \"opinion\", \"opinion\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"oppose\", \"oppose\", \"oppose\", \"oppose\", \"ought\", \"ought\", \"ought\", \"ought\", \"owe\", \"patriot\", \"patriot\", \"patriot\", \"patriot\", \"pay\", \"pay\", \"pay\", \"pay\", \"period\", \"period\", \"period\", \"period\", \"perpetual\", \"perpetual\", \"perpetual\", \"plainly\", \"plainly\", \"plainly\", \"please\", \"population\", \"population\", \"population\", \"precisely\", \"precisely\", \"precisely\", \"preparation\", \"press\", \"press\", \"press\", \"problem\", \"problem\", \"problem\", \"problem\", \"program\", \"program\", \"program\", \"promise\", \"promise\", \"promise\", \"promise\", \"promote\", \"promote\", \"promote\", \"proper\", \"proper\", \"proper\", \"proper\", \"protection\", \"protection\", \"protection\", \"provision\", \"provision\", \"provision\", \"prudent\", \"prudent\", \"prudent\", \"prudent\", \"putt\", \"putt\", \"putt\", \"quest\", \"reach\", \"reach\", \"reach\", \"reach\", \"reach\", \"reality\", \"realization\", \"reason\", \"reason\", \"reason\", \"reason\", \"recommendation\", \"regard\", \"regard\", \"regard\", \"regret\", \"regret\", \"relation\", \"relation\", \"relation\", \"relation\", \"remedy\", \"remedy\", \"remember\", \"remember\", \"remember\", \"remember\", \"renewal\", \"republic\", \"republic\", \"republic\", \"reserve\", \"reserve\", \"reserve\", \"resolution\", \"result\", \"result\", \"result\", \"result\", \"revenue\", \"revenue\", \"rightful\", \"rightful\", \"rightful\", \"rightful\", \"role\", \"ruler\", \"ruler\", \"ruler\", \"ruler\", \"sacredly\", \"sacredly\", \"sacredly\", \"safety\", \"safety\", \"safety\", \"safety\", \"salutary\", \"salutary\", \"section\", \"section\", \"section\", \"self\", \"self\", \"self\", \"self\", \"senator\", \"senator\", \"senator\", \"send\", \"send\", \"send\", \"send\", \"session\", \"set\", \"set\", \"set\", \"share\", \"share\", \"share\", \"share\", \"share\", \"slave\", \"slave\", \"slave\", \"soul\", \"soul\", \"soul\", \"source\", \"source\", \"source\", \"south\", \"south\", \"southern\", \"southern\", \"speaker\", \"speaker\", \"speech\", \"speech\", \"speech\", \"spiritual\", \"statement\", \"statement\", \"storm\", \"strengthen\", \"strengthen\", \"strengthen\", \"strengthen\", \"strict\", \"strict\", \"strict\", \"strive\", \"strive\", \"supplication\", \"supplication\", \"surrender\", \"surrender\", \"surrender\", \"surrender\", \"tariff\", \"tariff\", \"tariff\", \"task\", \"task\", \"task\", \"task\", \"territory\", \"territory\", \"territory\", \"territory\", \"thank\", \"thank\", \"thank\", \"there\", \"there\", \"there\", \"there\", \"throw\", \"throw\", \"throw\", \"timeless\", \"timeless\", \"today\", \"today\", \"today\", \"today\", \"tomorrow\", \"tomorrow\", \"town\", \"town\", \"town\", \"trade\", \"trade\", \"trade\", \"trade\", \"trade\", \"treasury\", \"treasury\", \"turn\", \"turn\", \"turn\", \"turn\", \"understand\", \"understand\", \"understand\", \"understand\", \"unimpaired\", \"unimpaired\", \"unimpaired\", \"unity\", \"unity\", \"unity\", \"use\", \"use\", \"use\", \"use\", \"use\", \"vision\", \"washington\", \"washington\", \"washington\", \"washington\", \"watch\", \"watch\", \"watch\", \"watch\", \"weapon\", \"weapon\", \"woman\", \"woman\", \"word\", \"word\", \"word\", \"word\", \"yes\", \"yes\", \"young\", \"young\", \"young\", \"your\", \"your\", \"your\", \"your\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 5, 2, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el6590847236420647909592289\", ldavis_el6590847236420647909592289_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el6590847236420647909592289\", ldavis_el6590847236420647909592289_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el6590847236420647909592289\", ldavis_el6590847236420647909592289_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.087913 -0.021614       1        1  47.815632\n",
       "4     -0.113353  0.005162       2        1  31.704443\n",
       "1      0.119048 -0.033252       3        1  15.354429\n",
       "3      0.000495  0.117563       4        1   3.585795\n",
       "2     -0.094103 -0.067858       5        1   1.539707, topic_info=     Category        Freq            Term       Total  loglift  logprob\n",
       "494   Default   74.000000           there   74.000000  30.0000  30.0000\n",
       "1578  Default   83.000000           today   83.000000  29.0000  29.0000\n",
       "1564  Default   69.000000            help   69.000000  28.0000  28.0000\n",
       "1207  Default   53.000000       democracy   53.000000  27.0000  27.0000\n",
       "369   Default   43.000000          friend   43.000000  26.0000  26.0000\n",
       "694   Default   55.000000           child   55.000000  25.0000  25.0000\n",
       "842   Default   39.000000            word   39.000000  24.0000  24.0000\n",
       "407   Default   54.000000            like   54.000000  23.0000  23.0000\n",
       "578   Default   60.000000      generation   60.000000  22.0000  22.0000\n",
       "1078  Default   41.000000            turn   41.000000  21.0000  21.0000\n",
       "1620  Default   62.000000       americans   62.000000  20.0000  20.0000\n",
       "315   Default  126.000000        congress  126.000000  19.0000  19.0000\n",
       "302   Default   36.000000            case   36.000000  18.0000  18.0000\n",
       "359   Default   34.000000            fact   34.000000  17.0000  17.0000\n",
       "1306  Default   68.000000         century   68.000000  16.0000  16.0000\n",
       "104   Default   95.000000       executive   95.000000  15.0000  15.0000\n",
       "336   Default   45.000000      difference   45.000000  14.0000  14.0000\n",
       "1633  Default   28.000000           woman   28.000000  13.0000  13.0000\n",
       "1023  Default   52.000000            make   52.000000  12.0000  12.0000\n",
       "886   Default   33.000000        remember   33.000000  11.0000  11.0000\n",
       "860   Default   46.000000            face   46.000000  10.0000  10.0000\n",
       "1495  Default   32.000000       challenge   32.000000   9.0000   9.0000\n",
       "166   Default   64.000000          object   64.000000   8.0000   8.0000\n",
       "34    Default   38.000000           bless   38.000000   7.0000   7.0000\n",
       "605   Default   36.000000          moment   36.000000   6.0000   6.0000\n",
       "1508  Default   43.000000         problem   43.000000   5.0000   5.0000\n",
       "1609  Default   43.000000        economic   43.000000   4.0000   4.0000\n",
       "294   Default   66.000000       authority   66.000000   3.0000   3.0000\n",
       "59    Default   50.000000  constitutional   50.000000   2.0000   2.0000\n",
       "1598  Default   26.000000           unity   26.000000   1.0000   1.0000\n",
       "...       ...         ...             ...         ...      ...      ...\n",
       "1096   Topic5    0.829715        attitude    7.220186   2.0100  -6.2832\n",
       "1163   Topic5    0.675646            send    5.968588   1.9950  -6.4886\n",
       "1484   Topic5    2.361961           young   20.931826   1.9918  -5.2370\n",
       "392    Topic5    0.676258    intellectual    6.059323   1.9808  -6.4877\n",
       "949    Topic5    0.675603           throw    6.079240   1.9765  -6.4886\n",
       "842    Topic5    4.089443            word   39.019928   1.9179  -4.6881\n",
       "494    Topic5    6.978973           there   74.391724   1.8071  -4.1536\n",
       "359    Topic5    2.990535            fact   34.445591   1.7296  -5.0010\n",
       "1587   Topic5    1.799534            hard   19.592075   1.7860  -5.5090\n",
       "1633   Topic5    2.362183           woman   28.557753   1.6812  -5.2369\n",
       "1492   Topic5    1.860101      washington   20.885019   1.7552  -5.4759\n",
       "1078   Topic5    2.974324            turn   41.167377   1.5459  -5.0065\n",
       "886    Topic5    2.372295        remember   33.237762   1.5337  -5.2326\n",
       "1578   Topic5    4.088375           today   83.722397   1.1542  -4.6883\n",
       "786    Topic5    1.842057           offer   25.322342   1.5528  -5.4856\n",
       "694    Topic5    3.028336           child   55.753880   1.2606  -4.9885\n",
       "407    Topic5    2.990397            like   54.731598   1.2665  -5.0011\n",
       "1207   Topic5    2.943614       democracy   53.851067   1.2670  -5.0169\n",
       "1564   Topic5    2.916661            help   69.125069   1.0081  -5.0261\n",
       "1000   Topic5    1.812380      expression   25.720448   1.5209  -5.5019\n",
       "382    Topic5    1.804456            idea   25.596798   1.5214  -5.5062\n",
       "578    Topic5    2.379591      generation   60.972843   0.9301  -5.2296\n",
       "1598   Topic5    1.797508           unity   26.176184   1.4951  -5.5101\n",
       "1495   Topic5    1.813329       challenge   32.487087   1.2879  -5.5013\n",
       "34     Topic5    1.841006           bless   38.031342   1.1455  -5.4862\n",
       "743    Topic5    1.839807          father   39.890129   1.0971  -5.4868\n",
       "315    Topic5    1.817924        congress  126.587967  -0.0697  -5.4988\n",
       "1023   Topic5    1.814453            make   52.826591   0.8023  -5.5007\n",
       "336    Topic5    1.805582      difference   45.645191   0.9436  -5.5056\n",
       "605    Topic5    1.800110          moment   36.665054   1.1596  -5.5086\n",
       "\n",
       "[345 rows x 6 columns], token_table=      Topic      Freq            Term\n",
       "term                                 \n",
       "1625      2  0.660205       abundance\n",
       "1625      4  0.330103       abundance\n",
       "1188      1  0.321752  accountability\n",
       "1188      3  0.643504  accountability\n",
       "1276      1  0.114081         achieve\n",
       "1276      2  0.684487         achieve\n",
       "1276      3  0.038027         achieve\n",
       "1276      4  0.152108         achieve\n",
       "4         1  0.687013        addition\n",
       "4         4  0.274805        addition\n",
       "1294      1  0.108685       adherence\n",
       "1294      2  0.326056       adherence\n",
       "1294      3  0.652112       adherence\n",
       "1360      1  0.894909       admission\n",
       "899       2  0.955280       adversary\n",
       "1091      1  0.126282       agreement\n",
       "1091      2  0.252565       agreement\n",
       "1091      4  0.505129       agreement\n",
       "1091      5  0.126282       agreement\n",
       "1254      1  0.176197             aim\n",
       "1254      2  0.469858             aim\n",
       "1254      3  0.176197             aim\n",
       "1254      4  0.176197             aim\n",
       "1526      1  0.279734           alien\n",
       "1526      2  0.419601           alien\n",
       "1526      4  0.139867           alien\n",
       "13        1  0.236311             all\n",
       "13        2  0.354467             all\n",
       "13        3  0.265850             all\n",
       "13        4  0.118156             all\n",
       "...     ...       ...             ...\n",
       "668       2  0.536702             use\n",
       "668       3  0.057504             use\n",
       "668       4  0.038336             use\n",
       "668       5  0.019168             use\n",
       "1632      2  0.964905          vision\n",
       "1492      1  0.430931      washington\n",
       "1492      2  0.430931      washington\n",
       "1492      3  0.047881      washington\n",
       "1492      5  0.095762      washington\n",
       "254       1  0.333984           watch\n",
       "254       2  0.400781           watch\n",
       "254       3  0.133594           watch\n",
       "254       5  0.133594           watch\n",
       "1661      2  0.909583          weapon\n",
       "1661      4  0.056849          weapon\n",
       "1633      2  0.910436           woman\n",
       "1633      5  0.070034           woman\n",
       "842       1  0.205023            word\n",
       "842       2  0.640698            word\n",
       "842       3  0.051256            word\n",
       "842       5  0.102512            word\n",
       "1678      2  0.861765             yes\n",
       "1678      5  0.095752             yes\n",
       "1484      2  0.764386           young\n",
       "1484      3  0.095548           young\n",
       "1484      5  0.095548           young\n",
       "1547      1  0.140836            your\n",
       "1547      2  0.422507            your\n",
       "1547      4  0.140836            your\n",
       "1547      5  0.281671            your\n",
       "\n",
       "[800 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 5, 2, 4, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Silence an annoying warning we cannot do anything about\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pyLDAvis code starts here\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some hints to help you interpret the visualisation:\n",
    "\n",
    "* On the **left-hand side** is a scatterplot of some bubbles:\n",
    " * Each **bubble** represents a topic.\n",
    " * The **size of a bubble** represents how _prevalent_ or popular the topic is overall.\n",
    " * The **distance** from one bubble to another represents how similar the topics are to each other. If they overlap then the topics share significant similarity.\n",
    " \n",
    "* On the **right-hand side** is a histogram of terms (tokens):\n",
    " * Select a bubble and it shows the top-30 **most relevant terms** for that topic.\n",
    " * The **red bar** represents how frequent a term is in the topic.\n",
    " * The **blue bar** represents how frequent the term is overall in all topics. So a long red bar with only a short blue bar indicates a term that is highly specific to that particular topic. Conversely, a red bar with a long blue bar means the term is also present in many other topics.\n",
    " * By mousing over a particular term, the size of the bubbles changes to show the relative frequency of that term in the various topics.\n",
    " * By adjusting the slide, it adjusts the **_relevance_ value (λ)**, which is the weight given to whether a term appears exclusively in a particular topic or is spread over topics more evenly. If λ = 1 terms are ranked according to their probabilities in the particular topic only; if λ = 0 terms are ranked higher if they are unusual terms that occur almost exclusively in that topic. Typically, the optimal value is around 0.6, but it is interesting to adjust it and observe any differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Summary\n",
    "\n",
    "Well done for getting to the end of the topic modelling fundamentals notebook! Here is what we have done:\n",
    "\n",
    "* Understood that Latent Dirichlet Allocation (LDA) is one type of topic modelling\n",
    "* Loaded and saved the cleaned tokens into a Gensim corpus dictionary\n",
    "* Created a bag-of-words (BoW) corpus\n",
    "* Looked at Term Frequency–Inverse Document Frequency (TF-IDF)\n",
    "* Trained a Latent Dirichlet Allocation (LDA) topic model\n",
    "* Visualised the resulting topics with pyLDAvis\n",
    "\n",
    "\n",
    "👌👌👌\n",
    "\n",
    "Congratulations! 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## What's Next?\n",
    "If you have decided that text-mining with Python might be for you, then here are some more resources to study in your own time.\n",
    "\n",
    "### Topic Modelling\n",
    "\n",
    "* For a general overview of the issues that should concern you as a humanist: [Topic Modeling for Humanists: A Guided Tour](http://scottbot.net/topic-modeling-for-humanists-a-guided-tour/).\n",
    "* Follow a more advanced Jupyter notebook: [Topic Modelling - and more - with Gensim!](https://github.com/bhargavvader/personal/blob/master/notebooks/text_analysis_tutorial/topic_modelling.ipynb).\n",
    "\n",
    "### Text-mining in General\n",
    "\n",
    "* Follow a more in-depth set of Jupyter notebooks with [The Art of Literary Text Analysis](https://github.com/sgsinclair/alta/blob/master/ipynb/ArtOfLiteraryTextAnalysis.ipynb).\n",
    "* Read a practical and well-explained approach to Natural Language Processing (NLP) in Python: Srinivasa-Desikan, B., 2018. _Natural Language Processing and Computational Linguistics : A practical guide to text analysis with Python, Gensim, spaCy, and Keras._ Birmingham: Packt Publishing. [Available online](https://idiscover.lib.cam.ac.uk/primo-explore/fulldisplay?docid=44CAM_NPLD_MARC018975982&context=L&vid=44CAM_PROD&search_scope=SCOP_CAM_ALL&tab=cam_lib_coll&lang=en_US). This book has chapters on text pre-processing steps, topic modelling, Gensim - and comes with Jupyter notebooks to follow.\n",
    "\n",
    "### Learning Python and Jupyter Notebooks for Digital Humanities:\n",
    "\n",
    "* I have written a guide to running these notebooks on your own computer in the [README](https://github.com/mchesterkadwell/intro-to-text-mining-with-python/blob/master/README.md) of the GitHub code repository.\n",
    "* Install Python using Anaconda on your computer: [Installing Anaconda on Windows](https://www.datacamp.com/community/tutorials/installing-anaconda-windows) [Installing Anaconda on Mac](https://www.datacamp.com/community/tutorials/installing-anaconda-mac-os-x).\n",
    "* Learn how to run and write Jupyter notebooks on your own computer (rather than using Binder): [Jupyter Notebook Tutorial: The Definitive Guide](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook).\n",
    "* Work through Chapters 1 - 4 (online Jupyter notebooks) of [Python Programming for the Humanities](http://www.karsdorp.io/python-course/).\n",
    "* Browse a big list of resources for [Teaching Yourself to Code in DH](http://scottbot.net/teaching-yourself-to-code-in-dh/).\n",
    "\n",
    "Even if you are not sure programming is for you, [Cambridge Digital Humanities](https://www.cdh.cam.ac.uk/) (CDH) has a number of resources to support your research. \n",
    "\n",
    "* CDH Learning - [training events/workshops](https://www.cdh.cam.ac.uk/learning/cdh-events) and mentoring programme.\n",
    "* CDH Lab - email [lab@cdh.cam.ac.uk](mailto:lab@cdh.cam.ac.uk) for advice on your project, whether you are just getting started, somewhere in the middle, or thinking about the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
