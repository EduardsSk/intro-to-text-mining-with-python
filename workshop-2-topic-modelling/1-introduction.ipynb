{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Topic Modelling with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## What is Topic Modelling?\n",
    "\n",
    "Topic modelling is a _distant reading_ technique for finding structure in large collections of text, without actually reading everything by eye. If you have hundreds or thousands of documents and want to understand roughly what your corpus contains, then topic modelling may be for you.\n",
    "\n",
    "A topic modelling programme finds the words that appear frequently together in a document and groups them together to form 'topics'. A **topic** is a mixture of words that is supposed to characterise (part of) the content of a document. For example, one topic of this [Wikipedia article](https://en.wikipedia.org/wiki/Black_hole) is:\n",
    "\n",
    "* black, hole, mass, star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Supermassive black hole](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Black_hole_-_Messier_87.jpg/320px-Black_hole_-_Messier_87.jpg \"First picture of a supermassive black hole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too surprising, you may think. We could say the topic seems pretty accurate from our perspective. What about a document that we are less familiar with? Here is a topic of a [speech](https://er.jsc.nasa.gov/seh/ricetalk.htm) made by John F. Kennedy at Rice University in 1962:\n",
    "\n",
    "* space, new, year, man\n",
    "\n",
    "This is Kennedy's famous 'we choose to go to the moon' speech. Notice that 'moon' is not in this topic; but the speech does cover the history of humankind's (\"man's\") endeavours and emphasises a forward-looking perspective (the \"new\"-ness of advancements).\n",
    "\n",
    "From these simplified examples, we can see that human intervention is still required to interpret what topics might 'mean'. Topic modelling is not magic; it is a tool that requires informed use and careful review, just like any other.\n",
    "\n",
    "### So... Why Do Topic Modelling?\n",
    "In the humanities, topic modelling may be used to support different approaches to large text corpora, such as:\n",
    "\n",
    "* Survey a collection that is too big to read closely e.g. [Computational Historiography: Data Mining in a Century of Classics Journals](http://www.perseus.tufts.edu/publications/02-jocch-mimno.pdf) (PDF)\n",
    "* Look at thematic trends over time in an archive e.g. [Topic Modeling Martha Ballard's Diary](http://www.cameronblevins.org/posts/topic-modeling-martha-ballards-diary/)\n",
    "* Create metadata for an archive to improve accessibility e.g. [Topic modelling for the valorisation of digitised archives of the European Commission](https://ieeexplore.ieee.org/abstract/document/7840981)\n",
    "\n",
    "### Alternatives to Topic Modelling in Python\n",
    "If you are looking to explore the topics of a few documents in a casual way, you can use the online digital texts environment [Voyant](), which allows you to upload or copy-and-paste texts and explore a corpus with a number of graphical tools, including topics.\n",
    "\n",
    "For serious research, a well-known tool for topic modelling is called [MALLET](http://mallet.cs.umass.edu/topics.php), which is a programme (written in Java) that you download to your computer. You have to type commands to use MALLET, but it has otherwise done a great deal for you. [Getting Started with Topic Modeling and MALLET](https://programminghistorian.org/en/lessons/topic-modeling-and-mallet) from Programming Historian gives a step-by-step tutorial on MALLET.\n",
    "\n",
    "There is a graphical interface for MALLET called [Topic Modeling Tool](https://github.com/senderle/topic-modeling-tool) that is a bit easier to use. The [Quickstart Guide](https://senderle.github.io/topic-modeling-tool/documentation/2017/01/06/quickstart.html) will get you up and running.\n",
    "\n",
    "If you are looking to use R rather than Python, then `tidytext` is a popular NLP library that will help you work with the `topicmodels` package. The book _Text Mining with R_ devotes [chapter 6](https://www.tidytextmining.com/topicmodeling.html) to this.\n",
    "\n",
    "---\n",
    "**With the alternatives out of the way, let's see how we can do topic modelling in Python!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## How to Join In with Coding\n",
    "\n",
    "* **Edit** any cell and try changing the code, or delete it and write your own.\n",
    "\n",
    "* Before running a cell, try to **guess** what the output will be by thinking through what will happen.\n",
    "\n",
    "* If you encounter an **error**, realise this is normal. Errors happen all the time and by reading the error message you will learn something new.\n",
    "\n",
    "* Remember: you cannot break the notebook or your computer, so **don't be afraid to experiment**.\n",
    "\n",
    "**Let's get coding!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Recap of Python Basics\n",
    "Welcome back! Let's recap the Python that we learnt last time. Any questions?\n",
    "### Strings\n",
    "Create a _string_ and store it with a _name_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Moon formed 4.51 billion years ago.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sentence = 'The Moon formed 4.51 billion years ago.'\n",
    "my_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Slice_ a string. Remember that indexing in Python starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Moon formed 4.51'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sentence[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform a string with string methods. Important: the original string `my_sentence` is unchanged. Instead, a string method _returns_ a new string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tHE mOON FORMED 4.51 BILLION YEARS AGO.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sentence.swapcase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a string with string methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sentence.islower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a string to see if it contains another string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'f' in my_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a _list_ of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Moon formed 4.51 billion years ago',\n",
       " \"The Moon is Earth's only permanent natural satellite\",\n",
       " 'The Moon was first reached in September 1959']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = ['The Moon formed 4.51 billion years ago',\n",
    "           \"The Moon is Earth's only permanent natural satellite\",\n",
    "          'The Moon was first reached in September 1959']\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Moon was first reached in September 1959'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformed list of strings with a _list comprehension_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"THE MOON IS EARTH'S ONLY PERMANENT NATURAL SATELLITE\"]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list = [string.upper() for string in my_list if 'Earth' in string]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "`import` a _module_ and use it. A module is simply code 'written by someone else' in another file (or files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE FIRST MEN IN THE MOON\\r\\n\\r\\nby H.G. Wells\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nChapter 1\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nMr. Bedford Meets Mr. Cavor at Lympne\\r\\n\\r\\nAs I sit down to write here amidst the shadows of vine-leaves under the\\r\\nblue sky of southern Italy, it com'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/1/1013/1013.txt')\n",
    "text = response.text\n",
    "text[681:900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`import` [Natural Language Tool Kit](http://www.nltk.org/) (NLTK) to help with natural language processing (NLP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE',\n",
       " 'FIRST',\n",
       " 'MEN',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'MOON',\n",
       " 'by',\n",
       " 'H.G',\n",
       " '.',\n",
       " 'Wells',\n",
       " 'Chapter',\n",
       " '1',\n",
       " 'Mr.',\n",
       " 'Bedford',\n",
       " 'Meets',\n",
       " 'Mr.',\n",
       " 'Cavor',\n",
       " 'at',\n",
       " 'Lympne',\n",
       " 'As']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "tokens[126:146]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "_Call_ a _function_ with _arguments_. For example, here the function `most_common()` takes a single argument `10`, to give us the ten most common tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 4612),\n",
       " ('.', 3851),\n",
       " ('the', 3639),\n",
       " ('and', 2538),\n",
       " ('of', 2483),\n",
       " ('I', 2190),\n",
       " ('a', 1809),\n",
       " ('to', 1658),\n",
       " (\"''\", 1214),\n",
       " ('``', 1160)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "freqdist = FreqDist(tokens)\n",
    "freqdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## More About Tokenising and Normalisation\n",
    "\n",
    "In the last workshop, in notebook `workshop-1-basics/2-collecting-and-preparing.ipynb`, we cleaned and prepared the text _The Iliad of Homer_ (translated by Alexander Pope (1899)) by:\n",
    "* Tokenising the text into individual words.\n",
    "* Normalising the text:\n",
    " * into lowercase,\n",
    " * removing punctuation,\n",
    " * removing non-words (empty strings, numerals, etc.),\n",
    " * removing stopwords.\n",
    "\n",
    "One form of normalisation we didn't do last time is making sure that different _inflections_ of the same word are counted together. In English, words are modified to express quantity, tense, etc. (i.e. _declension_ and _conjugation_ for those who remember their language lessons!).\n",
    "\n",
    "For example, 'fish', 'fishes', 'fishy' and 'fishing' are all formed from the root 'fish'. Last workshop, all these words would have been counted as different words, which may or may not be desirable.\n",
    "\n",
    "### Stemming and Lemmatization\n",
    "\n",
    "There are two main ways to normalise for inflection:\n",
    "\n",
    "* **Stemming** - reducing a word to a stem by removing endings (a **stem** may not be an actual word).\n",
    "* **Lemmatization** - reducing a word to its meaningful base form using its context (a **lemma** is typically a proper word in the language).\n",
    "\n",
    "To do this we can use several facilities provided by NLTK. There are many different ways to stem and lemmatize words, but we will compare the results of the [Porter Stemmer](https://tartarus.org/martin/PorterStemmer/) and [WordNet](https://wordnet.princeton.edu/) lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All about us on the sunlit slopes frothed and swayed the darting shrubs'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_wells = text[118017:118088]\n",
    "hg_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all',\n",
       " 'about',\n",
       " 'us',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sunlit',\n",
       " 'slope',\n",
       " 'froth',\n",
       " 'and',\n",
       " 'sway',\n",
       " 'the',\n",
       " 'dart',\n",
       " 'shrub']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(hg_wells)\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "stems = [porter.stem(token) for token in tokens]\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/mary/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All',\n",
       " 'about',\n",
       " 'u',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sunlit',\n",
       " 'slope',\n",
       " 'frothed',\n",
       " 'and',\n",
       " 'swayed',\n",
       " 'the',\n",
       " 'darting',\n",
       " 'shrub']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think about the results? Perhaps surprisingly, the lemmatizer seems to have performed more poorly than the stemmer since `frothed` and `darting` have not been reduced to `froth` and `dart`.\n",
    "\n",
    "The different rules used to stem and lemmatize words are called _algorithms_ and they can result in different stems and lemmas. If the precise details of this are important to your research, you should compare the results of the various algorithms. Stemmers and lemmatizers are also available in many languages, not just English.\n",
    "\n",
    "---\n",
    "#### Going Further: Improving Lemmatization with Part-of-Speech Tagging\n",
    "\n",
    "To improve the lemmatizer's performance we can tell it which _part of speech_ each word is, which is known as **part-of-speech tagging (POS tagging)**. A part of speech is the role a word plays in the sentence, e.g. verb, noun, adjective, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mary/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the POS tagger\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('All', 'DT'),\n",
       " ('about', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('sunlit', 'NN'),\n",
       " ('slopes', 'VBZ'),\n",
       " ('frothed', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('swayed', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('darting', 'NN'),\n",
       " ('shrubs', 'NN')]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the POS tags for each token\n",
    "tags = nltk.pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tags that NLTK generates are from the [Penn Treebank II tag set](https://www.clips.uantwerpen.be/pages/MBSP-tags). For example, now we know that `frothed` is a 'verb, past participle' (VBN).\n",
    "\n",
    "Unfortunately, the NLTK lemmatizer takes WordNet tags (`ADJ, ADV, NOUN, VERB = 'a', 'r', 'n', 'v'`) instead! In theory, at least, if we pass the tagging information to the lemmatizer, the results are better. Now, `frothing` has been reduced to `froth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All',\n",
       " 'about',\n",
       " 'u',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sunlit',\n",
       " 'slop',\n",
       " 'froth',\n",
       " 'and',\n",
       " 'sway',\n",
       " 'the',\n",
       " 'darting',\n",
       " 'shrub']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping of tokens to WordNet POS tags\n",
    "tags = [('All', 'n'),\n",
    " ('about', 'n'),\n",
    " ('us', 'n'),\n",
    " ('on', 'n'),\n",
    " ('the', 'n'),\n",
    " ('sunlit', 'a'),\n",
    " ('slopes', 'v'),\n",
    " ('frothed', 'v'),\n",
    " ('and', 'n'),\n",
    " ('swayed', 'v'),\n",
    " ('the', 'n'),\n",
    " ('darting', 'a'),\n",
    " ('shrubs', 'n')]\n",
    "\n",
    "lemmas = [lemmatizer.lemmatize(*tag) for tag in tags]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, however, we may wish to [experiment](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/) with other lemmatizers to get the best results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text into a dict of tokens using built-in Gensim function preprocess_string\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "text_data = preprocess_string('''\n",
    " President Pitzer, Mr. Vice President, Governor, Congressman Thomas, Senator Wiley, and Congressman Miller, Mr. Webb, Mr. Bell, scientists, distinguished guests, and ladies and gentlemen:\n",
    "\n",
    "I appreciate your president having made me an honorary visiting professor, and I will assure you that my first lecture will be very brief.\n",
    "\n",
    "I am delighted to be here, and I'm particularly delighted to be here on this occasion.\n",
    "\n",
    "We meet at a college noted for knowledge, in a city noted for progress, in a State noted for strength, and we stand in need of all three, for we meet in an hour of change and challenge, in a decade of hope and fear, in an age of both knowledge and ignorance. The greater our knowledge increases, the greater our ignorance unfolds.\n",
    "\n",
    "Despite the striking fact that most of the scientists that the world has ever known are alive and working today, despite the fact that this Nation¹s own scientific manpower is doubling every 12 years in a rate of growth more than three times that of our population as a whole, despite that, the vast stretches of the unknown and the unanswered and the unfinished still far outstrip our collective comprehension.\n",
    "\n",
    "No man can fully grasp how far and how fast we have come, but condense, if you will, the 50,000 years of man¹s recorded history in a time span of but a half-century. Stated in these terms, we know very little about the first 40 years, except at the end of them advanced man had learned to use the skins of animals to cover them. Then about 10 years ago, under this standard, man emerged from his caves to construct other kinds of shelter. Only five years ago man learned to write and use a cart with wheels. Christianity began less than two years ago. The printing press came this year, and then less than two months ago, during this whole 50-year span of human history, the steam engine provided a new source of power.\n",
    "\n",
    "Newton explored the meaning of gravity. Last month electric lights and telephones and automobiles and airplanes became available. Only last week did we develop penicillin and television and nuclear power, and now if America's new spacecraft succeeds in reaching Venus, we will have literally reached the stars before midnight tonight.\n",
    "\n",
    "This is a breathtaking pace, and such a pace cannot help but create new ills as it dispels old, new ignorance, new problems, new dangers. Surely the opening vistas of space promise high costs and hardships, as well as high reward.\n",
    "\n",
    "So it is not surprising that some would have us stay where we are a little longer to rest, to wait. But this city of Houston, this State of Texas, this country of the United States was not built by those who waited and rested and wished to look behind them. This country was conquered by those who moved forward--and so will space.\n",
    "\n",
    "William Bradford, speaking in 1630 of the founding of the Plymouth Bay Colony, said that all great and honorable actions are accompanied with great difficulties, and both must be enterprised and overcome with answerable courage.\n",
    "\n",
    "If this capsule history of our progress teaches us anything, it is that man, in his quest for knowledge and progress, is determined and cannot be deterred. The exploration of space will go ahead, whether we join in it or not, and it is one of the great adventures of all time, and no nation which expects to be the leader of other nations can expect to stay behind in the race for space.\n",
    "\n",
    "Those who came before us made certain that this country rode the first waves of the industrial revolutions, the first waves of modern invention, and the first wave of nuclear power, and this generation does not intend to founder in the backwash of the coming age of space. We mean to be a part of it--we mean to lead it. For the eyes of the world now look into space, to the moon and to the planets beyond, and we have vowed that we shall not see it governed by a hostile flag of conquest, but by a banner of freedom and peace. We have vowed that we shall not see space filled with weapons of mass destruction, but with instruments of knowledge and understanding.\n",
    "\n",
    "Yet the vows of this Nation can only be fulfilled if we in this Nation are first, and, therefore, we intend to be first. In short, our leadership in science and in industry, our hopes for peace and security, our obligations to ourselves as well as others, all require us to make this effort, to solve these mysteries, to solve them for the good of all men, and to become the world's leading space-faring nation.\n",
    "\n",
    "We set sail on this new sea because there is new knowledge to be gained, and new rights to be won, and they must be won and used for the progress of all people. For space science, like nuclear science and all technology, has no conscience of its own. Whether it will become a force for good or ill depends on man, and only if the United States occupies a position of pre-eminence can we help decide whether this new ocean will be a sea of peace or a new terrifying theater of war. I do not say the we should or will go unprotected against the hostile misuse of space any more than we go unprotected against the hostile use of land or sea, but I do say that space can be explored and mastered without feeding the fires of war, without repeating the mistakes that man has made in extending his writ around this globe of ours.\n",
    "\n",
    "There is no strife, no prejudice, no national conflict in outer space as yet. Its hazards are hostile to us all. Its conquest deserves the best of all mankind, and its opportunity for peaceful cooperation many never come again. But why, some say, the moon? Why choose this as our goal? And they may well ask why climb the highest mountain? Why, 35 years ago, fly the Atlantic? Why does Rice play Texas?\n",
    "\n",
    "We choose to go to the moon. We choose to go to the moon in this decade and do the other things, not because they are easy, but because they are hard, because that goal will serve to organize and measure the best of our energies and skills, because that challenge is one that we are willing to accept, one we are unwilling to postpone, and one which we intend to win, and the others, too.\n",
    "\n",
    "It is for these reasons that I regard the decision last year to shift our efforts in space from low to high gear as among the most important decisions that will be made during my incumbency in the office of the Presidency.\n",
    "\n",
    "In the last 24 hours we have seen facilities now being created for the greatest and most complex exploration in man's history. We have felt the ground shake and the air shattered by the testing of a Saturn C-1 booster rocket, many times as powerful as the Atlas which launched John Glenn, generating power equivalent to 10,000 automobiles with their accelerators on the floor. We have seen the site where the F-1 rocket engines, each one as powerful as all eight engines of the Saturn combined, will be clustered together to make the advanced Saturn missile, assembled in a new building to be built at Cape Canaveral as tall as a 48 story structure, as wide as a city block, and as long as two lengths of this field.\n",
    "\n",
    "Within these last 19 months at least 45 satellites have circled the earth. Some 40 of them were \"made in the United States of America\" and they were far more sophisticated and supplied far more knowledge to the people of the world than those of the Soviet Union.\n",
    "\n",
    "The Mariner spacecraft now on its way to Venus is the most intricate instrument in the history of space science. The accuracy of that shot is comparable to firing a missile from Cape Canaveral and dropping it in this stadium between the the 40-yard lines.\n",
    "\n",
    "Transit satellites are helping our ships at sea to steer a safer course. Tiros satellites have given us unprecedented warnings of hurricanes and storms, and will do the same for forest fires and icebergs.\n",
    "\n",
    "We have had our failures, but so have others, even if they do not admit them. And they may be less public.\n",
    "\n",
    "To be sure, we are behind, and will be behind for some time in manned flight. But we do not intend to stay behind, and in this decade, we shall make up and move ahead.\n",
    "\n",
    "The growth of our science and education will be enriched by new knowledge of our universe and environment, by new techniques of learning and mapping and observation, by new tools and computers for industry, medicine, the home as well as the school. Technical institutions, such as Rice, will reap the harvest of these gains.\n",
    "\n",
    "And finally, the space effort itself, while still in its infancy, has already created a great number of new companies, and tens of thousands of new jobs. Space and related industries are generating new demands in investment and skilled personnel, and this city and this State, and this region, will share greatly in this growth. What was once the furthest outpost on the old frontier of the West will be the furthest outpost on the new frontier of science and space. Houston, your City of Houston, with its Manned Spacecraft Center, will become the heart of a large scientific and engineering community. During the next 5 years the National Aeronautics and Space Administration expects to double the number of scientists and engineers in this area, to increase its outlays for salaries and expenses to $60 million a year; to invest some $200 million in plant and laboratory facilities; and to direct or contract for new space efforts over $1 billion from this Center in this City.\n",
    "\n",
    "To be sure, all this costs us all a good deal of money. This year¹s space budget is three times what it was in January 1961, and it is greater than the space budget of the previous eight years combined. That budget now stands at $5,400 million a year--a staggering sum, though somewhat less than we pay for cigarettes and cigars every year. Space expenditures will soon rise some more, from 40 cents per person per week to more than 50 cents a week for every man, woman and child in the United Stated, for we have given this program a high national priority--even though I realize that this is in some measure an act of faith and vision, for we do not now know what benefits await us.\n",
    "\n",
    "But if I were to say, my fellow citizens, that we shall send to the moon, 240,000 miles away from the control station in Houston, a giant rocket more than 300 feet tall, the length of this football field, made of new metal alloys, some of which have not yet been invented, capable of standing heat and stresses several times more than have ever been experienced, fitted together with a precision better than the finest watch, carrying all the equipment needed for propulsion, guidance, control, communications, food and survival, on an untried mission, to an unknown celestial body, and then return it safely to earth, re-entering the atmosphere at speeds of over 25,000 miles per hour, causing heat about half that of the temperature of the sun--almost as hot as it is here today--and do all this, and do it right, and do it first before this decade is out--then we must be bold.\n",
    "\n",
    "I'm the one who is doing all the work, so we just want you to stay cool for a minute. [laughter]\n",
    "\n",
    "However, I think we're going to do it, and I think that we must pay what needs to be paid. I don't think we ought to waste any money, but I think we ought to do the job. And this will be done in the decade of the sixties. It may be done while some of you are still here at school at this college and university. It will be done during the term of office of some of the people who sit here on this platform. But it will be done. And it will be done before the end of this decade.\n",
    "\n",
    "I am delighted that this university is playing a part in putting a man on the moon as part of a great national effort of the United States of America.\n",
    "\n",
    "Many years ago the great British explorer George Mallory, who was to die on Mount Everest, was asked why did he want to climb it. He said, \"Because it is there.\"\n",
    "\n",
    "Well, space is there, and we're going to climb it, and the moon and the planets are there, and new hopes for knowledge and peace are there. And, therefore, as we set sail we ask God's blessing on the most hazardous and dangerous and greatest adventure on which man has ever embarked.\n",
    "\n",
    "Thank you. ''')\n",
    "# preprocess_string('No fishes to poise the lance or bend the fish; But hand to hand fishing, and fishy man to man, they grow:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presid',\n",
       " 'pitzer',\n",
       " 'vice',\n",
       " 'presid',\n",
       " 'governor',\n",
       " 'congressman',\n",
       " 'thoma',\n",
       " 'senat',\n",
       " 'wilei',\n",
       " 'congressman',\n",
       " 'miller',\n",
       " 'webb',\n",
       " 'bell',\n",
       " 'scientist',\n",
       " 'distinguish',\n",
       " 'guest',\n",
       " 'ladi',\n",
       " 'gentlemen',\n",
       " 'appreci',\n",
       " 'presid',\n",
       " 'have',\n",
       " 'honorari',\n",
       " 'visit',\n",
       " 'professor',\n",
       " 'assur',\n",
       " 'lectur',\n",
       " 'brief',\n",
       " 'delight',\n",
       " 'particularli',\n",
       " 'delight',\n",
       " 'occas',\n",
       " 'meet',\n",
       " 'colleg',\n",
       " 'note',\n",
       " 'knowledg',\n",
       " 'citi',\n",
       " 'note',\n",
       " 'progress',\n",
       " 'state',\n",
       " 'note',\n",
       " 'strength',\n",
       " 'stand',\n",
       " 'need',\n",
       " 'meet',\n",
       " 'hour',\n",
       " 'chang',\n",
       " 'challeng',\n",
       " 'decad',\n",
       " 'hope',\n",
       " 'fear',\n",
       " 'ag',\n",
       " 'knowledg',\n",
       " 'ignor',\n",
       " 'greater',\n",
       " 'knowledg',\n",
       " 'increas',\n",
       " 'greater',\n",
       " 'ignor',\n",
       " 'unfold',\n",
       " 'despit',\n",
       " 'strike',\n",
       " 'fact',\n",
       " 'scientist',\n",
       " 'world',\n",
       " 'known',\n",
       " 'aliv',\n",
       " 'work',\n",
       " 'todai',\n",
       " 'despit',\n",
       " 'fact',\n",
       " 'nation¹',\n",
       " 'scientif',\n",
       " 'manpow',\n",
       " 'doubl',\n",
       " 'year',\n",
       " 'rate',\n",
       " 'growth',\n",
       " 'time',\n",
       " 'popul',\n",
       " 'despit',\n",
       " 'vast',\n",
       " 'stretch',\n",
       " 'unknown',\n",
       " 'unansw',\n",
       " 'unfinish',\n",
       " 'far',\n",
       " 'outstrip',\n",
       " 'collect',\n",
       " 'comprehens',\n",
       " 'man',\n",
       " 'fulli',\n",
       " 'grasp',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'come',\n",
       " 'condens',\n",
       " 'year',\n",
       " 'man¹',\n",
       " 'record',\n",
       " 'histori']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpora dictionary of tokens using Gensim (corpora.Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a bag-of-words corpus using Gensim (corpora.Dictionary.doc2bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bag-of-words corpus object to disc using pickle (alternatives?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LDA model to find topics using Gensim (gensim.models.ldamodel.LdaModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "A bag-of-words (BoW) corpus is a _vocabulary_ of the known words in the corpus together with some _measure_ of how often they occur. The measurement may be:\n",
    "* binary (presence or absence)\n",
    "* count (how many times the word occurs)\n",
    "* frequency (count divided by the total number of words).  \n",
    "\n",
    "This combination of vocabulary and measurement is called a **document vector**.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Here is a simplified example to demonstrate the principles of creating a vector from a document.\n",
    "\n",
    "Document (20 words):\n",
    "\n",
    ">'No room to poise the lance or bend the bow;\n",
    "> But hand to hand, and man to man, they grow:'\n",
    " \n",
    " (from _The Iliad of Homer_, translated by Alexander Pope (1899)) \n",
    "  \n",
    "Vocabulary of unique words (15 words):\n",
    "\n",
    "* no\n",
    "* room\n",
    "* to\n",
    "* poise\n",
    "* the\n",
    "* lance\n",
    "* or\n",
    "* bend\n",
    "* bow\n",
    "* but\n",
    "* hand\n",
    "* and\n",
    "* man\n",
    "* they\n",
    "* grow\n",
    "\n",
    "Count measurements (how many times each word appears in the document):\n",
    "\n",
    "* no = 1\n",
    "* room = 1\n",
    "* to = 3\n",
    "* poise = 1\n",
    "* the = 2\n",
    "* lance = 1\n",
    "* or = 1\n",
    "* bend = 1\n",
    "* bow = 1\n",
    "* but = 1\n",
    "* hand = 2\n",
    "* and = 1\n",
    "* man = 2\n",
    "* they = 1\n",
    "* grow = 1\n",
    "\n",
    "If we treat this vocabulary as a list with a fixed order, we can just extract the counts into a list. This is the document vector.\n",
    "\n",
    "`[1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1]`\n",
    "\n",
    "In order to compare other documents with this one for similarity, we could generate a document vector with the same vocabulary list for each document, or expand the vocabulary list to cover all the words in all the documents we are interested in.\n",
    "\n",
    "#### The 'bag' in bag of wordsprocessing\n",
    "\n",
    "In this most basic BoW model all order and location of the words is discarded. For example, it does not matter if the words 'red' and 'nose' are adjacent ('red nose'), or at the beginning or end of a sentence; BoW just treats the words individually. It is like a 'bag' of Scrabble™ tiles, where each tile is a word, all rattling around together in no particular order.\n",
    "\n",
    "It is possible to create a BoW corpus that uses two or more adjacent words, and potentially . For example, if you measure all pairs of words in our example document (above) you might end up with a vocabulary that looks like this:\n",
    "\n",
    "* no room\n",
    "* room to\n",
    "* to poise\n",
    "* poise the\n",
    "* the lance\n",
    "* lance or\n",
    "* or bend\n",
    "* bend the\n",
    "* the bow\n",
    "* bow but\n",
    "* but hand\n",
    "* hand to\n",
    "* to hand\n",
    "* hand and\n",
    "* and man\n",
    "* man to\n",
    "* to man\n",
    "* man they\n",
    "* they grow\n",
    "\n",
    "#### n-grams\n",
    "\n",
    "Two adjacent words together like this is known as an **bigram**. The case before where we took just one word is called a **unigram**. Three words is a **trigram** and so on. These are all special cases of **n-gram**, where _n_ is some number of words.\n",
    "\n",
    "#### Vocabulary choice\n",
    "\n",
    "As you may have suspected by now, the size and nature of the vocabulary you choose is vitally important. A large vocabulary will take more computational power and memory to analyse. A vocabulary with many rare words (so the count for these words is 0) creates what is called a _sparse_ vector, which has less useful information in it. Likewise, very common but largely meaningless words are often wasteful to include, for example, we would probably want to exclude a list of **stopwords**.\n",
    "\n",
    "#### Term Frequency–Inverse Document Frequency (TF-IDF)\n",
    "If you measure word frequency, highly frequent words come to dominate your results and yet they may not be as meaningful or interesting as rarer words. For example, if you are looking at articles about the history of the Moon landings, even if you have removed all the stopwords, you may well find that the words 'lunar', 'moon', 'landing', 'orbit', and 'earth' predominate. Subtle differences in topic between documents may be lost.\n",
    "\n",
    "One way to deal with this is to use a _weighting factor_ called **TF-IDF**. A value is calculated for each word that reflects:\n",
    "* Term frequency (TF) - the number of times the word appears in the document\n",
    "* Document frequency (DF) - the number of documents in the corpus that contain the word\n",
    "\n",
    "For example, if a very uncommon word is present in two documents, this word is weighted more highly than a word that is present in all documents in a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'maso')\n",
      "(1, 'mele')\n",
      "(2, 'máma')\n",
      "(3, 'ema')\n",
      "(4, 'má')\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "dct = Dictionary([\"máma mele maso\".split(), \"ema má máma\".split()])\n",
    "str(dct)\n",
    "for item in dct.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"máma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(2, 1)], {'is': 1, 'this': 1})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"máma\"], return_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7fba50dcb828>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary([text_data])\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 2),\n",
       "  (9, 2),\n",
       "  (10, 1),\n",
       "  (11, 2),\n",
       "  (12, 6),\n",
       "  (13, 2),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 3),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 3),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 2),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 1),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (39, 2),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1),\n",
       "  (46, 1),\n",
       "  (47, 1),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (50, 1),\n",
       "  (51, 3),\n",
       "  (52, 1),\n",
       "  (53, 2),\n",
       "  (54, 2),\n",
       "  (55, 2),\n",
       "  (56, 1),\n",
       "  (57, 2),\n",
       "  (58, 1),\n",
       "  (59, 1),\n",
       "  (60, 1),\n",
       "  (61, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 2),\n",
       "  (65, 2),\n",
       "  (66, 1),\n",
       "  (67, 1),\n",
       "  (68, 2),\n",
       "  (69, 1),\n",
       "  (70, 1),\n",
       "  (71, 3),\n",
       "  (72, 1),\n",
       "  (73, 1),\n",
       "  (74, 1),\n",
       "  (75, 1),\n",
       "  (76, 6),\n",
       "  (77, 1),\n",
       "  (78, 3),\n",
       "  (79, 1),\n",
       "  (80, 1),\n",
       "  (81, 2),\n",
       "  (82, 1),\n",
       "  (83, 2),\n",
       "  (84, 3),\n",
       "  (85, 2),\n",
       "  (86, 1),\n",
       "  (87, 1),\n",
       "  (88, 1),\n",
       "  (89, 1),\n",
       "  (90, 1),\n",
       "  (91, 1),\n",
       "  (92, 1),\n",
       "  (93, 2),\n",
       "  (94, 1),\n",
       "  (95, 2),\n",
       "  (96, 1),\n",
       "  (97, 1),\n",
       "  (98, 1),\n",
       "  (99, 2),\n",
       "  (100, 1),\n",
       "  (101, 1),\n",
       "  (102, 2),\n",
       "  (103, 3),\n",
       "  (104, 1),\n",
       "  (105, 1),\n",
       "  (106, 1),\n",
       "  (107, 3),\n",
       "  (108, 2),\n",
       "  (109, 1),\n",
       "  (110, 6),\n",
       "  (111, 1),\n",
       "  (112, 2),\n",
       "  (113, 3),\n",
       "  (114, 1),\n",
       "  (115, 1),\n",
       "  (116, 1),\n",
       "  (117, 3),\n",
       "  (118, 1),\n",
       "  (119, 1),\n",
       "  (120, 1),\n",
       "  (121, 1),\n",
       "  (122, 1),\n",
       "  (123, 1),\n",
       "  (124, 1),\n",
       "  (125, 1),\n",
       "  (126, 1),\n",
       "  (127, 2),\n",
       "  (128, 1),\n",
       "  (129, 2),\n",
       "  (130, 1),\n",
       "  (131, 1),\n",
       "  (132, 5),\n",
       "  (133, 1),\n",
       "  (134, 1),\n",
       "  (135, 1),\n",
       "  (136, 1),\n",
       "  (137, 2),\n",
       "  (138, 1),\n",
       "  (139, 5),\n",
       "  (140, 1),\n",
       "  (141, 1),\n",
       "  (142, 1),\n",
       "  (143, 1),\n",
       "  (144, 1),\n",
       "  (145, 1),\n",
       "  (146, 1),\n",
       "  (147, 3),\n",
       "  (148, 1),\n",
       "  (149, 1),\n",
       "  (150, 1),\n",
       "  (151, 5),\n",
       "  (152, 1),\n",
       "  (153, 1),\n",
       "  (154, 2),\n",
       "  (155, 2),\n",
       "  (156, 1),\n",
       "  (157, 1),\n",
       "  (158, 4),\n",
       "  (159, 1),\n",
       "  (160, 1),\n",
       "  (161, 1),\n",
       "  (162, 1),\n",
       "  (163, 1),\n",
       "  (164, 1),\n",
       "  (165, 1),\n",
       "  (166, 2),\n",
       "  (167, 1),\n",
       "  (168, 1),\n",
       "  (169, 1),\n",
       "  (170, 3),\n",
       "  (171, 1),\n",
       "  (172, 1),\n",
       "  (173, 1),\n",
       "  (174, 1),\n",
       "  (175, 1),\n",
       "  (176, 1),\n",
       "  (177, 1),\n",
       "  (178, 1),\n",
       "  (179, 1),\n",
       "  (180, 1),\n",
       "  (181, 1),\n",
       "  (182, 1),\n",
       "  (183, 1),\n",
       "  (184, 2),\n",
       "  (185, 1),\n",
       "  (186, 1),\n",
       "  (187, 2),\n",
       "  (188, 2),\n",
       "  (189, 1),\n",
       "  (190, 3),\n",
       "  (191, 1),\n",
       "  (192, 1),\n",
       "  (193, 1),\n",
       "  (194, 2),\n",
       "  (195, 1),\n",
       "  (196, 1),\n",
       "  (197, 2),\n",
       "  (198, 2),\n",
       "  (199, 1),\n",
       "  (200, 3),\n",
       "  (201, 1),\n",
       "  (202, 1),\n",
       "  (203, 1),\n",
       "  (204, 1),\n",
       "  (205, 6),\n",
       "  (206, 3),\n",
       "  (207, 2),\n",
       "  (208, 1),\n",
       "  (209, 1),\n",
       "  (210, 3),\n",
       "  (211, 1),\n",
       "  (212, 1),\n",
       "  (213, 2),\n",
       "  (214, 1),\n",
       "  (215, 1),\n",
       "  (216, 1),\n",
       "  (217, 1),\n",
       "  (218, 2),\n",
       "  (219, 1),\n",
       "  (220, 2),\n",
       "  (221, 3),\n",
       "  (222, 4),\n",
       "  (223, 1),\n",
       "  (224, 5),\n",
       "  (225, 1),\n",
       "  (226, 1),\n",
       "  (227, 1),\n",
       "  (228, 3),\n",
       "  (229, 4),\n",
       "  (230, 1),\n",
       "  (231, 3),\n",
       "  (232, 4),\n",
       "  (233, 1),\n",
       "  (234, 1),\n",
       "  (235, 1),\n",
       "  (236, 3),\n",
       "  (237, 2),\n",
       "  (238, 1),\n",
       "  (239, 2),\n",
       "  (240, 1),\n",
       "  (241, 4),\n",
       "  (242, 1),\n",
       "  (243, 1),\n",
       "  (244, 2),\n",
       "  (245, 4),\n",
       "  (246, 1),\n",
       "  (247, 2),\n",
       "  (248, 2),\n",
       "  (249, 1),\n",
       "  (250, 2),\n",
       "  (251, 1),\n",
       "  (252, 1),\n",
       "  (253, 1),\n",
       "  (254, 2),\n",
       "  (255, 9),\n",
       "  (256, 1),\n",
       "  (257, 1),\n",
       "  (258, 1),\n",
       "  (259, 1),\n",
       "  (260, 1),\n",
       "  (261, 1),\n",
       "  (262, 1),\n",
       "  (263, 2),\n",
       "  (264, 1),\n",
       "  (265, 1),\n",
       "  (266, 3),\n",
       "  (267, 1),\n",
       "  (268, 2),\n",
       "  (269, 1),\n",
       "  (270, 1),\n",
       "  (271, 1),\n",
       "  (272, 1),\n",
       "  (273, 2),\n",
       "  (274, 1),\n",
       "  (275, 1),\n",
       "  (276, 2),\n",
       "  (277, 1),\n",
       "  (278, 1),\n",
       "  (279, 13),\n",
       "  (280, 1),\n",
       "  (281, 1),\n",
       "  (282, 1),\n",
       "  (283, 1),\n",
       "  (284, 1),\n",
       "  (285, 1),\n",
       "  (286, 1),\n",
       "  (287, 3),\n",
       "  (288, 2),\n",
       "  (289, 1),\n",
       "  (290, 2),\n",
       "  (291, 1),\n",
       "  (292, 1),\n",
       "  (293, 1),\n",
       "  (294, 2),\n",
       "  (295, 1),\n",
       "  (296, 3),\n",
       "  (297, 1),\n",
       "  (298, 2),\n",
       "  (299, 1),\n",
       "  (300, 1),\n",
       "  (301, 1),\n",
       "  (302, 1),\n",
       "  (303, 2),\n",
       "  (304, 3),\n",
       "  (305, 7),\n",
       "  (306, 1),\n",
       "  (307, 1),\n",
       "  (308, 1),\n",
       "  (309, 1),\n",
       "  (310, 9),\n",
       "  (311, 1),\n",
       "  (312, 3),\n",
       "  (313, 22),\n",
       "  (314, 1),\n",
       "  (315, 3),\n",
       "  (316, 3),\n",
       "  (317, 2),\n",
       "  (318, 1),\n",
       "  (319, 1),\n",
       "  (320, 1),\n",
       "  (321, 1),\n",
       "  (322, 1),\n",
       "  (323, 2),\n",
       "  (324, 2),\n",
       "  (325, 1),\n",
       "  (326, 1),\n",
       "  (327, 1),\n",
       "  (328, 2),\n",
       "  (329, 1),\n",
       "  (330, 1),\n",
       "  (331, 2),\n",
       "  (332, 1),\n",
       "  (333, 1),\n",
       "  (334, 2),\n",
       "  (335, 2),\n",
       "  (336, 1),\n",
       "  (337, 1),\n",
       "  (338, 5),\n",
       "  (339, 1),\n",
       "  (340, 3),\n",
       "  (341, 1),\n",
       "  (342, 1),\n",
       "  (343, 1),\n",
       "  (344, 2),\n",
       "  (345, 2),\n",
       "  (346, 1),\n",
       "  (347, 1),\n",
       "  (348, 1),\n",
       "  (349, 1),\n",
       "  (350, 1),\n",
       "  (351, 1),\n",
       "  (352, 6),\n",
       "  (353, 1),\n",
       "  (354, 1),\n",
       "  (355, 1),\n",
       "  (356, 4),\n",
       "  (357, 1),\n",
       "  (358, 1),\n",
       "  (359, 1),\n",
       "  (360, 1),\n",
       "  (361, 1),\n",
       "  (362, 1),\n",
       "  (363, 1),\n",
       "  (364, 4),\n",
       "  (365, 1),\n",
       "  (366, 1),\n",
       "  (367, 1),\n",
       "  (368, 1),\n",
       "  (369, 1),\n",
       "  (370, 1),\n",
       "  (371, 1),\n",
       "  (372, 1),\n",
       "  (373, 2),\n",
       "  (374, 1),\n",
       "  (375, 1),\n",
       "  (376, 1),\n",
       "  (377, 1),\n",
       "  (378, 1),\n",
       "  (379, 1),\n",
       "  (380, 1),\n",
       "  (381, 1),\n",
       "  (382, 1),\n",
       "  (383, 2),\n",
       "  (384, 1),\n",
       "  (385, 1),\n",
       "  (386, 1),\n",
       "  (387, 2),\n",
       "  (388, 2),\n",
       "  (389, 1),\n",
       "  (390, 3),\n",
       "  (391, 1),\n",
       "  (392, 1),\n",
       "  (393, 1),\n",
       "  (394, 2),\n",
       "  (395, 2),\n",
       "  (396, 1),\n",
       "  (397, 3),\n",
       "  (398, 3),\n",
       "  (399, 2),\n",
       "  (400, 6),\n",
       "  (401, 2),\n",
       "  (402, 3),\n",
       "  (403, 4),\n",
       "  (404, 1),\n",
       "  (405, 2),\n",
       "  (406, 1),\n",
       "  (407, 1),\n",
       "  (408, 1),\n",
       "  (409, 2),\n",
       "  (410, 1),\n",
       "  (411, 4),\n",
       "  (412, 1),\n",
       "  (413, 1),\n",
       "  (414, 1),\n",
       "  (415, 1),\n",
       "  (416, 1),\n",
       "  (417, 1),\n",
       "  (418, 1),\n",
       "  (419, 1),\n",
       "  (420, 1),\n",
       "  (421, 1),\n",
       "  (422, 2),\n",
       "  (423, 1),\n",
       "  (424, 2),\n",
       "  (425, 1),\n",
       "  (426, 1),\n",
       "  (427, 1),\n",
       "  (428, 1),\n",
       "  (429, 1),\n",
       "  (430, 23),\n",
       "  (431, 3),\n",
       "  (432, 2),\n",
       "  (433, 1),\n",
       "  (434, 1),\n",
       "  (435, 1),\n",
       "  (436, 1),\n",
       "  (437, 4),\n",
       "  (438, 3),\n",
       "  (439, 1),\n",
       "  (440, 1),\n",
       "  (441, 9),\n",
       "  (442, 1),\n",
       "  (443, 1),\n",
       "  (444, 1),\n",
       "  (445, 1),\n",
       "  (446, 1),\n",
       "  (447, 1),\n",
       "  (448, 1),\n",
       "  (449, 1),\n",
       "  (450, 1),\n",
       "  (451, 1),\n",
       "  (452, 1),\n",
       "  (453, 1),\n",
       "  (454, 1),\n",
       "  (455, 1),\n",
       "  (456, 1),\n",
       "  (457, 3),\n",
       "  (458, 1),\n",
       "  (459, 1),\n",
       "  (460, 2),\n",
       "  (461, 1),\n",
       "  (462, 1),\n",
       "  (463, 1),\n",
       "  (464, 1),\n",
       "  (465, 1),\n",
       "  (466, 1),\n",
       "  (467, 1),\n",
       "  (468, 1),\n",
       "  (469, 2),\n",
       "  (470, 1),\n",
       "  (471, 1),\n",
       "  (472, 2),\n",
       "  (473, 1),\n",
       "  (474, 1),\n",
       "  (475, 1),\n",
       "  (476, 4),\n",
       "  (477, 1),\n",
       "  (478, 1),\n",
       "  (479, 7),\n",
       "  (480, 1),\n",
       "  (481, 2),\n",
       "  (482, 1),\n",
       "  (483, 1),\n",
       "  (484, 1),\n",
       "  (485, 1),\n",
       "  (486, 1),\n",
       "  (487, 1),\n",
       "  (488, 1),\n",
       "  (489, 1),\n",
       "  (490, 5),\n",
       "  (491, 3),\n",
       "  (492, 2),\n",
       "  (493, 1),\n",
       "  (494, 2),\n",
       "  (495, 1),\n",
       "  (496, 1),\n",
       "  (497, 3),\n",
       "  (498, 1),\n",
       "  (499, 2),\n",
       "  (500, 1),\n",
       "  (501, 1),\n",
       "  (502, 1),\n",
       "  (503, 1),\n",
       "  (504, 3),\n",
       "  (505, 1),\n",
       "  (506, 2),\n",
       "  (507, 2),\n",
       "  (508, 2),\n",
       "  (509, 1),\n",
       "  (510, 1),\n",
       "  (511, 1),\n",
       "  (512, 3),\n",
       "  (513, 1),\n",
       "  (514, 1),\n",
       "  (515, 3),\n",
       "  (516, 1),\n",
       "  (517, 1),\n",
       "  (518, 1),\n",
       "  (519, 1),\n",
       "  (520, 1),\n",
       "  (521, 1),\n",
       "  (522, 1),\n",
       "  (523, 1),\n",
       "  (524, 1),\n",
       "  (525, 2),\n",
       "  (526, 2),\n",
       "  (527, 4),\n",
       "  (528, 1),\n",
       "  (529, 1),\n",
       "  (530, 1),\n",
       "  (531, 16),\n",
       "  (532, 1)]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in [text_data]]\n",
    "corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.002*\"space\" + 0.002*\"new\" + 0.002*\"year\" + 0.002*\"man\"')\n",
      "(1, '0.002*\"space\" + 0.002*\"new\" + 0.002*\"year\" + 0.002*\"man\"')\n",
      "(2, '0.002*\"space\" + 0.002*\"new\" + 0.002*\"year\" + 0.002*\"man\"')\n",
      "(3, '0.023*\"space\" + 0.022*\"new\" + 0.016*\"year\" + 0.013*\"man\"')\n",
      "(4, '0.002*\"new\" + 0.002*\"year\" + 0.002*\"space\" + 0.002*\"man\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(26, 1), (56, 1), (58, 1)]\n",
      "[(0, 0.050024964), (1, 0.55387896), (2, 0.29605168), (3, 0.05002095), (4, 0.05002346)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = 'Practical Bayesian Optimization of Machine Learning Algorithms'\n",
    "new_doc = prepare_text_for_lda(new_doc)\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "print(new_doc_bow)\n",
    "print(ldamodel.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put this in somewhere?\n",
    "\n",
    "### A Bit About Machine Learning\n",
    "\n",
    "You may not have realised it when you started this notebook, but topic modelling is a Machine Learning (ML) method. ML is, of course, something of a hot topic...\n",
    "\n",
    "Topic modelling is described as an **unsupervised** **classification** technique.\n",
    "\n",
    "**Model**\n",
    "... \n",
    "\n",
    "**Classification**\n",
    "\n",
    "**Supervised and unsupervised techniques**\n",
    "\n",
    "Since topic modelling is an _unsupervised_ technique, we need to spend some time evaluating the topic models that are produced. We will do this in our worked example, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Python Basics\n",
    "As necessary as we go along. Maybe some clarification and extension of last time's.\n",
    "\n",
    "## Worked example\n",
    "* Corpus of more than one text\n",
    "* Remember cleaning from last time (may not actually do this in notebooks, but rather just recap)\n",
    "* Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Choosing the Right Text-Mining Techniques\n",
    "\n",
    "Table/Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Summary\n",
    "\n",
    "Blah\n",
    "\n",
    "Blah: \n",
    "\n",
    "* sdfsdfsdf\n",
    "* sdfsdfsdf\n",
    "\n",
    "👌👌👌\n",
    "\n",
    "The next notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## What's Next?\n",
    "If you have decided that text-mining in Python is for you, then here are some more resources to study in your own time.\n",
    "\n",
    "Topic modelling:\n",
    "\n",
    "* [Topic Modeling for Humanists: A Guided Tour](http://scottbot.net/topic-modeling-for-humanists-a-guided-tour/)\n",
    "\n",
    "Text-mining in general:\n",
    "\n",
    "* Follow a more in-depth set of Jupyter notebooks [The Art of Literary Text Analysis](https://github.com/sgsinclair/alta/blob/master/ipynb/ArtOfLiteraryTextAnalysis.ipynb).\n",
    "\n",
    "Learning Python:\n",
    "\n",
    "* Install Python using Anaconda on your computer: [Installing Anaconda on Windows](https://www.datacamp.com/community/tutorials/installing-anaconda-windows) [Installing Anaconda on Mac](https://www.datacamp.com/community/tutorials/installing-anaconda-mac-os-x).\n",
    "\n",
    "Even if you are not sure programming is for you, [Cambridge Digital Humanities](https://www.cdh.cam.ac.uk/) (CDH) has a number of resources to support your research. \n",
    "\n",
    "* CDH Learning - [training events/workshops](https://www.cdh.cam.ac.uk/learning/cdh-events) and mentoring programme\n",
    "* CDH Lab - email [lab@cdh.cam.ac.uk](mailto:lab@cdh.cam.ac.uk) for advice on your project, whether you are just getting started, somewhere in the middle, or thinking about the future\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
