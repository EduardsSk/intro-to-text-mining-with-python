{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic Modelling Fundamentals by Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpora dictionary of tokens using Gensim (corpora.Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a bag-of-words corpus using Gensim (corpora.Dictionary.doc2bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "A bag-of-words (BoW) corpus is a _vocabulary_ of the known words in the corpus together with some _measure_ of how often they occur. The measurement may be:\n",
    "* binary (presence or absence)\n",
    "* count (how many times the word occurs)\n",
    "* frequency (count divided by the total number of words).  \n",
    "\n",
    "This combination of vocabulary and measurement is called a **document vector**.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Here is a simplified example to demonstrate the principles of creating a vector from a document.\n",
    "\n",
    "Document (20 words):\n",
    "\n",
    ">'No room to poise the lance or bend the bow;\n",
    "> But hand to hand, and man to man, they grow:'\n",
    " \n",
    " (from _The Iliad of Homer_, translated by Alexander Pope (1899)) \n",
    "  \n",
    "Vocabulary of unique words (15 words):\n",
    "\n",
    "* no\n",
    "* room\n",
    "* to\n",
    "* poise\n",
    "* the\n",
    "* lance\n",
    "* or\n",
    "* bend\n",
    "* bow\n",
    "* but\n",
    "* hand\n",
    "* and\n",
    "* man\n",
    "* they\n",
    "* grow\n",
    "\n",
    "Count measurements (how many times each word appears in the document):\n",
    "\n",
    "* no = 1\n",
    "* room = 1\n",
    "* to = 3\n",
    "* poise = 1\n",
    "* the = 2\n",
    "* lance = 1\n",
    "* or = 1\n",
    "* bend = 1\n",
    "* bow = 1\n",
    "* but = 1\n",
    "* hand = 2\n",
    "* and = 1\n",
    "* man = 2\n",
    "* they = 1\n",
    "* grow = 1\n",
    "\n",
    "If we treat this vocabulary as a list with a fixed order, we can just extract the counts into a list. This is the document vector.\n",
    "\n",
    "`[1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1]`\n",
    "\n",
    "In order to compare other documents with this one for similarity, we could generate a document vector with the same vocabulary list for each document, or expand the vocabulary list to cover all the words in all the documents we are interested in.\n",
    "\n",
    "#### The 'bag' in bag of wordsprocessing\n",
    "\n",
    "In this most basic BoW model all order and location of the words is discarded. For example, it does not matter if the words 'red' and 'nose' are adjacent ('red nose'), or at the beginning or end of a sentence; BoW just treats the words individually. It is like a 'bag' of Scrabble™ tiles, where each tile is a word, all rattling around together in no particular order.\n",
    "\n",
    "It is possible to create a BoW corpus that uses two or more adjacent words, and potentially . For example, if you measure all pairs of words in our example document (above) you might end up with a vocabulary that looks like this:\n",
    "\n",
    "* no room\n",
    "* room to\n",
    "* to poise\n",
    "* poise the\n",
    "* the lance\n",
    "* lance or\n",
    "* or bend\n",
    "* bend the\n",
    "* the bow\n",
    "* bow but\n",
    "* but hand\n",
    "* hand to\n",
    "* to hand\n",
    "* hand and\n",
    "* and man\n",
    "* man to\n",
    "* to man\n",
    "* man they\n",
    "* they grow\n",
    "\n",
    "#### n-grams\n",
    "\n",
    "Two adjacent words together like this is known as an **bigram**. The case before where we took just one word is called a **unigram**. Three words is a **trigram** and so on. These are all special cases of **n-gram**, where _n_ is some number of words.\n",
    "\n",
    "#### Vocabulary choice\n",
    "\n",
    "As you may have suspected by now, the size and nature of the vocabulary you choose is vitally important. A large vocabulary will take more computational power and memory to analyse. A vocabulary with many rare words (so the count for these words is 0) creates what is called a _sparse_ vector, which has less useful information in it. Likewise, very common but largely meaningless words are often wasteful to include, for example, we would probably want to exclude a list of **stopwords**.\n",
    "\n",
    "#### Term Frequency–Inverse Document Frequency (TF-IDF)\n",
    "If you measure word frequency, highly frequent words come to dominate your results and yet they may not be as meaningful or interesting as rarer words. For example, if you are looking at articles about the history of the Moon landings, even if you have removed all the stopwords, you may well find that the words 'lunar', 'moon', 'landing', 'orbit', and 'earth' predominate. Subtle differences in topic between documents may be lost.\n",
    "\n",
    "One way to deal with this is to use a _weighting factor_ called **TF-IDF**. A value is calculated for each word that reflects:\n",
    "* Term frequency (TF) - the number of times the word appears in the document\n",
    "* Document frequency (DF) - the number of documents in the corpus that contain the word\n",
    "\n",
    "For example, if a very uncommon word is present in two documents, this word is weighted more highly than a word that is present in all documents in a corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bag-of-words corpus object to disc using pickle (alternatives?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LDA model to find topics using Gensim (gensim.models.ldamodel.LdaModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "dct = Dictionary([\"máma mele maso\".split(), \"ema má máma\".split()])\n",
    "str(dct)\n",
    "for item in dct.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"máma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"máma\"], return_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary([text_data])\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in [text_data]]\n",
    "corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = 'Practical Bayesian Optimization of Machine Learning Algorithms'\n",
    "new_doc = prepare_text_for_lda(new_doc)\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "print(new_doc_bow)\n",
    "print(ldamodel.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put this in somewhere?\n",
    "\n",
    "### A Bit About Machine Learning\n",
    "\n",
    "You may not have realised it when you started this notebook, but topic modelling is a Machine Learning (ML) method. ML is, of course, something of a hot topic...\n",
    "\n",
    "Topic modelling is described as an **unsupervised** **classification** technique.\n",
    "\n",
    "**Model**\n",
    "... \n",
    "\n",
    "**Classification**\n",
    "\n",
    "**Supervised and unsupervised techniques**\n",
    "\n",
    "Since topic modelling is an _unsupervised_ technique, we need to spend some time evaluating the topic models that are produced. We will do this in our worked example, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Summary\n",
    "\n",
    "Blah\n",
    "\n",
    "Blah: \n",
    "\n",
    "* sdfsdfsdf\n",
    "* sdfsdfsdf\n",
    "\n",
    "👌👌👌\n",
    "\n",
    "The next notebook ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
