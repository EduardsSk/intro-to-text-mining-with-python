{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic Modelling Fundamentals by Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Let's dive right in! 🏊🏽‍♀️**\n",
    "\n",
    "We have a corpus of 56 presidential speeches that we've prepared into clean lemmas.\n",
    "\n",
    "> Our question: **What are the underlying themes of these texts as a group?**\n",
    "\n",
    "---\n",
    "---\n",
    "## Loading the Corpus into Gensim from Files\n",
    "\n",
    "First, we have to load the corpus from text files into a _dictionary_. Gensim provides a special class of dictionary for us to work with called `gensim.corpora.Dictionary`.\n",
    "\n",
    "Get a list of all the files in the `data/inaugural` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "files = Path('data', 'inaugural').iterdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all the files in turn and add their contents to a big list of strings call `text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 56 documents loaded.\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as reader:       \n",
    "        document = []\n",
    "        for lemma in reader.read().split():\n",
    "            document.append(lemma)\n",
    "        text.append(document)\n",
    "\n",
    "print(f'There are {len(text)} documents loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(👆👆👆 The above code is a bit tricky; if you don't understand it yet, don't worry. You can skip over it and still follow along with the topic modelling.)\n",
    "\n",
    "Now we load the `text` into the Gensim `Dictionary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dictionary(6164 unique tokens: ['2', 'abandon', 'abide', 'abundance', 'abundantly']...)\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(text)\n",
    "str(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can understand that Gensim has found 6164 unique tokens in the corpus. But exactly what information does this `Dictionary` contain?\n",
    "\n",
    "In short, it is a _mapping_ between each token and a unique id number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 0,\n",
       " 'abandon': 1,\n",
       " 'abide': 2,\n",
       " 'abundance': 3,\n",
       " 'abundantly': 4,\n",
       " 'achieve': 5,\n",
       " 'action': 6,\n",
       " 'add': 7,\n",
       " 'advance': 8,\n",
       " 'allow': 9,\n",
       " 'altar': 10,\n",
       " 'america': 11,\n",
       " 'american': 12,\n",
       " 'americans': 13,\n",
       " 'ancient': 14,\n",
       " 'and': 15,\n",
       " 'ant': 16,\n",
       " 'article': 17,\n",
       " 'aside': 18,\n",
       " 'ask': 19,\n",
       " 'aspire': 20,\n",
       " 'await': 21,\n",
       " 'barely': 22,\n",
       " 'battalion': 23,\n",
       " 'bear': 24,\n",
       " 'before': 25,\n",
       " 'belief': 26,\n",
       " 'believe': 27,\n",
       " 'believer': 28,\n",
       " 'belong': 29,\n",
       " 'bend': 30,\n",
       " 'betray': 31,\n",
       " 'bill': 32,\n",
       " 'bind': 33,\n",
       " 'body': 34,\n",
       " 'bounty': 35,\n",
       " 'brave': 36,\n",
       " 'brighten': 37,\n",
       " 'bring': 38,\n",
       " 'build': 39,\n",
       " 'but': 40,\n",
       " 'call': 41,\n",
       " 'candle': 42,\n",
       " 'capitalist': 43,\n",
       " 'cause': 44,\n",
       " 'century': 45,\n",
       " 'change': 46,\n",
       " 'changeless': 47,\n",
       " 'character': 48,\n",
       " 'child': 49,\n",
       " 'choice': 50,\n",
       " 'citizen': 51,\n",
       " 'city': 52,\n",
       " 'clamor': 53,\n",
       " 'clear': 54,\n",
       " 'clerk': 55,\n",
       " 'close': 56,\n",
       " 'color': 57,\n",
       " 'come': 58,\n",
       " 'common': 59,\n",
       " 'companion': 60,\n",
       " 'conceive': 61,\n",
       " 'conquer': 62,\n",
       " 'constantly': 63,\n",
       " 'continent': 64,\n",
       " 'control': 65,\n",
       " 'conviction': 66,\n",
       " 'country': 67,\n",
       " 'countryman': 68,\n",
       " 'countryside': 69,\n",
       " 'course': 70,\n",
       " 'covenant': 71,\n",
       " 'create': 72,\n",
       " 'danger': 73,\n",
       " 'day': 74,\n",
       " 'decide': 75,\n",
       " 'deep': 76,\n",
       " 'defeat': 77,\n",
       " 'demand': 78,\n",
       " 'democracy': 79,\n",
       " 'deny': 80,\n",
       " 'depression': 81,\n",
       " 'desert': 82,\n",
       " 'destiny': 83,\n",
       " 'destroy': 84,\n",
       " 'destruction': 85,\n",
       " 'die': 86,\n",
       " 'difference': 87,\n",
       " 'different': 88,\n",
       " 'difficult': 89,\n",
       " 'discover': 90,\n",
       " 'divide': 91,\n",
       " 'division': 92,\n",
       " 'dominion': 93,\n",
       " 'dot': 94,\n",
       " 'dream': 95,\n",
       " 'each': 96,\n",
       " 'earn': 97,\n",
       " 'earth': 98,\n",
       " 'easily': 99,\n",
       " 'end': 100,\n",
       " 'endure': 101,\n",
       " 'enemy': 102,\n",
       " 'enlarge': 103,\n",
       " 'enterprise': 104,\n",
       " 'even': 105,\n",
       " 'excitement': 106,\n",
       " 'exile': 107,\n",
       " 'existence': 108,\n",
       " 'experience': 109,\n",
       " 'fail': 110,\n",
       " 'faith': 111,\n",
       " 'faithful': 112,\n",
       " 'fall': 113,\n",
       " 'family': 114,\n",
       " 'fantastic': 115,\n",
       " 'farewell': 116,\n",
       " 'farmer': 117,\n",
       " 'fate': 118,\n",
       " 'favor': 119,\n",
       " 'fellow': 120,\n",
       " 'fight': 121,\n",
       " 'find': 122,\n",
       " 'finish': 123,\n",
       " 'flourish': 124,\n",
       " 'follow': 125,\n",
       " 'for': 126,\n",
       " 'forebear': 127,\n",
       " 'foreign': 128,\n",
       " 'forget': 129,\n",
       " 'forth': 130,\n",
       " 'fragile': 131,\n",
       " 'free': 132,\n",
       " 'freedom': 133,\n",
       " 'friend': 134,\n",
       " 'frighten': 135,\n",
       " 'fruit': 136,\n",
       " 'future': 137,\n",
       " 'gain': 138,\n",
       " 'generation': 139,\n",
       " 'give': 140,\n",
       " 'globe': 141,\n",
       " 'go': 142,\n",
       " 'goal': 143,\n",
       " 'god': 144,\n",
       " 'government': 145,\n",
       " 'great': 146,\n",
       " 'greatness': 147,\n",
       " 'grind': 148,\n",
       " 'growth': 149,\n",
       " 'hand': 150,\n",
       " 'hang': 151,\n",
       " 'happiness': 152,\n",
       " 'hardship': 153,\n",
       " 'harsh': 154,\n",
       " 'harvest': 155,\n",
       " 'hate': 156,\n",
       " 'hatred': 157,\n",
       " 'head': 158,\n",
       " 'heal': 159,\n",
       " 'heart': 160,\n",
       " 'help': 161,\n",
       " 'heritage': 162,\n",
       " 'him': 163,\n",
       " 'his': 164,\n",
       " 'history': 165,\n",
       " 'hope': 166,\n",
       " 'hopeless': 167,\n",
       " 'hour': 168,\n",
       " 'how': 169,\n",
       " 'hungry': 170,\n",
       " 'imagine': 171,\n",
       " 'important': 172,\n",
       " 'increase': 173,\n",
       " 'incredible': 174,\n",
       " 'injustice': 175,\n",
       " 'inspire': 176,\n",
       " 'isolation': 177,\n",
       " 'join': 178,\n",
       " 'journey': 179,\n",
       " 'judge': 180,\n",
       " 'judgment': 181,\n",
       " 'justice': 182,\n",
       " 'keep': 183,\n",
       " 'know': 184,\n",
       " 'knowledge': 185,\n",
       " 'land': 186,\n",
       " 'lead': 187,\n",
       " 'leader': 188,\n",
       " 'learn': 189,\n",
       " 'let': 190,\n",
       " 'liberation': 191,\n",
       " 'liberty': 192,\n",
       " 'life': 193,\n",
       " 'lifetime': 194,\n",
       " 'like': 195,\n",
       " 'live': 196,\n",
       " 'long': 197,\n",
       " 'look': 198,\n",
       " 'majesty': 199,\n",
       " 'man': 200,\n",
       " 'mankind': 201,\n",
       " 'map': 202,\n",
       " 'mar': 203,\n",
       " 'mastery': 204,\n",
       " 'mean': 205,\n",
       " 'midst': 206,\n",
       " 'mighty': 207,\n",
       " 'miracle': 208,\n",
       " 'misery': 209,\n",
       " 'mission': 210,\n",
       " 'mistake': 211,\n",
       " 'moment': 212,\n",
       " 'move': 213,\n",
       " 'multiply': 214,\n",
       " 'nation': 215,\n",
       " 'nature': 216,\n",
       " 'need': 217,\n",
       " 'neighbor': 218,\n",
       " 'new': 219,\n",
       " 'november': 220,\n",
       " 'oath': 221,\n",
       " 'occasion': 222,\n",
       " 'old': 223,\n",
       " 'opinion': 224,\n",
       " 'order': 225,\n",
       " 'our': 226,\n",
       " 'outside': 227,\n",
       " 'passenger': 228,\n",
       " 'people': 229,\n",
       " 'place': 230,\n",
       " 'possibility': 231,\n",
       " 'poverty': 232,\n",
       " 'price': 233,\n",
       " 'prideful': 234,\n",
       " 'probe': 235,\n",
       " 'progress': 236,\n",
       " 'promise': 237,\n",
       " 'prosperous': 238,\n",
       " 'proud': 239,\n",
       " 'provide': 240,\n",
       " 'public': 241,\n",
       " 'purpose': 242,\n",
       " 'pursue': 243,\n",
       " 'pursuit': 244,\n",
       " 'rapid': 245,\n",
       " 'reach': 246,\n",
       " 'read': 247,\n",
       " 'real': 248,\n",
       " 'reason': 249,\n",
       " 'reject': 250,\n",
       " 'rejoice': 251,\n",
       " 'rekindle': 252,\n",
       " 'remember': 253,\n",
       " 'remind': 254,\n",
       " 'reopen': 255,\n",
       " 'repeat': 256,\n",
       " 'require': 257,\n",
       " 'resource': 258,\n",
       " 'rest': 259,\n",
       " 'retreat': 260,\n",
       " 'rich': 261,\n",
       " 'ridge': 262,\n",
       " 'right': 263,\n",
       " 'road': 264,\n",
       " 'rocket': 265,\n",
       " 'rush': 266,\n",
       " 'say': 267,\n",
       " 'scar': 268,\n",
       " 'scene': 269,\n",
       " 'scholar': 270,\n",
       " 'secret': 271,\n",
       " 'seek': 272,\n",
       " 'self': 273,\n",
       " 'servant': 274,\n",
       " 'serve': 275,\n",
       " 'shake': 276,\n",
       " 'shall': 277,\n",
       " 'share': 278,\n",
       " 'short': 279,\n",
       " 'shoulder': 280,\n",
       " 'sick': 281,\n",
       " 'sleep': 282,\n",
       " 'small': 283,\n",
       " 'society': 284,\n",
       " 'someday': 285,\n",
       " 'sorrowful': 286,\n",
       " 'space': 287,\n",
       " 'spill': 288,\n",
       " 'spin': 289,\n",
       " 'spirit': 290,\n",
       " 'stand': 291,\n",
       " 'star': 292,\n",
       " 'sterile': 293,\n",
       " 'stick': 294,\n",
       " 'strange': 295,\n",
       " 'stranger': 296,\n",
       " 'strength': 297,\n",
       " 'stretch': 298,\n",
       " 'strife': 299,\n",
       " 'struggle': 300,\n",
       " 'succeed': 301,\n",
       " 'success': 302,\n",
       " 'suffer': 303,\n",
       " 'surrender': 304,\n",
       " 'surrounding': 305,\n",
       " 'sweat': 306,\n",
       " 'take': 307,\n",
       " 'talent': 308,\n",
       " 'teach': 309,\n",
       " 'tear': 310,\n",
       " 'term': 311,\n",
       " 'terrific': 312,\n",
       " 'the': 313,\n",
       " 'there': 314,\n",
       " 'they': 315,\n",
       " 'think': 316,\n",
       " 'this': 317,\n",
       " 'thus': 318,\n",
       " 'thy': 319,\n",
       " 'time': 320,\n",
       " 'today': 321,\n",
       " 'toil': 322,\n",
       " 'tower': 323,\n",
       " 'transform': 324,\n",
       " 'treasure': 325,\n",
       " 'trouble': 326,\n",
       " 'true': 327,\n",
       " 'trust': 328,\n",
       " 'try': 329,\n",
       " 'two': 330,\n",
       " 'tyranny': 331,\n",
       " 'unattended': 332,\n",
       " 'uncertain': 333,\n",
       " 'unchanged': 334,\n",
       " 'unclimbed': 335,\n",
       " 'uncrossed': 336,\n",
       " 'under': 337,\n",
       " 'underneath': 338,\n",
       " 'union': 339,\n",
       " 'unity': 340,\n",
       " 'unplowed': 341,\n",
       " 'uproot': 342,\n",
       " 'value': 343,\n",
       " 'victory': 344,\n",
       " 'vigilantly': 345,\n",
       " 'want': 346,\n",
       " 'war': 347,\n",
       " 'waste': 348,\n",
       " 'way': 349,\n",
       " 'wealth': 350,\n",
       " 'weapon': 351,\n",
       " 'welcome': 352,\n",
       " 'well': 353,\n",
       " 'wilderness': 354,\n",
       " 'wind': 355,\n",
       " 'wisdom': 356,\n",
       " 'without': 357,\n",
       " 'word': 358,\n",
       " 'work': 359,\n",
       " 'worker': 360,\n",
       " 'world': 361,\n",
       " 'wound': 362,\n",
       " 'write': 363,\n",
       " 'year': 364,\n",
       " 'young': 365,\n",
       " '\\ufeff1': 366,\n",
       " 'ability': 367,\n",
       " 'abject': 368,\n",
       " 'above': 369,\n",
       " 'acceptance': 370,\n",
       " 'accomplishment': 371,\n",
       " 'accountability': 372,\n",
       " 'achievement': 373,\n",
       " 'acquiescence': 374,\n",
       " 'activity': 375,\n",
       " 'adjust': 376,\n",
       " 'advancement': 377,\n",
       " 'advantage': 378,\n",
       " 'advise': 379,\n",
       " 'affair': 380,\n",
       " 'agent': 381,\n",
       " 'aggregation': 382,\n",
       " 'aid': 383,\n",
       " 'allure': 384,\n",
       " 'americanism': 385,\n",
       " 'announce': 386,\n",
       " 'anxiety': 387,\n",
       " 'appall': 388,\n",
       " 'appeal': 389,\n",
       " 'appointee': 390,\n",
       " 'appointment': 391,\n",
       " 'approach': 392,\n",
       " 'approval': 393,\n",
       " 'arouse': 394,\n",
       " 'assume': 395,\n",
       " 'assurance': 396,\n",
       " 'attachment': 397,\n",
       " 'attack': 398,\n",
       " 'avert': 399,\n",
       " 'avoid': 400,\n",
       " 'award': 401,\n",
       " 'away': 402,\n",
       " 'badge': 403,\n",
       " 'bane': 404,\n",
       " 'be': 405,\n",
       " 'begin': 406,\n",
       " 'behoove': 407,\n",
       " 'beneficence': 408,\n",
       " 'beneficent': 409,\n",
       " 'benefit': 410,\n",
       " 'bequeath': 411,\n",
       " 'blind': 412,\n",
       " 'border': 413,\n",
       " 'bound': 414,\n",
       " 'branch': 415,\n",
       " 'briefly': 416,\n",
       " 'brood': 417,\n",
       " 'burden': 418,\n",
       " 'business': 419,\n",
       " 'cabinet': 420,\n",
       " 'calculation': 421,\n",
       " 'carry': 422,\n",
       " 'certain': 423,\n",
       " 'challenge': 424,\n",
       " 'cheapness': 425,\n",
       " 'check': 426,\n",
       " 'cheerfully': 427,\n",
       " 'choose': 428,\n",
       " 'citizenship': 429,\n",
       " 'civil': 430,\n",
       " 'civilization': 431,\n",
       " 'closely': 432,\n",
       " 'collapse': 433,\n",
       " 'combination': 434,\n",
       " 'comfort': 435,\n",
       " 'command': 436,\n",
       " 'compensation': 437,\n",
       " 'competency': 438,\n",
       " 'competition': 439,\n",
       " 'complete': 440,\n",
       " 'concede': 441,\n",
       " 'concern': 442,\n",
       " 'concession': 443,\n",
       " 'condemn': 444,\n",
       " 'condition': 445,\n",
       " 'conduct': 446,\n",
       " 'confidence': 447,\n",
       " 'confident': 448,\n",
       " 'confront': 449,\n",
       " 'conservative': 450,\n",
       " 'considerately': 451,\n",
       " 'consistency': 452,\n",
       " 'conspiracy': 453,\n",
       " 'constant': 454,\n",
       " 'constitute': 455,\n",
       " 'constitution': 456,\n",
       " 'constitutional': 457,\n",
       " 'constrain': 458,\n",
       " 'consummation': 459,\n",
       " 'contain': 460,\n",
       " 'contemplate': 461,\n",
       " 'contempt': 462,\n",
       " 'content': 463,\n",
       " 'contentment': 464,\n",
       " 'cooperate': 465,\n",
       " 'cooperation': 466,\n",
       " 'counsel': 467,\n",
       " 'court': 468,\n",
       " 'craft': 469,\n",
       " 'credit': 470,\n",
       " 'crime': 471,\n",
       " 'cupidity': 472,\n",
       " 'currency': 473,\n",
       " 'daily': 474,\n",
       " 'deal': 475,\n",
       " 'dealings': 476,\n",
       " 'decree': 477,\n",
       " 'dedicate': 478,\n",
       " 'deem': 479,\n",
       " 'deeply': 480,\n",
       " 'defend': 481,\n",
       " 'defense': 482,\n",
       " 'define': 483,\n",
       " 'defy': 484,\n",
       " 'degradation': 485,\n",
       " 'degrade': 486,\n",
       " 'delusion': 487,\n",
       " 'demonstrate': 488,\n",
       " 'demoralize': 489,\n",
       " 'denial': 490,\n",
       " 'dependence': 491,\n",
       " 'deplorably': 492,\n",
       " 'depreciation': 493,\n",
       " 'derive': 494,\n",
       " 'deserve': 495,\n",
       " 'design': 496,\n",
       " 'desire': 497,\n",
       " 'determine': 498,\n",
       " 'devote': 499,\n",
       " 'devotion': 500,\n",
       " 'dictate': 501,\n",
       " 'direct': 502,\n",
       " 'disable': 503,\n",
       " 'disaster': 504,\n",
       " 'discouragement': 505,\n",
       " 'discredit': 506,\n",
       " 'disease': 507,\n",
       " 'disinterested': 508,\n",
       " 'disposition': 509,\n",
       " 'disregard': 510,\n",
       " 'distribution': 511,\n",
       " 'doom': 512,\n",
       " 'doubt': 513,\n",
       " 'duty': 514,\n",
       " 'economy': 515,\n",
       " 'education': 516,\n",
       " 'effective': 517,\n",
       " 'efficiency': 518,\n",
       " 'effort': 519,\n",
       " 'element': 520,\n",
       " 'elevation': 521,\n",
       " 'embarrass': 522,\n",
       " 'encourage': 523,\n",
       " 'encouragement': 524,\n",
       " 'enforce': 525,\n",
       " 'enjoin': 526,\n",
       " 'enjoy': 527,\n",
       " 'enjoyment': 528,\n",
       " 'enlighten': 529,\n",
       " 'ennoble': 530,\n",
       " 'enthusiasm': 531,\n",
       " 'entitle': 532,\n",
       " 'equality': 533,\n",
       " 'equally': 534,\n",
       " 'equitable': 535,\n",
       " 'escape': 536,\n",
       " 'especial': 537,\n",
       " 'especially': 538,\n",
       " 'establish': 539,\n",
       " 'evade': 540,\n",
       " 'every': 541,\n",
       " 'evil': 542,\n",
       " 'exact': 543,\n",
       " 'exaction': 544,\n",
       " 'exaggerate': 545,\n",
       " 'excuse': 546,\n",
       " 'executive': 547,\n",
       " 'exercise': 548,\n",
       " 'expansion': 549,\n",
       " 'expect': 550,\n",
       " 'expenditure': 551,\n",
       " 'expose': 552,\n",
       " 'exposure': 553,\n",
       " 'expression': 554,\n",
       " 'extent': 555,\n",
       " 'extravagance': 556,\n",
       " 'failure': 557,\n",
       " 'fair': 558,\n",
       " 'fairness': 559,\n",
       " 'familiarity': 560,\n",
       " 'far': 561,\n",
       " 'father': 562,\n",
       " 'fault': 563,\n",
       " 'favoritism': 564,\n",
       " 'federal': 565,\n",
       " 'field': 566,\n",
       " 'finance': 567,\n",
       " 'financial': 568,\n",
       " 'fit': 569,\n",
       " 'fitness': 570,\n",
       " 'fix': 571,\n",
       " 'forbearance': 572,\n",
       " 'form': 573,\n",
       " 'frank': 574,\n",
       " 'frequently': 575,\n",
       " 'frugality': 576,\n",
       " 'fully': 577,\n",
       " 'function': 578,\n",
       " 'fund': 579,\n",
       " 'furnish': 580,\n",
       " 'general': 581,\n",
       " 'generous': 582,\n",
       " 'good': 583,\n",
       " 'goodness': 584,\n",
       " 'govern': 585,\n",
       " 'governmental': 586,\n",
       " 'grant': 587,\n",
       " 'grateful': 588,\n",
       " 'gratitude': 589,\n",
       " 'gravity': 590,\n",
       " 'guarantee': 591,\n",
       " 'guaranty': 592,\n",
       " 'guide': 593,\n",
       " 'hall': 594,\n",
       " 'hardihood': 595,\n",
       " 'hardly': 596,\n",
       " 'harmonious': 597,\n",
       " 'health': 598,\n",
       " 'hearty': 599,\n",
       " 'heedless': 600,\n",
       " 'heedlessness': 601,\n",
       " 'hold': 602,\n",
       " 'home': 603,\n",
       " 'honest': 604,\n",
       " 'honestly': 605,\n",
       " 'honesty': 606,\n",
       " 'honor': 607,\n",
       " 'human': 608,\n",
       " 'humanity': 609,\n",
       " 'humbly': 610,\n",
       " 'idea': 611,\n",
       " 'ill': 612,\n",
       " 'immense': 613,\n",
       " 'impatience': 614,\n",
       " 'importance': 615,\n",
       " 'impose': 616,\n",
       " 'impress': 617,\n",
       " 'impressively': 618,\n",
       " 'impulse': 619,\n",
       " 'impunity': 620,\n",
       " 'incentive': 621,\n",
       " 'incident': 622,\n",
       " 'include': 623,\n",
       " 'inconsistent': 624,\n",
       " 'independent': 625,\n",
       " 'indians': 626,\n",
       " 'indicate': 627,\n",
       " 'individual': 628,\n",
       " 'inexorable': 629,\n",
       " 'infirmity': 630,\n",
       " 'influence': 631,\n",
       " 'inordinate': 632,\n",
       " 'insidious': 633,\n",
       " 'insist': 634,\n",
       " 'instead': 635,\n",
       " 'institution': 636,\n",
       " 'instrumentality': 637,\n",
       " 'insuperable': 638,\n",
       " 'integrity': 639,\n",
       " 'interest': 640,\n",
       " 'interference': 641,\n",
       " 'intervene': 642,\n",
       " 'intolerance': 643,\n",
       " 'invest': 644,\n",
       " 'its': 645,\n",
       " 'justification': 646,\n",
       " 'justly': 647,\n",
       " 'kindred': 648,\n",
       " 'labor': 649,\n",
       " 'languish': 650,\n",
       " 'law': 651,\n",
       " 'legislation': 652,\n",
       " 'legislative': 653,\n",
       " 'legitimate': 654,\n",
       " 'lesson': 655,\n",
       " 'lift': 656,\n",
       " 'limit': 657,\n",
       " 'limitation': 658,\n",
       " 'locate': 659,\n",
       " 'lose': 660,\n",
       " 'lot': 661,\n",
       " 'love': 662,\n",
       " 'loyally': 663,\n",
       " 'loyalty': 664,\n",
       " 'lurk': 665,\n",
       " 'madness': 666,\n",
       " 'maintain': 667,\n",
       " 'maintenance': 668,\n",
       " 'mandate': 669,\n",
       " 'manifestly': 670,\n",
       " 'manliness': 671,\n",
       " 'master': 672,\n",
       " 'meantime': 673,\n",
       " 'measure': 674,\n",
       " 'menace': 675,\n",
       " 'mercy': 676,\n",
       " 'method': 677,\n",
       " 'mind': 678,\n",
       " 'mindful': 679,\n",
       " 'misappropriation': 680,\n",
       " 'misconception': 681,\n",
       " 'mode': 682,\n",
       " 'money': 683,\n",
       " 'national': 684,\n",
       " 'near': 685,\n",
       " 'necessary': 686,\n",
       " 'necessity': 687,\n",
       " 'neglect': 688,\n",
       " 'obedience': 689,\n",
       " 'object': 690,\n",
       " 'obstacle': 691,\n",
       " 'office': 692,\n",
       " 'official': 693,\n",
       " 'one': 694,\n",
       " 'open': 695,\n",
       " 'operation': 696,\n",
       " 'oppose': 697,\n",
       " 'opposition': 698,\n",
       " 'ought': 699,\n",
       " 'outgrow': 700,\n",
       " 'overleap': 701,\n",
       " 'part': 702,\n",
       " 'partisan': 703,\n",
       " 'party': 704,\n",
       " 'passion': 705,\n",
       " 'paternalism': 706,\n",
       " 'path': 707,\n",
       " 'patriotic': 708,\n",
       " 'patriotically': 709,\n",
       " 'pay': 710,\n",
       " 'pension': 711,\n",
       " 'perform': 712,\n",
       " 'peril': 713,\n",
       " 'permit': 714,\n",
       " 'personal': 715,\n",
       " 'perversion': 716,\n",
       " 'pervert': 717,\n",
       " 'phasis': 718,\n",
       " 'phrase': 719,\n",
       " 'pitiful': 720,\n",
       " 'plain': 721,\n",
       " 'plan': 722,\n",
       " 'pledge': 723,\n",
       " 'policy': 724,\n",
       " 'political': 725,\n",
       " 'popular': 726,\n",
       " 'portion': 727,\n",
       " 'positive': 728,\n",
       " 'positively': 729,\n",
       " 'power': 730,\n",
       " 'powerful': 731,\n",
       " 'precaution': 732,\n",
       " 'present': 733,\n",
       " 'preserve': 734,\n",
       " 'prevalence': 735,\n",
       " 'prevent': 736,\n",
       " 'pride': 737,\n",
       " 'principle': 738,\n",
       " 'private': 739,\n",
       " 'proclaim': 740,\n",
       " 'prodigality': 741,\n",
       " 'production': 742,\n",
       " 'progeny': 743,\n",
       " 'prompt': 744,\n",
       " 'promptly': 745,\n",
       " 'prosperity': 746,\n",
       " 'prostitute': 747,\n",
       " 'protect': 748,\n",
       " 'protection': 749,\n",
       " 'prudent': 750,\n",
       " 'punishment': 751,\n",
       " 'purchase': 752,\n",
       " 'purification': 753,\n",
       " 'question': 754,\n",
       " 'race': 755,\n",
       " 'realize': 756,\n",
       " 'reckless': 757,\n",
       " 'recognition': 758,\n",
       " 'rectification': 759,\n",
       " 'redemption': 760,\n",
       " 'reduce': 761,\n",
       " 'refer': 762,\n",
       " 'reform': 763,\n",
       " 'refusal': 764,\n",
       " 'regard': 765,\n",
       " 'reinstate': 766,\n",
       " 'relate': 767,\n",
       " 'relation': 768,\n",
       " 'reliance': 769,\n",
       " 'relieve': 770,\n",
       " 'remedial': 771,\n",
       " 'remove': 772,\n",
       " 'repose': 773,\n",
       " 'represent': 774,\n",
       " 'republican': 775,\n",
       " 'reservation': 776,\n",
       " 'responsibility': 777,\n",
       " 'restlessness': 778,\n",
       " 'restrain': 779,\n",
       " 'restraint': 780,\n",
       " 'result': 781,\n",
       " 'retard': 782,\n",
       " 'return': 783,\n",
       " 'revenue': 784,\n",
       " 'reverently': 785,\n",
       " 'reward': 786,\n",
       " 'rise': 787,\n",
       " 'robust': 788,\n",
       " 'rude': 789,\n",
       " 'rule': 790,\n",
       " 'safely': 791,\n",
       " 'safety': 792,\n",
       " 'sake': 793,\n",
       " 'sanction': 794,\n",
       " 'sap': 795,\n",
       " 'save': 796,\n",
       " 'scheme': 797,\n",
       " 'secure': 798,\n",
       " 'selfish': 799,\n",
       " 'sense': 800,\n",
       " 'sentiment': 801,\n",
       " 'service': 802,\n",
       " 'set': 803,\n",
       " 'shield': 804,\n",
       " 'shock': 805,\n",
       " 'situation': 806,\n",
       " 'solemn': 807,\n",
       " 'solicitude': 808,\n",
       " 'sordid': 809,\n",
       " 'sound': 810,\n",
       " 'sphere': 811,\n",
       " 'spoil': 812,\n",
       " 'stable': 813,\n",
       " 'state': 814,\n",
       " 'statesmanship': 815,\n",
       " 'station': 816,\n",
       " 'stern': 817,\n",
       " 'stifle': 818,\n",
       " 'stimulate': 819,\n",
       " 'strict': 820,\n",
       " 'strive': 821,\n",
       " 'strong': 822,\n",
       " 'stupefy': 823,\n",
       " 'stupendous': 824,\n",
       " 'sturdiness': 825,\n",
       " 'sturdy': 826,\n",
       " 'subject': 827,\n",
       " 'subsidy': 828,\n",
       " 'substitute': 829,\n",
       " 'sudden': 830,\n",
       " 'sufficiency': 831,\n",
       " 'suggest': 832,\n",
       " 'superiority': 833,\n",
       " 'supersede': 834,\n",
       " 'support': 835,\n",
       " 'supremacy': 836,\n",
       " 'supreme': 837,\n",
       " 'sure': 838,\n",
       " 'swift': 839,\n",
       " 'symptom': 840,\n",
       " 'tariff': 841,\n",
       " 'task': 842,\n",
       " 'tax': 843,\n",
       " 'taxation': 844,\n",
       " 'temper': 845,\n",
       " 'tempt': 846,\n",
       " 'temptation': 847,\n",
       " 'tend': 848,\n",
       " 'tendency': 849,\n",
       " 'theory': 850,\n",
       " 'thoughtful': 851,\n",
       " 'threaten': 852,\n",
       " 'thrift': 853,\n",
       " 'toleration': 854,\n",
       " 'trace': 855,\n",
       " 'trade': 856,\n",
       " 'trait': 857,\n",
       " 'treat': 858,\n",
       " 'truth': 859,\n",
       " 'turn': 860,\n",
       " 'unaided': 861,\n",
       " 'underlie': 862,\n",
       " 'undermine': 863,\n",
       " 'undertake': 864,\n",
       " 'unequal': 865,\n",
       " 'unheeded': 866,\n",
       " 'unimpaired': 867,\n",
       " 'unite': 868,\n",
       " 'unlearn': 869,\n",
       " 'unmoved': 870,\n",
       " 'unnatural': 871,\n",
       " 'unremittingly': 872,\n",
       " 'unreserved': 873,\n",
       " 'unvexed': 874,\n",
       " 'unwholesome': 875,\n",
       " 'unwilling': 876,\n",
       " 'use': 877,\n",
       " 'usefulness': 878,\n",
       " 'usually': 879,\n",
       " 'utmost': 880,\n",
       " 'veneration': 881,\n",
       " 'verdict': 882,\n",
       " 'vicious': 883,\n",
       " 'vigor': 884,\n",
       " 'vindictiveness': 885,\n",
       " 'violence': 886,\n",
       " 'virtue': 887,\n",
       " 'vital': 888,\n",
       " 'vitals': 889,\n",
       " 'voter': 890,\n",
       " 'wage': 891,\n",
       " 'ward': 892,\n",
       " 'watch': 893,\n",
       " 'weakness': 894,\n",
       " 'welfare': 895,\n",
       " 'when': 896,\n",
       " 'while': 897,\n",
       " 'wholesome': 898,\n",
       " 'wild': 899,\n",
       " 'wily': 900,\n",
       " 'wise': 901,\n",
       " 'wisely': 902,\n",
       " 'withhold': 903,\n",
       " 'witness': 904,\n",
       " 'wonderful': 905,\n",
       " 'wrong': 906,\n",
       " 'abolish': 907,\n",
       " 'acrimony': 908,\n",
       " 'adversary': 909,\n",
       " 'african': 910,\n",
       " 'age': 911,\n",
       " 'ago': 912,\n",
       " 'ahead': 913,\n",
       " 'air': 914,\n",
       " 'airport': 915,\n",
       " 'alive': 916,\n",
       " 'along': 917,\n",
       " 'answer': 918,\n",
       " 'anymore': 919,\n",
       " 'apart': 920,\n",
       " 'army': 921,\n",
       " 'atom': 922,\n",
       " 'awful': 923,\n",
       " 'balance': 924,\n",
       " 'beloved': 925,\n",
       " 'bernardin': 926,\n",
       " 'beyond': 927,\n",
       " 'bicker': 928,\n",
       " 'big': 929,\n",
       " 'biological': 930,\n",
       " 'bless': 931,\n",
       " 'blessing': 932,\n",
       " 'bloodshed': 933,\n",
       " 'blueprint': 934,\n",
       " 'bold': 935,\n",
       " 'bond': 936,\n",
       " 'boy': 937,\n",
       " 'breach': 938,\n",
       " 'bridge': 939,\n",
       " 'bright': 940,\n",
       " 'broad': 941,\n",
       " 'budget': 942,\n",
       " 'camp': 943,\n",
       " 'cardinal': 944,\n",
       " 'care': 945,\n",
       " 'ceaseless': 946,\n",
       " 'celebrate': 947,\n",
       " 'center': 948,\n",
       " 'chance': 949,\n",
       " 'chapter': 950,\n",
       " 'chemical': 951,\n",
       " 'circle': 952,\n",
       " 'claim': 953,\n",
       " 'class': 954,\n",
       " 'classroom': 955,\n",
       " 'clean': 956,\n",
       " 'cloak': 957,\n",
       " 'coast': 958,\n",
       " 'cold': 959,\n",
       " 'college': 960,\n",
       " 'commerce': 961,\n",
       " 'commonplace': 962,\n",
       " 'community': 963,\n",
       " 'congress': 964,\n",
       " 'connection': 965,\n",
       " 'conscience': 966,\n",
       " 'conservation': 967,\n",
       " 'courage': 968,\n",
       " 'creed': 969,\n",
       " 'cripple': 970,\n",
       " 'cross': 971,\n",
       " 'culture': 972,\n",
       " 'cure': 973,\n",
       " 'curse': 974,\n",
       " 'dare': 975,\n",
       " 'dark': 976,\n",
       " 'dawn': 977,\n",
       " 'debate': 978,\n",
       " 'decade': 979,\n",
       " 'decency': 980,\n",
       " 'declare': 981,\n",
       " 'decode': 982,\n",
       " 'deepen': 983,\n",
       " 'depend': 984,\n",
       " 'deplore': 985,\n",
       " 'destine': 986,\n",
       " 'dictatorship': 987,\n",
       " 'dignity': 988,\n",
       " 'din': 989,\n",
       " 'diversity': 990,\n",
       " 'door': 991,\n",
       " 'drug': 992,\n",
       " 'echo': 993,\n",
       " 'edge': 994,\n",
       " 'educational': 995,\n",
       " 'embrace': 996,\n",
       " 'encyclopedia': 997,\n",
       " 'environment': 998,\n",
       " 'equal': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The key to understanding Natural Language Processing (NLP) is that the computer can only do computations on **numbers**. We have to present our corpus for analysis in a numerical form — and make human sense of it at the end.\n",
    "\n",
    "Now we have got the corpus loaded we can start to analyse its contents. The first step is to count the words to create a **bag-of-words** corpus.\n",
    "\n",
    "---\n",
    "---\n",
    "## Bag of words\n",
    "\n",
    "A bag-of-words (BoW) corpus is a _vocabulary_ of the known words in the corpus together with some _measure_ of how often they occur. The measurement may be:\n",
    "* binary (presence or absence)\n",
    "* count (how many times the word occurs)\n",
    "* frequency (count divided by the total number of words).  \n",
    "\n",
    "This combination of vocabulary and measurement is called a **document vector**.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Here is a simplified example to demonstrate the principles of creating a vector from a document.\n",
    "\n",
    "Document (20 words):\n",
    "\n",
    ">'No room to poise the lance or bend the bow;\n",
    "> But hand to hand, and man to man, they grow:'\n",
    " \n",
    " (from _The Iliad of Homer_, translated by Alexander Pope (1899)) \n",
    "  \n",
    "Vocabulary of unique words (15 words):\n",
    "\n",
    "* no\n",
    "* room\n",
    "* to\n",
    "* poise\n",
    "* the\n",
    "* lance\n",
    "* or\n",
    "* bend\n",
    "* bow\n",
    "* but\n",
    "* hand\n",
    "* and\n",
    "* man\n",
    "* they\n",
    "* grow\n",
    "\n",
    "Count measurements (how many times each word appears in the document):\n",
    "\n",
    "* no = 1\n",
    "* room = 1\n",
    "* to = 3\n",
    "* poise = 1\n",
    "* the = 2\n",
    "* lance = 1\n",
    "* or = 1\n",
    "* bend = 1\n",
    "* bow = 1\n",
    "* but = 1\n",
    "* hand = 2\n",
    "* and = 1\n",
    "* man = 2\n",
    "* they = 1\n",
    "* grow = 1\n",
    "\n",
    "If we treat this vocabulary as a list with a fixed order, we can just extract the counts into a list. This is the document vector.\n",
    "\n",
    "`[1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1]`\n",
    "\n",
    "In order to compare other documents with this one for similarity, we could generate a document vector with the same vocabulary list for each document, or expand the vocabulary list to cover all the words in all the documents we are interested in.\n",
    "\n",
    "#### The 'bag' in bag of wordsprocessing\n",
    "\n",
    "In this most basic BoW model all order and location of the words is discarded. For example, it does not matter if the words 'red' and 'nose' are adjacent ('red nose'), or at the beginning or end of a sentence; BoW just treats the words individually. It is like a 'bag' of Scrabble™ tiles, where each tile is a word, all rattling around together in no particular order.\n",
    "\n",
    "It is possible to create a BoW corpus that uses two or more adjacent words, and potentially . For example, if you measure all pairs of words in our example document (above) you might end up with a vocabulary that looks like this:\n",
    "\n",
    "* no room\n",
    "* room to\n",
    "* to poise\n",
    "* poise the\n",
    "* the lance\n",
    "* lance or\n",
    "* or bend\n",
    "* bend the\n",
    "* the bow\n",
    "* bow but\n",
    "* but hand\n",
    "* hand to\n",
    "* to hand\n",
    "* hand and\n",
    "* and man\n",
    "* man to\n",
    "* to man\n",
    "* man they\n",
    "* they grow\n",
    "\n",
    "### n-grams\n",
    "\n",
    "Two adjacent words together like this is known as an **bigram**. The case before where we took just one word is called a **unigram**. Three words is a **trigram** and so on. These are all special cases of **n-gram**, where _n_ is some number of words.\n",
    "\n",
    "### Vocabulary choice\n",
    "\n",
    "As you may have suspected by now, the size and nature of the vocabulary you choose is vitally important. A large vocabulary will take more computational power and memory to analyse. A vocabulary with many rare words (so the count for these words is 0) creates what is called a _sparse_ vector, which has less useful information in it. Likewise, very common but largely meaningless words are often wasteful to include, for example, we would probably want to exclude a list of **stopwords**.\n",
    "\n",
    "### Term Frequency–Inverse Document Frequency (TF-IDF)\n",
    "If you measure word frequency, highly frequent words come to dominate your results and yet they may not be as meaningful or interesting as rarer words. For example, if you are looking at articles about the history of the Moon landings, even if you have removed all the stopwords, you may well find that the words 'lunar', 'moon', 'landing', 'orbit', and 'earth' predominate. Subtle differences in topic between documents may be lost.\n",
    "\n",
    "One way to deal with this is to use a _weighting factor_ called **TF-IDF**. A value is calculated for each word that reflects:\n",
    "* Term frequency (TF) - the number of times the word appears in the document\n",
    "* Document frequency (DF) - the number of documents in the corpus that contain the word\n",
    "\n",
    "For example, if a very uncommon word is present in two documents, this word is weighted more highly than a word that is present in all documents in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a bag-of-words corpus using Gensim (corpora.Dictionary.doc2bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bag-of-words corpus object to disc using pickle (alternatives?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LDA model to find topics using Gensim (gensim.models.ldamodel.LdaModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'maso')\n",
      "(1, 'mele')\n",
      "(2, 'máma')\n",
      "(3, 'ema')\n",
      "(4, 'má')\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "dct = Dictionary([\"máma mele maso\".split(), \"ema má máma\".split()])\n",
    "str(dct)\n",
    "for item in dct.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"máma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(2, 1)], {'is': 1, 'this': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"máma\"], return_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b2d7fc428858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_data' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary([text_data])\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f015d93b94ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_data' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in [text_data]]\n",
    "corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = 'Practical Bayesian Optimization of Machine Learning Algorithms'\n",
    "new_doc = prepare_text_for_lda(new_doc)\n",
    "new_doc_bow = dictionary.doc2bow(new_doc)\n",
    "print(new_doc_bow)\n",
    "print(ldamodel.get_document_topics(new_doc_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put this in somewhere?\n",
    "\n",
    "### A Bit About Machine Learning\n",
    "\n",
    "You may not have realised it when you started this notebook, but topic modelling is a Machine Learning (ML) method. ML is, of course, something of a hot topic...\n",
    "\n",
    "Topic modelling is described as an **unsupervised** **classification** technique.\n",
    "\n",
    "**Model**\n",
    "... \n",
    "\n",
    "**Classification**\n",
    "\n",
    "**Supervised and unsupervised techniques**\n",
    "\n",
    "Since topic modelling is an _unsupervised_ technique, we need to spend some time evaluating the topic models that are produced. We will do this in our worked example, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Summary\n",
    "\n",
    "Blah\n",
    "\n",
    "Blah: \n",
    "\n",
    "* sdfsdfsdf\n",
    "* sdfsdfsdf\n",
    "\n",
    "👌👌👌\n",
    "\n",
    "The next notebook ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
